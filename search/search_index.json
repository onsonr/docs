{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>Sonr is a decentralized identity network built on the Cosmos-sdk. It has early origins as a peer-to-peer file sharing network, but has since evolved into a platform for decentralized authentication and authorization. The early lessons taught from our file sharing roots are used as our theology for building the Sonr Blockchain.</p> <ol> <li>Cosmos-SDK</li> <li>Chain-Modules</li> <li>System-Architecture</li> <li>Token-Economy</li> <li>Service-Management</li> <li>Design-System</li> <li>Self-Custody</li> <li>Consumer Launch</li> </ol>"},{"location":"#principles","title":"Principles","text":"<ol> <li>Bitcoin is digital gold</li> <li>Blockchains are programmable databases with functional operations</li> <li>Staking is essentially a savings account</li> <li>The Sonr Network conducts all operations in the $SNR token</li> <li>Service Delegation subsidizes user wallet operations.</li> <li>Cryptocurrency has the potential to break the software innovation ceiling</li> </ol>"},{"location":"#the-problem","title":"The Problem","text":"<p>Centralized identity has led to internet monopolies abusing your trust and privacy.</p>"},{"location":"#the-solution","title":"The Solution","text":"<p>A peer-to-peer system for decentralized personal identity with Authentication and Authorization capabilities.</p>"},{"location":"#what-is-sonr","title":"What is Sonr?","text":"<p>A privacy preserving, identity system managed by user controlled decentralized vaults which have the flexibility of software wallets with the security of hardware wallets.</p>"},{"location":"#the-end-goal","title":"The End Goal","text":"<p>A Data sharing economy where human-specific information has intrinsic value. Services are incentivized to act in good faith in order to obtain quality user data.</p>"},{"location":"#how-do-we-do-it","title":"How do we do it?","text":"<p>Provide Internet Citizens with a robust easy to use WebVault which features a crypto wallet, passkey authenticator, and encrypted messages. The WebVault serves as a wrapper over every sensitive intent-based user interaction. The Smart blockchain is responsible for keeping a record of where WebVaults are located, when authorization activity occurs, and which services are allowed over what permissions.</p>"},{"location":"#the-user-incentive","title":"The User Incentive","text":"<p>Data is the byproduct of currency exchange in the Information age. Meaning services pay other services for user data or profits in order to enrich their database with complete user personas.</p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#v0527-2024-12-16","title":"v0.5.27 (2024-12-16)","text":""},{"location":"changelog/#v0526-2024-12-13","title":"v0.5.26 (2024-12-13)","text":""},{"location":"changelog/#fix","title":"Fix","text":"<ul> <li>Correct regular expression for version tags in release workflow</li> </ul>"},{"location":"changelog/#v0525-2024-12-11","title":"v0.5.25 (2024-12-11)","text":""},{"location":"changelog/#feat","title":"Feat","text":"<ul> <li>enable GoReleaser releases on tags and snapshots</li> <li>automate release on tag and workflow dispatch</li> </ul>"},{"location":"changelog/#v0524-2024-12-11","title":"v0.5.24 (2024-12-11)","text":""},{"location":"changelog/#feat_1","title":"Feat","text":"<ul> <li>prevent duplicate releases</li> </ul>"},{"location":"changelog/#v0523-2024-12-11","title":"v0.5.23 (2024-12-11)","text":""},{"location":"changelog/#refactor","title":"Refactor","text":"<ul> <li>rename scheduled release workflow to versioned release</li> <li>remove changelog from release artifacts</li> </ul>"},{"location":"changelog/#v0522-2024-12-11","title":"v0.5.22 (2024-12-11)","text":""},{"location":"changelog/#feat_2","title":"Feat","text":"<ul> <li>Implement passkey-based authentication and registration flow</li> </ul>"},{"location":"changelog/#v0521-2024-12-11","title":"v0.5.21 (2024-12-11)","text":""},{"location":"changelog/#feat_3","title":"Feat","text":"<ul> <li>allow manual triggering of deployment workflow</li> <li>add start-tui command for interactive mode</li> <li>add coin selection and update passkey input in registration form</li> <li>add hway command for Sonr DID gateway</li> <li>Conditionally install process-compose only if binary not found</li> <li>Add process-compose support with custom start and down commands</li> <li>implement passkey registration flow</li> <li>Improve createProfile form layout with wider max-width and enhanced spacing</li> <li>improve index page UI with new navigation buttons and remove redundant settings buttons</li> <li>Make input rows responsive with grid layout for mobile and desktop</li> <li>enhance index page with additional settings buttons and style adjustments</li> <li>implement passkey-based authentication</li> <li>add support for Cloudsmith releases</li> <li>add go dependency and enhance devbox environment variables</li> <li>update create profile form placeholders and handle</li> <li>add DID-based authentication middleware</li> <li>Add validation for human verification slider sum in CreateProfile form</li> <li>implement passkey registration flow</li> <li>Update WebAuthn credential handling with modern browser standards</li> <li>Streamline passkey registration with automatic form submission</li> <li>Add credential parsing and logging in register finish handler</li> <li>Add credential details row with icon after passkey creation</li> <li>Add form validation for passkey credential input</li> <li>implement passkey registration flow</li> <li>Add hidden input to store passkey credential data for form submission</li> <li>add CI workflow for deploying network</li> <li>add hway binary support and Homebrew formula</li> <li>remove username from passkey creation</li> <li>implement passkey registration flow</li> <li>add passkey creation functionality</li> <li>add CNAME for onsonr.dev domain</li> </ul>"},{"location":"changelog/#fix_1","title":"Fix","text":"<ul> <li>use Unix domain sockets for devnet processes</li> <li>correct workflow name and improve devnet deployment process</li> <li>correct title of profile creation page</li> <li>rename devbox start script to up and remove stop script</li> <li>Consolidate archive configuration and add LICENSE file</li> <li>Improve cross-browser passkey credential handling and encoding</li> <li>Remove commented-out code in passkey registration script</li> <li>remove line-clamp from tailwind config</li> <li>remove unnecessary background and restart settings from process-compose.yaml</li> <li>suppress process-compose server output and log to file</li> </ul>"},{"location":"changelog/#refactor_1","title":"Refactor","text":"<ul> <li>remove unnecessary git fetch step in deploy workflow</li> <li>remove obsolete interchain test dependencies</li> <li>update index views to use new nebula components</li> <li>move Wasm related code to pkg/common/wasm</li> <li>migrate config package to pkg directory</li> <li>migrate to new configuration system and model definitions</li> <li>move session package to pkg directory</li> <li>Refactor registration forms to use UI components</li> <li>move gateway config to vault package</li> <li>improve command line flag descriptions and variable names</li> <li>refactor hway command to use echo framework for server</li> <li>Update root command to load EnvImpl from cobra flags</li> <li>Modify command flags and environment loading logic in cmds.go</li> <li>improve build process and move process-compose.yaml</li> <li>remove unused devbox.json and related configurations</li> <li>Improve mobile layout responsiveness for Rows and Columns components</li> <li>Remove max-w-fit from Rows component</li> <li>replace session package with context package</li> <li>rename database initialization function</li> <li>move session management to dedicated database module</li> <li>remove unused UI components related to wallet and index pages</li> <li>consolidate handlers into single files</li> <li>move gateway and vault packages to internal directory</li> <li>Move registration form components to dedicated directory</li> <li>remove unused devbox package</li> <li>remove devbox configuration</li> <li>move vault package to app directory</li> <li>improve code structure within gateway package</li> <li>move gateway package to app directory</li> <li>move vault package internal components to root</li> <li>migrate layout imports to common styles package</li> <li>Move form templates and styles to common directory</li> <li>consolidate authentication and DID handling logic</li> <li>Improve WebAuthn credential handling and validation in register finish route</li> <li>remove profile card component</li> <li>Simplify passkey registration UI and move profile component inline</li> <li>Update credential logging with transport and ID type</li> <li>Update register handler to use protocol.CredentialDescriptor struct</li> <li>Update credential handling to use protocol.CredentialDescriptor</li> <li>improve profile card styling and functionality</li> <li>Simplify session management and browser information extraction</li> <li>Update PeerInfo to extract and store comprehensive device information</li> <li>improve address display in property details</li> <li>remove unused documentation generation script</li> <li>replace sonr/pkg/styles/layout with nebula/ui/layout</li> <li>migrate UI components to nebula module</li> <li>improve scopes.json structure and update scripts for better usability</li> </ul>"},{"location":"changelog/#v0520-2024-12-07","title":"v0.5.20 (2024-12-07)","text":""},{"location":"changelog/#refactor_2","title":"Refactor","text":"<ul> <li>simplify CI workflow by removing redundant asset publishing steps</li> </ul>"},{"location":"changelog/#v0519-2024-12-06","title":"v0.5.19 (2024-12-06)","text":""},{"location":"changelog/#feat_4","title":"Feat","text":"<ul> <li>add support for parent field and resources list in Capability message</li> <li>add fast reflection methods for Capability and Resource</li> <li>add gum package and update devbox configuration</li> <li>add new button components and layout improvements</li> </ul>"},{"location":"changelog/#fix_2","title":"Fix","text":"<ul> <li>adjust fullscreen modal close button margin</li> <li>update devbox lockfile</li> <li>resolve rendering issue in login modal</li> </ul>"},{"location":"changelog/#refactor_3","title":"Refactor","text":"<ul> <li>rename accaddr package to address</li> <li>Update Credential table to match WebAuthn Credential Descriptor</li> <li>Deployment setup</li> <li>migrate build system from Taskfile to Makefile</li> <li>rename Assertion to Account and update related code</li> <li>remove unused TUI components</li> <li>Move IPFS interaction functions to common package</li> <li>remove dependency on DWN.pkl</li> <li>remove unused dependencies and simplify module imports</li> <li>Rename x/vault -&gt; x/dwn and x/service -&gt; x/svc</li> <li>move resolver formatter to services package</li> <li>remove web documentation</li> <li>update devbox configuration and scripts</li> <li>rename layout component to root</li> <li>refactor authentication pages into their own modules</li> <li>update templ version to v0.2.778 and remove unused air config</li> <li>move signer implementation to mpc package</li> </ul>"},{"location":"changelog/#v0518-2024-11-06","title":"v0.5.18 (2024-11-06)","text":""},{"location":"changelog/#v0517-2024-11-05","title":"v0.5.17 (2024-11-05)","text":""},{"location":"changelog/#feat_5","title":"Feat","text":"<ul> <li>add remote client constructor</li> <li>add avatar image components</li> <li>add SVG CDN Illustrations to marketing architecture</li> <li>marketing: refactor marketing page components</li> <li>Refactor intro video component to use a proper script template</li> <li>Move Alpine.js script initialization to separate component</li> <li>Add intro video modal component</li> <li>add homepage architecture section</li> <li>add Hero section component with stats and buttons</li> <li>css: add new utility classes for group hover</li> <li>implement authentication register finish endpoint</li> <li>add controller creation step to allocate</li> <li>Update service module README based on protobuf files</li> <li>Update x/macaroon/README.md with details from protobuf files</li> <li>update Vault README with details from proto files</li> </ul>"},{"location":"changelog/#fix_3","title":"Fix","text":"<ul> <li>update file paths in error messages</li> <li>update intro video modal script</li> <li>include assets generation in wasm build</li> </ul>"},{"location":"changelog/#refactor_4","title":"Refactor","text":"<ul> <li>update marketing section architecture</li> <li>change verification table id</li> <li>proto: remove macaroon proto</li> <li>rename ValidateBasic to Validate</li> <li>rename session cookie key</li> <li>remove unused sync-initial endpoint</li> <li>remove formatter.go from service module</li> </ul>"},{"location":"changelog/#v0516-2024-10-21","title":"v0.5.16 (2024-10-21)","text":""},{"location":"changelog/#v0515-2024-10-21","title":"v0.5.15 (2024-10-21)","text":""},{"location":"changelog/#v0514-2024-10-21","title":"v0.5.14 (2024-10-21)","text":""},{"location":"changelog/#refactor_5","title":"Refactor","text":"<ul> <li>remove StakingKeeper dependency from GlobalFeeDecorator</li> </ul>"},{"location":"changelog/#v0513-2024-10-21","title":"v0.5.13 (2024-10-21)","text":""},{"location":"changelog/#feat_6","title":"Feat","text":"<ul> <li>add custom secp256k1 pubkey</li> </ul>"},{"location":"changelog/#refactor_6","title":"Refactor","text":"<ul> <li>update gRPC client to use new request types</li> <li>use RawPublicKey instead of PublicKey in macaroon issuer</li> <li>improve error handling in DID module</li> </ul>"},{"location":"changelog/#v0512-2024-10-18","title":"v0.5.12 (2024-10-18)","text":""},{"location":"changelog/#feat_7","title":"Feat","text":"<ul> <li>add User-Agent and Platform to session</li> <li>introduce AuthState enum for authentication state</li> </ul>"},{"location":"changelog/#fix_4","title":"Fix","text":"<ul> <li>version: revert version bump to 0.5.11</li> <li>version: update version to 0.5.12</li> </ul>"},{"location":"changelog/#refactor_7","title":"Refactor","text":"<ul> <li>remove dependency on proto change detection</li> <li>update asset publishing configuration</li> </ul>"},{"location":"changelog/#v0511-2024-10-10","title":"v0.5.11 (2024-10-10)","text":""},{"location":"changelog/#feat_8","title":"Feat","text":"<ul> <li>nebula assets served from CDN</li> <li>use CDN for nebula frontend assets</li> <li>add static hero section content to homepage</li> <li>add wrangler scripts for development, build, and deployment</li> <li>remove build configuration</li> <li>move gateway web code to dedicated directory</li> <li>add PubKey fast reflection</li> <li>macaroon: add transaction allowlist/denylist caveats</li> <li>add PR labeler</li> <li>devbox: remove hway start command</li> <li>add GitHub Actions workflow for running tests</li> <li>add workflow for deploying Hway to Cloudflare Workers</li> <li>Publish configs to R2</li> <li>integrate nebula UI with worker-assets-gen</li> <li>extract reusable layout components</li> <li>Implement service worker for IPFS vault</li> <li>implement CDN support for assets</li> <li>add payment method support</li> <li>add support for public key management</li> <li>add ModalForm component</li> <li>add LoginStart and RegisterStart routes</li> <li>implement authentication views</li> <li>add json tags to config structs</li> <li>implement templ forms for consent privacy, credential assert, credential register, and profile details</li> <li>vault: introduce assembly of the initial vault</li> <li>add client logos to homepage</li> <li>add tailwind utility classes</li> <li>implement new profile card component</li> </ul>"},{"location":"changelog/#fix_5","title":"Fix","text":"<ul> <li>Correct source directory for asset publishing</li> <li>install dependencies before nebula build</li> <li>update Schema service to use new API endpoint</li> <li>fix broken logo image path</li> </ul>"},{"location":"changelog/#refactor_8","title":"Refactor","text":"<ul> <li>remove unnecessary branch configuration from scheduled release workflow</li> <li>update dwn configuration generation import path</li> <li>use nebula/routes instead of nebula/global</li> <li>move index template to routes package</li> <li>remove cdn package and move assets to global styles</li> <li>move nebula assets to hway build directory</li> <li>remove docker build and deployment</li> <li>rename internal/session package to internal/ctx</li> <li>remove unused fields from</li> <li>rename PR_TEMPLATE to PULL_REQUEST_TEMPLATE</li> <li>remove devbox.json init hook</li> <li>rename sonrd dockerfile to Dockerfile</li> <li>remove unused dependency</li> <li>rename 'global/cdn' to 'assets'</li> <li>move CDN assets to separate folder</li> <li>move Pkl module definitions to dedicated package</li> <li>move CDN assets to js/ folder</li> <li>remove unused component templates</li> <li>move ui components to global</li> <li>move view handlers to router package</li> </ul>"},{"location":"changelog/#v0510-2024-10-07","title":"v0.5.10 (2024-10-07)","text":""},{"location":"changelog/#feat_9","title":"Feat","text":"<ul> <li>blocks: remove button component</li> </ul>"},{"location":"changelog/#v059-2024-10-06","title":"v0.5.9 (2024-10-06)","text":""},{"location":"changelog/#feat_10","title":"Feat","text":"<ul> <li>add Motr support</li> <li>update UIUX PKL to utilize optional fields</li> </ul>"},{"location":"changelog/#fix_6","title":"Fix","text":"<ul> <li>Update source directory for asset publishing</li> </ul>"},{"location":"changelog/#v058-2024-10-04","title":"v0.5.8 (2024-10-04)","text":""},{"location":"changelog/#refactor_9","title":"Refactor","text":"<ul> <li>Remove unused logs configuration</li> </ul>"},{"location":"changelog/#v057-2024-10-04","title":"v0.5.7 (2024-10-04)","text":""},{"location":"changelog/#feat_11","title":"Feat","text":"<ul> <li>devbox: use process-compose for testnet services</li> <li>remove motr.mjs dependency</li> <li>add markdown rendering to issue templates</li> <li>update issue templates for better clarity</li> <li>add issue templates for tracking and task issues</li> <li>add issue templates for bug report and tracking</li> <li>introduce docker-compose based setup</li> </ul>"},{"location":"changelog/#refactor_10","title":"Refactor","text":"<ul> <li>update issue template headings</li> <li>rename bug-report issue template to bug</li> </ul>"},{"location":"changelog/#v056-2024-10-03","title":"v0.5.6 (2024-10-03)","text":""},{"location":"changelog/#feat_12","title":"Feat","text":"<ul> <li>add hway and sonr processes to dev environment</li> </ul>"},{"location":"changelog/#v055-2024-10-03","title":"v0.5.5 (2024-10-03)","text":""},{"location":"changelog/#feat_13","title":"Feat","text":"<ul> <li>add rudimentary DidController table</li> <li>update home section with new features</li> <li>introduce Home model and refactor views</li> <li>nebula: create Home model for home page</li> </ul>"},{"location":"changelog/#refactor_11","title":"Refactor","text":"<ul> <li>reorganize pkl files for better separation of concerns</li> <li>rename msg_server_test.go to rpc_test.go</li> </ul>"},{"location":"changelog/#v054-2024-10-02","title":"v0.5.4 (2024-10-02)","text":""},{"location":"changelog/#v053-2024-10-02","title":"v0.5.3 (2024-10-02)","text":""},{"location":"changelog/#fix_7","title":"Fix","text":"<ul> <li>remove unnecessary telegram message template</li> </ul>"},{"location":"changelog/#v052-2024-10-02","title":"v0.5.2 (2024-10-02)","text":""},{"location":"changelog/#feat_14","title":"Feat","text":"<ul> <li>service: integrate group module (#1104)</li> </ul>"},{"location":"changelog/#refactor_12","title":"Refactor","text":"<ul> <li>revert version bump to 0.5.1</li> </ul>"},{"location":"changelog/#v051-2024-10-02","title":"v0.5.1 (2024-10-02)","text":""},{"location":"changelog/#refactor_13","title":"Refactor","text":"<ul> <li>move Motr API to state package</li> </ul>"},{"location":"changelog/#v050-2024-10-02","title":"v0.5.0 (2024-10-02)","text":""},{"location":"changelog/#feat_15","title":"Feat","text":"<ul> <li>allow multiple macaroons with the same id</li> </ul>"},{"location":"changelog/#v045-2024-10-02","title":"v0.4.5 (2024-10-02)","text":""},{"location":"changelog/#fix_8","title":"Fix","text":"<ul> <li>use correct secret for docker login</li> </ul>"},{"location":"changelog/#v044-2024-10-02","title":"v0.4.4 (2024-10-02)","text":""},{"location":"changelog/#v043-2024-10-02","title":"v0.4.3 (2024-10-02)","text":""},{"location":"changelog/#feat_16","title":"Feat","text":"<ul> <li>release: add docker images for sonrd and motr</li> <li>update homepage with new visual design</li> <li>add DID to vault genesis schema</li> <li>add video component</li> <li>add video component</li> <li>add hx-get attribute to primary button in hero section</li> </ul>"},{"location":"changelog/#fix_9","title":"Fix","text":"<ul> <li>layout: add missing favicon</li> <li>hero: Use hx-swap for primary button to prevent flicker</li> </ul>"},{"location":"changelog/#refactor_14","title":"Refactor","text":"<ul> <li>use single GITHUB_TOKEN for release workflow</li> <li>update workflow variables</li> </ul>"},{"location":"changelog/#v042-2024-10-01","title":"v0.4.2 (2024-10-01)","text":""},{"location":"changelog/#refactor_15","title":"Refactor","text":"<ul> <li>use single GITHUB_TOKEN for release workflow</li> </ul>"},{"location":"changelog/#v041-2024-10-01","title":"v0.4.1 (2024-10-01)","text":""},{"location":"changelog/#feat_17","title":"Feat","text":"<ul> <li>Implement session management</li> <li>allow manual release triggers</li> <li>add Input and RegistrationForm models</li> <li>add new utility classes</li> <li>add login and registration pages</li> <li>add tailwindcss utilities</li> <li>add support for ARM64 architecture</li> <li>add DWN resolver field</li> <li>add stats section to homepage</li> <li>implement hero section using Pkl</li> <li>add PKL schema for message formats</li> <li>add Homebrew tap for sonr</li> <li>update release workflow to use latest tag</li> </ul>"},{"location":"changelog/#fix_10","title":"Fix","text":"<ul> <li>version: update version number to 0.4.0</li> <li>update release workflow to use latest tag</li> <li>versioning: revert version to 0.9.0</li> <li>cta: Fix typo in CTA title</li> <li>change bento section title to reflect security focus</li> <li>adjust hero image dimensions</li> <li>Input: Change type from to</li> <li>update hero image height in config.pkl</li> </ul>"},{"location":"changelog/#refactor_16","title":"Refactor","text":"<ul> <li>move home page sections to home package</li> <li>rename motrd to motr</li> <li>update hero image dimensions</li> <li>move nebula configuration to static file</li> <li>rename buf-publish.yml to publish-assets.yml</li> <li>remove unused field from</li> </ul>"},{"location":"changelog/#v040-2024-09-30","title":"v0.4.0 (2024-09-30)","text":""},{"location":"changelog/#feat_18","title":"Feat","text":"<ul> <li>dwn: add wasm build for dwn</li> <li>add macaroon and oracle genesis states</li> <li>add scheduled binary release workflow</li> <li>introduce process-compose for process management</li> <li>add counter animation to hero section</li> <li>add registration page</li> </ul>"},{"location":"changelog/#fix_11","title":"Fix","text":"<ul> <li>Enable scheduled release workflow</li> </ul>"},{"location":"changelog/#refactor_17","title":"Refactor","text":"<ul> <li>remove old changelog entries</li> <li>remove unnecessary checkout in scheduled-release workflow</li> <li>rename build ID to sonr</li> <li>remove unnecessary release existence check</li> <li>move dwn wasm build to pkg directory</li> </ul>"},{"location":"changelog/#v031-2024-09-29","title":"v0.3.1 (2024-09-29)","text":""},{"location":"changelog/#refactor_18","title":"Refactor","text":"<ul> <li>move nebula/pages to pkg/nebula/pages</li> </ul>"},{"location":"changelog/#v030-2024-09-29","title":"v0.3.0 (2024-09-29)","text":""},{"location":"changelog/#feat_19","title":"Feat","text":"<ul> <li>add buf.lock for proto definitions</li> </ul>"},{"location":"changelog/#fix_12","title":"Fix","text":"<ul> <li>remove unused linting rules</li> <li>update proto breaking check target to master branch</li> </ul>"},{"location":"changelog/#refactor_19","title":"Refactor","text":"<ul> <li>remove unused lock files and configurations</li> </ul>"},{"location":"changelog/#v020-2024-09-29","title":"v0.2.0 (2024-09-29)","text":""},{"location":"changelog/#feat_20","title":"Feat","text":"<ul> <li>disable goreleaser workflow</li> <li>update workflows to include master branch</li> <li>remove global style declaration</li> <li>oracle: add oracle module</li> <li>optimize IPFS configuration for better performance</li> <li>add local IPFS bootstrap script and refactor devbox config</li> <li>add AllocateVault HTTP endpoint</li> <li>add WebAuthn credential management functionality</li> <li>remove unused coins interface</li> <li>remove global integrity proof from genesis state</li> <li>add vault module</li> <li>enable buf.build publishing on master and develop branches</li> <li>add Gitflow workflow for syncing branches</li> <li>add automated production release workflow</li> <li>ui: implement profile page</li> <li>add automated production release workflow</li> <li>did: remove unused proto files</li> <li>add enums.pulsar.go file for PermissionScope enum (#4)</li> <li>add initial DID implementation</li> <li>remove builder interface</li> <li>add basic UI for block explorer</li> <li>add Usage: pkl [OPTIONS] COMMAND [ARGS]...</li> <li>use SQLite embedded driver</li> <li>add DID method for each coin</li> <li>Expand KeyType enum and update KeyInfo message in genesis.proto</li> <li>Add whitelisted key types to genesis params</li> <li>Add DID grants protobuf definition</li> <li>Add fields to KeyInfo struct to distinguish CBOR and standard blockchain key types</li> <li>Add new message types for AssetInfo, ChainInfo, Endpoint, ExplorerInfo, FeeInfo, and KeyInfo</li> <li>run sonr-node container in testnet network and make network external</li> <li>Add docker-compose.yaml file to start a Sonr testnet node</li> <li>configure Sonr testnet environment</li> <li>Update Dockerfile to start and run a testnet</li> <li>add Equal methods for AssetInfo and ChainInfo types</li> <li>Add ProveWitness and SyncVault RPCs</li> <li>Add MsgRegisterService to handle service registration</li> <li>Add MsgRegisterService to handle service registration</li> <li>add enums.pulsar.go file for PermissionScope enum</li> </ul>"},{"location":"changelog/#fix_13","title":"Fix","text":"<ul> <li>ensure go version is up-to-date</li> <li>use GITHUB_TOKEN for version bump workflow</li> <li>update account table interface to use address, chain and network</li> <li>ci: update docker vm release workflow with new token</li> <li>use mnemonic phrases for test account keys</li> <li>reduce motr proxy shutdown timeout</li> <li>nebula: use bunx for tailwindcss build</li> <li>proto: update protobuf message index numbers</li> <li>ante: reduce POA rate floor and ceiling</li> <li>Update proc_list_width in mprocs.yaml</li> <li>Add service to database when registering</li> <li>pin added did documents to local ipfs node</li> <li>remove extra spaces in typeUrl</li> <li>release: remove unnecessary quotes in tag pattern</li> <li>remove unused imports and simplify KeyInfo message</li> <li>bind node ports to localhost</li> <li>Update docker-compose network name to dokploy-network</li> <li>Update network name to dokploy</li> <li>remove unused port mapping</li> <li>Update docker-compose.yaml to use correct volume path</li> <li>update docker-compose volume name</li> <li>Update docker-compose.yaml to use shell directly for sonrd command</li> <li>replace \"sh\" with \"/bin/sh\" in docker-compose.yaml command</li> <li>Update runner image dependencies for debian-11</li> <li>deps: update golang image to 1.21</li> <li>chains: update nomic chain build target</li> <li>Remove unused <code>Meta</code> message from <code>genesis.proto</code></li> <li>Add ProveWitness and SyncVault RPCs</li> </ul>"},{"location":"changelog/#refactor_20","title":"Refactor","text":"<ul> <li>adjust source directory for config files (#1102)</li> <li>Use actions/checkout@v4</li> <li>remove unused master branch from CI workflow</li> <li>rename github token secret</li> <li>remove unnecessary x-cloak styles</li> <li>optimize oracle genesis proto</li> <li>remove unused code related to whitelisted assets</li> <li>update buf publish source directory</li> <li>adjust devbox configuration to reflect nebula changes</li> <li>rename msg_server.go to rpc.go</li> <li>remove devbox integration</li> <li>move dwn package to app/config</li> <li>move configuration files to app directory</li> <li>extract root command creation to separate file</li> <li>move ipfs setup to function</li> <li>remove unnecessary proxy config</li> <li>rename script to</li> <li>move DWN proxy server logic to separate file</li> <li>use htmx instead of dwn for vault client</li> <li>remove unused environment variables</li> <li>simplify verification method structure</li> <li>use staking keeper in DID keeper</li> <li>remove unused dependencies</li> <li>remove unused image building workflow</li> <li>add field to</li> <li>Update KeyKind Enum to have proper naming conventions</li> <li>Update <code>DIDNamespace</code> to have proper naming convention</li> <li>expose ports directly in docker-compose</li> <li>remove unused port mappings</li> <li>streamline script execution</li> <li>use CMD instead of ENTRYPOINT in Dockerfile</li> <li>deps: Upgrade Debian base image to 11</li> <li>Simplify the types and properties to keep a consistent structure for the blockchain</li> <li>remove PERMISSION_SCOPE_IDENTIFIERS_ENS enum value</li> </ul>"},{"location":"guides/Chain-Modules/","title":"Chain Modules","text":""},{"location":"guides/Chain-Modules/#xdid-auth-authz","title":"<code>x/did</code> - Auth &amp; AuthZ","text":"<p>The DID module is responsible for managing the creation and management of DIDs. Controllers represent on-chain accounts backed by a MPC keypair. Controllers provide methods for Wallet Account Abstraction (WAA) and are responsible for managing the creation and management of DIDs for an individual user.</p>"},{"location":"guides/Chain-Modules/#features","title":"Features","text":"<ul> <li>DID Controllers leverage the Cosmos SDK's <code>x/accounts</code> std interface for WAA.</li> <li>DIDs are represented by a <code>x/did</code> controller and are required to state the   controller's public key, and which map to the controller's capabilities.</li> <li>General Sign/Verify methods are provides from the QueryServer for HTTP requests.</li> <li>The Execute method is used to broadcast transactions across the network. (TODO)</li> <li>Biscuits are used to authenticate and authorize requests between services. (TODO)</li> </ul>"},{"location":"guides/Chain-Modules/#references","title":"References","text":"<ul> <li>State</li> <li>State Transitions</li> <li>Messages</li> <li>Queries</li> <li>Params</li> <li>Client</li> <li>Future Improvements</li> <li>Tests</li> <li>Appendix</li> </ul>"},{"location":"guides/Chain-Modules/#xmacaroon","title":"<code>x/macaroon</code>","text":"<p>The macaroon module is responsible for issuing and verifying macaroons. Macaroons are used to authenticate and authorize requests between services. Macaroons are requested by NFT Records from <code>x/service</code> and granted by controllers from <code>x/did</code></p>"},{"location":"guides/Chain-Modules/#features_1","title":"Features","text":"<ul> <li>On Controller creation, a macaroon is created with an admin scope and a default expiry of 315,569,520 blocks (or ~10 years).</li> <li>On Service registration, a macaroon is created with a service scope and a default expiry of 31,556,952 blocks (or ~1 year).</li> <li>Macaroons contain the scope of access for a service and the expiry of the permissions in <code>blockHeight</code>.</li> </ul>"},{"location":"guides/Chain-Modules/#references_1","title":"References","text":"<ul> <li>State</li> <li>State Transitions</li> <li>Messages</li> <li>Queries</li> <li>Params</li> <li>Client</li> <li>Future Improvements</li> <li>Tests</li> <li>Appendix</li> </ul>"},{"location":"guides/Chain-Modules/#xservice","title":"<code>x/service</code>","text":"<p>The service module is responsible for managing decentralized services. Services on the Sonr network are essentially on-chain MultiSig wallets that are represented by a NFT. Service admins are represented by a <code>x/did</code> controller and are required to state the service's scope of access, and which map to the services' capabilities.</p>"},{"location":"guides/Chain-Modules/#features_2","title":"Features","text":"<ul> <li>Needs a Valid Domain with .htaccess file to be whitelisted.</li> </ul>"},{"location":"guides/Chain-Modules/#references_2","title":"References","text":"<ul> <li>State</li> <li>State Transitions</li> <li>Messages</li> <li>Queries</li> <li>Params</li> <li>Client</li> <li>Future Improvements</li> <li>Tests</li> <li>Appendix</li> </ul>"},{"location":"guides/Chain-Modules/#xvault","title":"<code>x/vault</code>","text":"<p>The vault module is responsible for managing the storage and acccess-control of Decentralized Web Nodes (DWNs) from IPFS. Vaults contain user-facing keys and are represented by a <code>x/did</code> controller.</p>"},{"location":"guides/Chain-Modules/#features_3","title":"Features","text":"<ul> <li>Vaults can be created by anyone, but efforts are made to restrict 1 per user.</li> <li>Vaults are stored in IPFS and when claimed, the bech32 Sonr Address is pinned to IPFS.</li> </ul>"},{"location":"guides/Chain-Modules/#references_3","title":"References","text":"<ul> <li>State</li> <li>State Transitions</li> <li>Messages</li> <li>Queries</li> <li>Params</li> <li>Client</li> <li>Future Improvements</li> <li>Tests</li> <li>Appendix</li> </ul>"},{"location":"guides/Consumer-Launch/","title":"Consumer Chain Launch Process","text":"<p>This guide is intended for consumer chain teams that are looking to be onboarded on to the Interchain Security testnet.</p>"},{"location":"guides/Consumer-Launch/#interchain-security-testnet-overview","title":"Interchain Security Testnet Overview","text":"<ul> <li>The Interchain Security (ICS) testnet is to be used to launch and test consumer chains. We recommend consumer chains to launch on the testnet before launching on the mainnet.</li> <li>All information about the ICS testnet is available in this repository.</li> <li>The testnet coordinators (Hypha) have majority voting power in the ICS testnet. This means we need to work with you to bring your chain live and also to successfully pass any governance proposals you make.</li> </ul>"},{"location":"guides/Consumer-Launch/#chain-onboarding-process","title":"Chain Onboarding Process","text":"<p>For teams looking to join the ICS testnet, the onboarding process can be broken down in four phases:</p> <ul> <li>Testing and Integration</li> <li>Planning with Testnet Coordinators</li> <li>Proposal Submission</li> <li>Chain Launch</li> </ul>"},{"location":"guides/Consumer-Launch/#local-testing-and-integration","title":"Local Testing and Integration","text":"<p>During this phase, your team will run integration tests with the following elements of an Interchain Security testnet:</p> <ul> <li>Gaia provider chain</li> <li>Visit the provider chain page for details on which Gaia version is currently being used.</li> <li>Relayers</li> <li>You will be responsible for running the relayer that relays the first set of Validator Set Change packets between provider and consumer chain. You should be proficient in setting up and running either Hermes or rly.</li> </ul> <p>By the end of this phase, you are able to launch a consumer chain within a local testnet or CI workflow that resembles the testnet (or mainnet) environment.</p>"},{"location":"guides/Consumer-Launch/#planning-with-testnet-coordinators","title":"Planning with Testnet Coordinators","text":"<p>Once you have a binary release ready, you can begin planning the launch with the testnet coordinators (Hypha).</p> <p>The goals of this phase are to update this repository with all the information validators need to join the network and to produce a <code>consumer-addition</code> proposal to be submitted in the provider chain.</p> <p>We expect you to run the minimum infrastructure required to make your consumer chain usable by testnet participants. This means running:</p> <ol> <li>Seed/persistent nodes</li> <li>Relayer it must be launched before the chain times out, preferably right after blocks start being produced.</li> <li>IMPORTANT: Make sure you have funds to pay gas fees for the relayer. You will likely need to set up an adequately funded genesis account for this purpose.</li> </ol> <p>Additionally, you may want to run:</p> <ul> <li>a faucet such as this simple REST faucet (it may need a separate funded account in the genesis file as well)</li> <li>a block explorer such as ping.pub</li> </ul>"},{"location":"guides/Consumer-Launch/#submitting-a-pr-for-a-new-chain","title":"\u270d\ufe0f Submitting a PR for a new chain","text":"<p>Each consumer chain gets its own directory. You can use the <code>slasher</code> chain as reference. Feel free to clone the slasher directory, modify it for your consumer chain, and make a PR with the relevant information.</p> <p>Hypha will be reviewing the PR to ensure it meets the following criteria:</p>"},{"location":"guides/Consumer-Launch/#readme-includes","title":"README includes:","text":"<ul> <li>[ ] Consumer chain repo and release or tag name.</li> <li>[ ] Build instructions for chain binary.</li> <li>[ ] Checksum of genesis file without CCV.</li> <li>[ ] Checksum of reference binary.</li> <li>[ ] Instructions on to join</li> <li>[ ] Installation steps</li> <li>Endpoints</li> <li>[ ] Seeds OR persistent peers</li> <li>[ ] State sync nodes (if any)</li> </ul> <p>See the <code>slasher</code> chain page for reference.</p>"},{"location":"guides/Consumer-Launch/#chain_id-must-be-identical-in-the-following-places","title":"<code>chain_id</code> must be identical in the following places:","text":"<ul> <li>[ ] <code>README</code></li> <li>[ ] genesis file</li> <li>[ ] consumer addition proposal</li> <li>[ ] bash script</li> </ul> <p>We recommend choosing a <code>chain_id</code> with the suffix <code>-1</code>, even if it's a subsequent test of the same chain, e.g. <code>testchain-second-rehearsal-1</code>.</p>"},{"location":"guides/Consumer-Launch/#binary-checksum-validation","title":"Binary checksum validation","text":"<ul> <li>[ ] <code>shasum -a 256 &lt;binary&gt;</code> matches the checksum in the proposal</li> <li>[ ] <code>shasum -a 256 &lt;binary&gt;</code> matches <code>README</code></li> </ul>"},{"location":"guides/Consumer-Launch/#bash-script","title":"Bash script","text":"<ul> <li>[ ] version built in script must match <code>README</code></li> <li>[ ] seeds or persistent peers must match <code>README</code></li> </ul>"},{"location":"guides/Consumer-Launch/#genesis-file","title":"Genesis file","text":"<ul> <li>[ ] Genesis time must match spawn time in the <code>consumer-addition</code> proposal</li> <li>[ ] Accounts and balances: Properly funded accounts (e.g., gas fees for relayer, faucet, etc.)</li> <li>[ ] Bank balance denom matches denom in <code>README</code></li> <li>[ ] Slashing parameters: Set <code>signed_blocks_window</code> and <code>min_signed_per_window</code> adequately to ensure validators have at least 12 hours to join the chain after launch without getting jailed</li> <li>[ ] <code>shasum -a 256 &lt;genesis file without CCV&gt;</code> matches the checksum in the proposal</li> <li>[ ] <code>shasum -a 256 &lt;genesis file without CCV&gt;</code> matches the checksum in the <code>README</code></li> <li>[ ] The genesis file is correctly formed: <code>&lt;consumer binary or gaiad&gt; validate-genesis /path/to/genesis-without-ccv.json</code> returns without error</li> </ul> <p>See the <code>slasher</code> chain genesis for reference.</p>"},{"location":"guides/Consumer-Launch/#consumer-addition-proposal","title":"<code>consumer-addition</code> proposal","text":"<ul> <li>[ ] Spawn time must match genesis time</li> <li>[ ] Spawn time must be later than voting period</li> <li>[ ] <code>revision_height: 1</code></li> <li>[ ] <code>revision_number: 1</code> (only if the <code>chain_id</code> ends in <code>-1</code>)</li> <li>[ ] <code>transfer_timeout_period: 1800000000000</code>. This value should be smaller than <code>blocks_per_distribution_transmission * block_time</code>.</li> <li>[ ] <code>ccv_timeout_period: 2419200000000000</code>. This value must be larger than the unbonding period, the default is 28 days.</li> <li>[ ] <code>unbonding_period: 1728000000000000</code> (given current provider params)</li> </ul> <p>See the <code>slasher</code> chain consumer-addition proposal and Interchain Security time-based parameters for reference.</p>"},{"location":"guides/Consumer-Launch/#node-configurations","title":"Node configurations","text":"<ul> <li>[ ] <code>minimum_gas_prices</code></li> <li>[ ] Check with Hypha about any other chain-specific params</li> </ul>"},{"location":"guides/Consumer-Launch/#on-chain-proposal-submission","title":"On-chain Proposal Submission","text":"<p>When you make your proposal, please let us know well in advance. The current voting period is five minutes, which means we\u2019ll need to vote right after you submit your proposal. We recommend submitting the proposal together with us on a call.</p> <p>The following will take place during the proposal submission phase:</p> <ul> <li>Your team will submit the <code>consumer-addition</code> proposal with a command that looks like this:   <code>gaiad tx gov submit-legacy-proposal consumer-addition proposal.json --from &lt;account name&gt; --chain-id provider --gas auto --fees 500uatom -b block -y</code></li> <li>Testnet coordinators will vote on it shortly afterwards to make sure it passes.</li> <li>You will open a pull request to add the new consumer chain entry to this repo and update the schedule page with the launch date.</li> <li>You will announce the upcoming launch, including the spawn time, in the Interchain Security <code>announcements</code> channel of the Cosmos Network Discord Server. If you need permissions for posting, please reach out to us.</li> </ul>"},{"location":"guides/Consumer-Launch/#chain-launch","title":"Chain Launch","text":"<p>After the spawn time is reached, the Cross-Chain Validation (CCV) state will be available on the provider chain and the new IBC client will be created. At this point, you will be able to:</p> <ul> <li>Collect the Cross-Chain Validation (CCV) state from the provider chain.   <code>gaiad q provider consumer-genesis &lt;chain-id&gt; -o json &gt; ccv-state.json</code></li> <li>Update the genesis file with the CCV state.   <code>jq -s '.[0].app_state.ccvconsumer = .[1] | .[0]' &lt;consumer genesis without CCV state&gt; ccv-state.json &gt; &lt;consumer genesis file with CCV state&gt;</code></li> <li>Publish the genesis file with CCV state to the testnets repo.</li> <li>Post the link to the genesis file and the SHA256 hash to the Interchain Security <code>interchain-security-testnet</code> channel of the Cosmos Network Discord Server.</li> <li>Ensure the required peers are online for people to connect to.</li> </ul> <p>The consumer chain will start producing blocks as soon as 66.67% of the provider chain's voting power comes online. You will be able to start the relayer afterwards:</p> <ul> <li>Query the IBC client ID of the provider chain.   <code>gaiad q provider list-consumer-chains</code></li> <li>Create the required IBC connections and channels for the CCV channel to be established. Using Hermes:   <code>hermes create connection --a-chain &lt;consumer chain ID&gt; --a-client 07-tendermint-0 --b-client &lt;provider chain client ID&gt;   hermes create channel --a-chain &lt;consumer chain ID&gt; --a-port consumer --b-port provider --order ordered --a-connection connection-0 --channel-version 1</code></li> <li>Start the relayer</li> <li>The trusting period fraction is set to <code>0.25</code> on the provider chain, so you should use a trusting period of 5 days in your relayer configuration.</li> </ul> <p>Finally, the testnet coordinators will:</p> <ul> <li>Trigger a validator set update in the provider chain to establish the CCV channel and verify the validator set has been updated in the consumer chain.</li> <li>Announce the chain is interchain secured.</li> <li>Update the testnets repo with the IBC information.</li> </ul>"},{"location":"guides/Consumer-Launch/#talk-to-us","title":"Talk to us","text":"<p>If you're a consumer chain looking to launch, please get in touch with Hypha. You can reach Lexa Michaelides at <code>lexa@hypha.coop</code> or on Telegram.</p>"},{"location":"guides/Self-Custody/","title":"Self Custody","text":"<p>With increasingly sensitive information being stored in centralized databases, we believe that a decentralized anonymity mechanism is the only way to protect user data. Sonr is at its core a peer-to-peer identity system, which means that users can choose to share their identity with others in a way that is private and secure.</p>"},{"location":"guides/Self-Custody/#decentralized-identifiers","title":"Decentralized Identifiers","text":""},{"location":"guides/Self-Custody/#cross-chain-interoperability","title":"Cross-chain Interoperability","text":""},{"location":"guides/Self-Custody/#w3c-web-apis","title":"W3C Web APIs","text":""},{"location":"guides/System-Architecture/","title":"System Architecture","text":"<p>Sonr is a decentralized platform that allows users to create and manage their own decentralized identity.</p>"},{"location":"guides/System-Architecture/#blockchain-sonr","title":"Blockchain: Sonr","text":"<p>Sonr stores Decentralized Identifiers (DIDs) on its Cosmos-sdk based blockchain. The blockchain's role is to act as the persistent pointer store for locations of User owned data.</p>"},{"location":"guides/System-Architecture/#user-key-vault-motr","title":"User Key Vault: Motr","text":"<p>The Motr node is a service-worker which functions as a personal encrypted key-enclave for users stored on IPFS. They can be allocated and persisted on the Sonr blockchain for Smart Wallet functionality.</p>"},{"location":"guides/System-Architecture/#network-gateway-hway","title":"Network Gateway: Hway","text":"<p>The Hway protocol is a network proxy which routes network requests to the appropriate service endpoint. This is used for seamless communication between Blockchain Nodes, Decentralized Applications, and User Nodes.</p>"},{"location":"guides/System-Architecture/#design-system-nebula","title":"Design System: Nebula","text":"<p>Built with Golang-Templ, TailwindCSS, HTMX, and Service Workers - Nebula is a component library which allows for consistent UX across the entire ecosystem.</p>"},{"location":"guides/Token-Economy/","title":"Token Economy","text":"<p>The <code>$SNR</code> token is the native platform token of the Sonr network. It is used by services to pay for Authentication and Authorization services. The system is designed for developers to be similar to centralized authentication providers like Google, Facebook, Okta, etc.</p>"},{"location":"guides/Token-Economy/#usage","title":"Usage","text":"<p>The Sonr blockchain is a Delegated Proof of Stake (DPoS) blockchain built with the Cosmos-sdk.</p>"},{"location":"guides/Token-Economy/#supply","title":"Supply","text":"<p>The total supply of <code>$SNR</code> is fixed at 1 billion.</p> <p></p>"},{"location":"guides/nebula-ui/","title":"Nebula ui","text":"<p>In order to maintain a tight-knit experience, we designed Sonr to operate completely in the point-of-view of the user. This led to us building a Component Library which creates consistent UX across the entire ecosystem.</p>"},{"location":"guides/nebula-ui/#overview","title":"Overview","text":"<p>The Sonr blockchain is a Delegated Proof of Stake (DPoS) blockchain built with the Cosmos-sdk.</p>"},{"location":"guides/nebula-ui/#nebula-package","title":"Nebula Package","text":"<p>The total supply of <code>$SNR</code> is fixed at 1 billion.</p>"},{"location":"guides/sdk-usage/","title":"Sdk usage","text":""},{"location":"guides/sdk-usage/#xdid-auth-authz","title":"<code>x/did</code> - Auth &amp; AuthZ","text":"<p>The DID module is responsible for managing the creation and management of DIDs. Controllers represent on-chain accounts backed by a MPC keypair. Controllers provide methods for Wallet Account Abstraction (WAA) and are responsible for managing the creation and management of DIDs for an individual user.</p>"},{"location":"guides/sdk-usage/#features","title":"Features","text":"<ul> <li>DID Controllers leverage the Cosmos SDK's <code>x/accounts</code> std interface for WAA.</li> <li>DIDs are represented by a <code>x/did</code> controller and are required to state the   controller's public key, and which map to the controller's capabilities.</li> <li>General Sign/Verify methods are provides from the QueryServer for HTTP requests.</li> <li>The Execute method is used to broadcast transactions across the network. (TODO)</li> <li>Biscuits are used to authenticate and authorize requests between services. (TODO)</li> </ul>"},{"location":"guides/sdk-usage/#references","title":"References","text":"<ul> <li>State</li> <li>State Transitions</li> <li>Messages</li> <li>Queries</li> <li>Params</li> <li>Client</li> <li>Future Improvements</li> <li>Tests</li> <li>Appendix</li> </ul>"},{"location":"guides/sdk-usage/#xmacaroon","title":"<code>x/macaroon</code>","text":"<p>The macaroon module is responsible for issuing and verifying macaroons. Macaroons are used to authenticate and authorize requests between services. Macaroons are requested by NFT Records from <code>x/service</code> and granted by controllers from <code>x/did</code></p>"},{"location":"guides/sdk-usage/#features_1","title":"Features","text":"<ul> <li>On Controller creation, a macaroon is created with an admin scope and a default expiry of 315,569,520 blocks (or ~10 years).</li> <li>On Service registration, a macaroon is created with a service scope and a default expiry of 31,556,952 blocks (or ~1 year).</li> <li>Macaroons contain the scope of access for a service and the expiry of the permissions in <code>blockHeight</code>.</li> </ul>"},{"location":"guides/sdk-usage/#references_1","title":"References","text":"<ul> <li>State</li> <li>State Transitions</li> <li>Messages</li> <li>Queries</li> <li>Params</li> <li>Client</li> <li>Future Improvements</li> <li>Tests</li> <li>Appendix</li> </ul>"},{"location":"guides/sdk-usage/#xservice","title":"<code>x/service</code>","text":"<p>The service module is responsible for managing decentralized services. Services on the Sonr network are essentially on-chain MultiSig wallets that are represented by a NFT. Service admins are represented by a <code>x/did</code> controller and are required to state the service's scope of access, and which map to the services' capabilities.</p>"},{"location":"guides/sdk-usage/#features_2","title":"Features","text":"<ul> <li>Needs a Valid Domain with .htaccess file to be whitelisted.</li> </ul>"},{"location":"guides/sdk-usage/#references_2","title":"References","text":"<ul> <li>State</li> <li>State Transitions</li> <li>Messages</li> <li>Queries</li> <li>Params</li> <li>Client</li> <li>Future Improvements</li> <li>Tests</li> <li>Appendix</li> </ul>"},{"location":"guides/sdk-usage/#xvault","title":"<code>x/vault</code>","text":"<p>The vault module is responsible for managing the storage and acccess-control of Decentralized Web Nodes (DWNs) from IPFS. Vaults contain user-facing keys and are represented by a <code>x/did</code> controller.</p>"},{"location":"guides/sdk-usage/#features_3","title":"Features","text":"<ul> <li>Vaults can be created by anyone, but efforts are made to restrict 1 per user.</li> <li>Vaults are stored in IPFS and when claimed, the bech32 Sonr Address is pinned to IPFS.</li> </ul>"},{"location":"guides/sdk-usage/#references_3","title":"References","text":"<ul> <li>State</li> <li>State Transitions</li> <li>Messages</li> <li>Queries</li> <li>Params</li> <li>Client</li> <li>Future Improvements</li> <li>Tests</li> <li>Appendix</li> </ul>"},{"location":"guides/svc-management/","title":"Svc management","text":"<p>The <code>$SNR</code> token is the native platform token of the Sonr network. It is used by services to pay for Authentication and Authorization services. The system is designed for developers to be similar to centralized authentication providers like Google, Facebook, Okta, etc.</p>"},{"location":"guides/svc-management/#usage","title":"Usage","text":"<p>The Sonr blockchain is a Delegated Proof of Stake (DPoS) blockchain built with the Cosmos-sdk.</p>"},{"location":"guides/svc-management/#supply","title":"Supply","text":"<p>The total supply of <code>$SNR</code> is fixed at 1 billion.</p>"},{"location":"guides/tools/cosmos-proto/","title":"Protocol Buffers in Cosmos SDK","text":""},{"location":"guides/tools/cosmos-proto/#overview","title":"Overview","text":"<p>The Cosmos SDK uses Protocol Buffers for serialization and API definitions. Generation is handled via a Docker image: <code>ghcr.io/cosmos/proto-builder:0.15.x</code>.</p>"},{"location":"guides/tools/cosmos-proto/#generation-tools","title":"Generation Tools","text":"<ul> <li>Buf: Primary tool for protobuf management</li> <li>protocgen.sh: Core generation script in <code>scripts/</code> </li> <li>Makefile Commands: Standard commands for generate, lint, format</li> </ul>"},{"location":"guides/tools/cosmos-proto/#key-components","title":"Key Components","text":""},{"location":"guides/tools/cosmos-proto/#buf-configuration","title":"Buf Configuration","text":"<ol> <li>Workspace Setup</li> <li>Root level buf workspace configuration</li> <li> <p>Manages multiple protobuf directories</p> </li> <li> <p>Directory Structure <code>proto/    \u251c\u2500\u2500 buf.gen.gogo.yaml    # GoGo Protobuf generation    \u251c\u2500\u2500 buf.gen.pulsar.yaml  # Pulsar API generation      \u251c\u2500\u2500 buf.gen.swagger.yaml # OpenAPI/Swagger docs    \u251c\u2500\u2500 buf.lock            # Dependencies    \u251c\u2500\u2500 buf.yaml            # Core configuration    \u251c\u2500\u2500 cosmos/            # Core protos    \u2514\u2500\u2500 tendermint/        # Consensus protos</code></p> </li> <li> <p>Module Protos</p> </li> <li>Located in <code>x/{moduleName}/proto</code></li> <li>Module-specific message definitions</li> </ol>"},{"location":"guides/tools/cosmos-proto/#bufgengogoyaml","title":"<code>buf.gen.gogo.yaml</code>","text":"<p><code>buf.gen.gogo.yaml</code> defines how the protobuf files should be generated for use with in the module. This file uses gogoproto, a separate generator from the google go-proto generator that makes working with various objects more ergonomic, and it has more performant encode and decode steps</p> <p>```go reference https://github.com/cosmos/cosmos-sdk/blob/main/proto/buf.gen.gogo.yaml#L1-L9</p> <pre><code>\n#### `buf.gen.pulsar.yaml`\n\n`buf.gen.pulsar.yaml` defines how protobuf files should be generated using the [new golang apiv2 of protobuf](https://go.dev/blog/protobuf-apiv2). This generator is used instead of the google go-proto generator because it has some extra helpers for Cosmos SDK applications and will have more performant encode and decode than the google go-proto generator. You can follow the development of this generator [here](https://github.com/cosmos/cosmos-proto).\n\n```go reference\nhttps://github.com/cosmos/cosmos-sdk/blob/main/proto/buf.gen.pulsar.yaml#L1-L18\n</code></pre>"},{"location":"guides/tools/cosmos-proto/#bufgenswaggeryaml","title":"<code>buf.gen.swagger.yaml</code>","text":"<p><code>buf.gen.swagger.yaml</code> generates the swagger documentation for the query and messages of the chain. This will only define the REST API end points that were defined in the query and msg servers. You can find examples of this here</p> <p>```go reference https://github.com/cosmos/cosmos-sdk/blob/main/proto/buf.gen.swagger.yaml#L1-L6</p> <pre><code>\n#### `buf.lock`\n\nThis is an autogenerated file based off the dependencies required by the `.gen` files. There is no need to copy the current one. If you depend on cosmos-sdk proto definitions a new entry for the Cosmos SDK will need to be provided. The dependency you will need to use is `buf.build/cosmos/cosmos-sdk`.\n\n```go reference\nhttps://github.com/cosmos/cosmos-sdk/blob/main/proto/buf.lock#L1-L16\n</code></pre>"},{"location":"guides/tools/cosmos-proto/#bufyaml","title":"<code>buf.yaml</code>","text":"<p><code>buf.yaml</code> defines the name of your package, which breakage checker to use and how to lint your protobuf files.</p> <p>It is advised to use a tagged version of the buf modules corresponding to the version of the Cosmos SDK being are used.</p> <p>```go reference https://github.com/cosmos/cosmos-sdk/blob/main/proto/buf.yaml#L1-L24</p> <pre><code>\nWe use a variety of linters for the Cosmos SDK protobuf files. The repo also checks this in ci.\nA reference to the github actions can be found [here](https://github.com/cosmos/cosmos-sdk/blob/main/.github/workflows/proto.yml#L1-L32)\n\n# ORM\n\nThe Cosmos SDK ORM is a state management library that provides a rich, but opinionated set of tools for managing a\nmodule's state. It provides support for:\n\n- type safe management of state\n- multipart keys\n- secondary indexes\n- unique indexes\n- easy prefix and range queries\n- automatic genesis import/export\n- automatic query services for clients, including support for light client proofs (still in development)\n- indexing state data in external databases (still in development)\n\n## Design and Philosophy\n\nThe ORM's data model is inspired by the relational data model found in SQL databases. The core abstraction is a table\nwith a primary key and optional secondary indexes.\n\nBecause the Cosmos SDK uses protobuf as its encoding layer, ORM tables are defined directly in .proto files using\nprotobuf options. Each table is defined by a single protobuf `message` type and a schema of multiple tables is\nrepresented by a single .proto file.\n\nTable structure is specified in the same file where messages are defined in order to make it easy to focus on better\ndesign of the state layer. Because blockchain state layout is part of the public API for clients (TODO: link to docs on\nlight client proofs), it is important to think about the state layout as being part of the public API of a module.\nChanging the state layout actually breaks clients, so it is ideal to think through it carefully up front and to aim for\na design that will eliminate or minimize breaking changes down the road. Also, good design of state enables building\nmore performant and sophisticated applications. Providing users with a set of tools inspired by relational databases\nwhich have a long history of database design best practices and allowing schema to be specified declaratively in a\nsingle place are design choices the ORM makes to enable better design and more durable APIs.\n\nAlso, by only supporting the table abstraction as opposed to key-value pair maps, it is easy to add to new\ncolumns/fields to any data structure without causing a breaking change and the data structures can easily be indexed in\nany off-the-shelf SQL database for more sophisticated queries.\n\nThe encoding of fields in keys is designed to support ordered iteration for all protobuf primitive field types\nexcept for `bytes` as well as the well-known types `google.protobuf.Timestamp` and `google.protobuf.Duration`. Encodings\nare optimized for storage space when it makes sense (see the documentation in `cosmos/orm/v1/orm.proto` for more details)\nand table rows do not use extra storage space to store key fields in the value.\n\nWe recommend that users of the ORM attempt to follow database design best practices such as\n[normalization](https://en.wikipedia.org/wiki/Database_normalization) (at least 1NF).\nFor instance, defining `repeated` fields in a table is considered an anti-pattern because breaks first normal form (1NF).\nAlthough we support `repeated` fields in tables, they cannot be used as key fields for this reason. This may seem\nrestrictive but years of best practice (and also experience in the SDK) have shown that following this pattern\nleads to easier to maintain schemas.\n\nTo illustrate the motivation for these principles with an example from the SDK, historically balances were stored\nas a mapping from account -&gt; map of denom to amount. This did not scale well because an account with 100 token balances\nneeded to be encoded/decoded every time a single coin balance changed. Now balances are stored as account,denom -&gt; amount\nas in the example above. With the ORM's data model, if we wanted to add a new field to `Balance` such as\n`unlocked_balance` (if vesting accounts were redesigned in this way), it would be easy to add it to this table without\nrequiring a data migration. Because of the ORM's optimizations, the account and denom are only stored in the key part\nof storage and not in the value leading to both a flexible data model and efficient usage of storage.\n\n## Defining Tables\n\nTo define a table:\n\n1. create a .proto file to describe the module's state (naming it `state.proto` is recommended for consistency),\n   and import \"cosmos/orm/v1/orm.proto\", ex:\n\n```protobuf\nsyntax = \"proto3\";\npackage bank_example;\n\nimport \"cosmos/orm/v1/orm.proto\";\n</code></pre> <ol> <li>define a <code>message</code> for the table, ex:</li> </ol> <pre><code>message Balance {\n  bytes account = 1;\n  string denom = 2;\n  uint64 balance = 3;\n}\n</code></pre> <ol> <li>add the <code>cosmos.orm.v1.table</code> option to the table and give the table an <code>id</code> unique within this .proto file:</li> </ol> <pre><code>message Balance {\n  option (cosmos.orm.v1.table) = {\n    id: 1\n  };\n\n  bytes account = 1;\n  string denom = 2;\n  uint64 balance = 3;\n}\n</code></pre> <ol> <li>define the primary key field or fields, as a comma-separated list of the fields from the message which should make    up the primary key:</li> </ol> <pre><code>message Balance {\n  option (cosmos.orm.v1.table) = {\n    id: 1\n    primary_key: { fields: \"account,denom\" }\n  };\n\n  bytes account = 1;\n  string denom = 2;\n  uint64 balance = 3;\n}\n</code></pre> <ol> <li>add any desired secondary indexes by specifying an <code>id</code> unique within the table and a comma-separate list of the    index fields:</li> </ol> <pre><code>message Balance {\n  option (cosmos.orm.v1.table) = {\n    id: 1;\n    primary_key: { fields: \"account,denom\" }\n    index: { id: 1 fields: \"denom\" } // this allows querying for the accounts which own a denom\n  };\n\n  bytes account = 1;\n  string denom   = 2;\n  uint64 amount  = 3;\n}\n</code></pre>"},{"location":"guides/tools/cosmos-proto/#auto-incrementing-primary-keys","title":"Auto-incrementing Primary Keys","text":"<p>A common pattern in SDK modules and in database design is to define tables with a single integer <code>id</code> field with an automatically generated primary key. In the ORM we can do this by setting the <code>auto_increment</code> option to <code>true</code> on the primary key, ex:</p> <pre><code>message Account {\n  option (cosmos.orm.v1.table) = {\n    id: 2;\n    primary_key: { fields: \"id\", auto_increment: true }\n  };\n\n  uint64 id = 1;\n  bytes address = 2;\n}\n</code></pre>"},{"location":"guides/tools/cosmos-proto/#unique-indexes","title":"Unique Indexes","text":"<p>A unique index can be added by setting the <code>unique</code> option to <code>true</code> on an index, ex:</p> <pre><code>message Account {\n  option (cosmos.orm.v1.table) = {\n    id: 2;\n    primary_key: { fields: \"id\", auto_increment: true }\n    index: {id: 1, fields: \"address\", unique: true}\n  };\n\n  uint64 id = 1;\n  bytes address = 2;\n}\n</code></pre>"},{"location":"guides/tools/cosmos-proto/#singletons","title":"Singletons","text":"<p>The ORM also supports a special type of table with only one row called a <code>singleton</code>. This can be used for storing module parameters. Singletons only need to define a unique <code>id</code> and that cannot conflict with the id of other tables or singletons in the same .proto file. Ex:</p> <pre><code>message Params {\n  option (cosmos.orm.v1.singleton) = {\n    id: 3;\n  };\n\n  google.protobuf.Duration voting_period = 1;\n  uint64 min_threshold = 2;\n}\n</code></pre>"},{"location":"guides/tools/cosmos-proto/#running-codegen","title":"Running Codegen","text":"<p>NOTE: the ORM will only work with protobuf code that implements the google.golang.org/protobuf API. That means it will not work with code generated using gogo-proto.</p> <p>To install the ORM's code generator, run:</p> <pre><code>go install cosmossdk.io/orm/cmd/protoc-gen-go-cosmos-orm@latest\n</code></pre> <p>The recommended way to run the code generator is to use buf build. This is an example <code>buf.gen.yaml</code> that runs <code>protoc-gen-go</code>, <code>protoc-gen-go-grpc</code> and <code>protoc-gen-go-cosmos-orm</code> using buf managed mode:</p> <pre><code>version: v1\nmanaged:\n  enabled: true\n  go_package_prefix:\n    default: foo.bar/api # the go package prefix of your package\n    override:\n      buf.build/cosmos/cosmos-sdk: cosmossdk.io/api # required to import the Cosmos SDK api module\nplugins:\n  - name: go\n    out: .\n    opt: paths=source_relative\n  - name: go-grpc\n    out: .\n    opt: paths=source_relative\n  - name: go-cosmos-orm\n    out: .\n    opt: paths=source_relative\n</code></pre>"},{"location":"guides/tools/cosmos-proto/#using-the-orm-in-a-module","title":"Using the ORM in a module","text":""},{"location":"guides/tools/cosmos-proto/#initialization","title":"Initialization","text":"<p>To use the ORM in a module, first create a <code>ModuleSchemaDescriptor</code>. This tells the ORM which .proto files have defined an ORM schema and assigns them all a unique non-zero id. Ex:</p> <pre><code>var MyModuleSchema = &amp;ormv1alpha1.ModuleSchemaDescriptor{\n    SchemaFile: []*ormv1alpha1.ModuleSchemaDescriptor_FileEntry{\n        {\n            Id:            1,\n            ProtoFileName: mymodule.File_my_module_state_proto.Path(),\n        },\n    },\n}\n</code></pre> <p>In the ORM generated code for a file named <code>state.proto</code>, there should be an interface <code>StateStore</code> that got generated with a constructor <code>NewStateStore</code> that takes a parameter of type <code>ormdb.ModuleDB</code>. Add a reference to <code>StateStore</code> to your module's keeper struct. Ex:</p> <pre><code>type Keeper struct {\n    db StateStore\n}\n</code></pre> <p>Then instantiate the <code>StateStore</code> instance via an <code>ormdb.ModuleDB</code> that is instantiated from the <code>SchemaDescriptor</code> above and one or more store services from <code>cosmossdk.io/core/store</code>. Ex:</p> <pre><code>func NewKeeper(storeService store.KVStoreService) (*Keeper, error) {\n    modDb, err := ormdb.NewModuleDB(MyModuleSchema, ormdb.ModuleDBOptions{KVStoreService: storeService})\n    if err != nil {\n        return nil, err\n    }\n    db, err := NewStateStore(modDb)\n    if err != nil {\n        return nil, err\n    }\n    return Keeper{db: db}, nil\n}\n</code></pre>"},{"location":"guides/tools/cosmos-proto/#using-the-generated-code","title":"Using the generated code","text":"<p>The generated code for the ORM contains methods for inserting, updating, deleting and querying table entries. For each table in a .proto file, there is a type-safe table interface implemented in generated code. For instance, for a table named <code>Balance</code> there should be a <code>BalanceTable</code> interface that looks like this:</p> <pre><code>type BalanceTable interface {\n    Insert(ctx context.Context, balance *Balance) error\n    Update(ctx context.Context, balance *Balance) error\n    Save(ctx context.Context, balance *Balance) error\n    Delete(ctx context.Context, balance *Balance) error\n    Has(ctx context.Context, account []byte, denom string) (found bool, err error)\n    // Get returns nil and an error which responds true to ormerrors.IsNotFound() if the record was not found.\n    Get(ctx context.Context, account []byte, denom string) (*Balance, error)\n    List(ctx context.Context, prefixKey BalanceIndexKey, opts ...ormlist.Option) (BalanceIterator, error)\n    ListRange(ctx context.Context, from, to BalanceIndexKey, opts ...ormlist.Option) (BalanceIterator, error)\n    DeleteBy(ctx context.Context, prefixKey BalanceIndexKey) error\n    DeleteRange(ctx context.Context, from, to BalanceIndexKey) error\n\n    doNotImplement()\n}\n</code></pre> <p>This <code>BalanceTable</code> should be accessible from the <code>StateStore</code> interface (assuming our file is named <code>state.proto</code>) via a <code>BalanceTable()</code> accessor method. If all the above example tables/singletons were in the same <code>state.proto</code>, then <code>StateStore</code> would get generated like this:</p> <pre><code>type BankStore interface {\n    BalanceTable() BalanceTable\n    AccountTable() AccountTable\n    ParamsTable() ParamsTable\n\n    doNotImplement()\n}\n</code></pre> <p>So to work with the <code>BalanceTable</code> in a keeper method we could use code like this:</p> <pre><code>func (k keeper) AddBalance(ctx context.Context, acct []byte, denom string, amount uint64) error {\n    balance, err := k.db.BalanceTable().Get(ctx, acct, denom)\n    if err != nil &amp;&amp; !ormerrors.IsNotFound(err) {\n        return err\n    }\n\n    if balance == nil {\n        balance = &amp;Balance{\n            Account: acct,\n            Denom:   denom,\n            Amount:  amount,\n        }\n    } else {\n        balance.Amount = balance.Amount + amount\n    }\n\n    return k.db.BalanceTable().Save(ctx, balance)\n}\n</code></pre> <p><code>List</code> methods take <code>IndexKey</code> parameters. For instance, <code>BalanceTable.List</code> takes <code>BalanceIndexKey</code>. <code>BalanceIndexKey</code> let's represent index keys for the different indexes (primary and secondary) on the <code>Balance</code> table. The primary key in the <code>Balance</code> table gets a struct <code>BalanceAccountDenomIndexKey</code> and the first index gets an index key <code>BalanceDenomIndexKey</code>. If we wanted to list all the denoms and amounts that an account holds, we would use <code>BalanceAccountDenomIndexKey</code> with a <code>List</code> query just on the account prefix. Ex:</p> <pre><code>it, err := keeper.db.BalanceTable().List(ctx, BalanceAccountDenomIndexKey{}.WithAccount(acct))\n</code></pre>"},{"location":"guides/tools/cosmos-proto/#sidebar_position-1","title":"sidebar_position: 1","text":""},{"location":"guides/tools/cosmos-proto/#protocolbuffer-annotations","title":"ProtocolBuffer Annotations","text":"<p>This document explains the various protobuf scalars that have been added to make working with protobuf easier for Cosmos SDK application developers</p>"},{"location":"guides/tools/cosmos-proto/#signer","title":"Signer","text":"<p>Signer specifies which field should be used to determine the signer of a message for the Cosmos SDK. This field can be used for clients as well to infer which field should be used to determine the signer of a message.</p> <p>Read more about the signer field here.</p> <p>```protobuf reference https://github.com/cosmos/cosmos-sdk/blob/e6848d99b55a65d014375b295bdd7f9641aac95e/proto/cosmos/bank/v1beta1/tx.proto#L40</p> <pre><code>\n```proto\noption (cosmos.msg.v1.signer) = \"from_address\";\n</code></pre>"},{"location":"guides/tools/cosmos-proto/#scalar","title":"Scalar","text":"<p>The scalar type defines a way for clients to understand how to construct protobuf messages according to what is expected by the module and sdk.</p> <pre><code>(cosmos_proto.scalar) = \"cosmos.AddressString\"\n</code></pre> <p>Example of account address string scalar:</p> <p>```proto reference https://github.com/cosmos/cosmos-sdk/blob/e6848d99b55a65d014375b295bdd7f9641aac95e/proto/cosmos/bank/v1beta1/tx.proto#L46</p> <pre><code>\nExample of validator address string scalar:\n\n```proto reference\nhttps://github.com/cosmos/cosmos-sdk/blob/e8f28bf5db18b8d6b7e0d94b542ce4cf48fed9d6/proto/cosmos/distribution/v1beta1/query.proto#L87\n</code></pre> <p>Example of pubkey scalar:</p> <p>```proto reference https://github.com/cosmos/cosmos-sdk/blob/11068bfbcd44a7db8af63b6a8aa079b1718f6040/proto/cosmos/staking/v1beta1/tx.proto#L94</p> <pre><code>\nExample of Decimals scalar:\n\n```proto reference\nhttps://github.com/cosmos/cosmos-sdk/blob/e8f28bf5db18b8d6b7e0d94b542ce4cf48fed9d6/proto/cosmos/distribution/v1beta1/distribution.proto#L26\n</code></pre> <p>Example of Int scalar:</p> <p>```proto reference https://github.com/cosmos/cosmos-sdk/blob/e8f28bf5db18b8d6b7e0d94b542ce4cf48fed9d6/proto/cosmos/gov/v1/gov.proto#L137</p> <pre><code>\nThere are a few options for what can be provided as a scalar: `cosmos.AddressString`, `cosmos.ValidatorAddressString`, `cosmos.ConsensusAddressString`, `cosmos.Int`, `cosmos.Dec`.\n\n## Implements_Interface\n\nImplement interface is used to provide information to client tooling like [telescope](https://github.com/cosmology-tech/telescope) on how to encode and decode protobuf messages.\n\n```proto\noption (cosmos_proto.implements_interface) = \"cosmos.auth.v1beta1.AccountI\";\n</code></pre>"},{"location":"guides/tools/cosmos-proto/#methodfieldmessage-added-in","title":"Method,Field,Message Added In","text":"<p><code>method_added_in</code>, <code>field_added_in</code> and <code>message_added_in</code> are annotations to denotate to clients that a field has been supported in a later version. This is useful when new methods or fields are added in later versions and that the client needs to be aware of what it can call.</p> <p>The annotation should be worded as follow:</p> <pre><code>option (cosmos_proto.method_added_in) = \"cosmos-sdk v0.50.1\";\noption (cosmos_proto.method_added_in) = \"x/epochs v1.0.0\";\noption (cosmos_proto.method_added_in) = \"simapp v24.0.0\";\n</code></pre>"},{"location":"guides/tools/cosmos-proto/#amino","title":"Amino","text":"<p>The amino codec was removed in <code>v0.50+</code>, this means there is not a need register <code>legacyAminoCodec</code>. To replace the amino codec, Amino protobuf annotations are used to provide information to the amino codec on how to encode and decode protobuf messages.</p> <p>:::note Amino annotations are only used for backwards compatibility with amino. New modules are not required use amino annotations. :::</p> <p>The below annotations are used to provide information to the amino codec on how to encode and decode protobuf messages in a backwards compatible manner.</p>"},{"location":"guides/tools/cosmos-proto/#name","title":"Name","text":"<p>Name specifies the amino name that would show up for the user in order for them see which message they are signing.</p> <pre><code>option (amino.name) = \"cosmos-sdk/BaseAccount\";\n</code></pre> <p>```proto reference https://github.com/cosmos/cosmos-sdk/blob/e8f28bf5db18b8d6b7e0d94b542ce4cf48fed9d6/proto/cosmos/bank/v1beta1/tx.proto#L41</p> <pre><code>\n### Field_Name\n\nField name specifies the amino name that would show up for the user in order for them see which field they are signing.\n\n```proto\nuint64 height = 1 [(amino.field_name) = \"public_key\"];\n</code></pre> <p>```proto reference https://github.com/cosmos/cosmos-sdk/blob/e8f28bf5db18b8d6b7e0d94b542ce4cf48fed9d6/proto/cosmos/distribution/v1beta1/distribution.proto#L166</p> <pre><code>\n### Dont_OmitEmpty\n\nDont omitempty specifies that the field should not be omitted when encoding to amino.\n\n```proto\nrepeated cosmos.base.v1beta1.Coin amount = 3 [(amino.dont_omitempty)   = true];\n</code></pre> <p>```proto reference https://github.com/cosmos/cosmos-sdk/blob/e8f28bf5db18b8d6b7e0d94b542ce4cf48fed9d6/proto/cosmos/bank/v1beta1/bank.proto#L56</p> <pre><code>\n### Encoding\n\nEncoding instructs the amino json marshaler how to encode certain fields that may differ from the standard encoding behaviour. The most common example of this is how `repeated cosmos.base.v1beta1.Coin` is encoded when using the amino json encoding format. The `legacy_coins` option tells the json marshaler [how to encode a null slice](https://github.com/cosmos/cosmos-sdk/blob/e8f28bf5db18b8d6b7e0d94b542ce4cf48fed9d6/x/tx/signing/aminojson/json_marshal.go#L65) of `cosmos.base.v1beta1.Coin`.\n\n```proto\n(amino.encoding)         = \"legacy_coins\",\n</code></pre> <p>```proto reference https://github.com/cosmos/cosmos-sdk/blob/e8f28bf5db18b8d6b7e0d94b542ce4cf48fed9d6/proto/cosmos/bank/v1beta1/genesis.proto#L23</p> <pre><code>\nAnother example is a protobuf `bytes` that contains a valid JSON document.\nThe `inline_json` option tells the json marshaler to embed the JSON bytes into the wrapping document without escaping.\n\n```proto\n(amino.encoding)         = \"inline_json\",\n</code></pre> <p>E.g. the bytes containing <code>{\"foo\":123}</code> in the <code>envelope</code> field would lead to the following JSON:</p> <pre><code>{\n  \"envelope\": {\n    \"foo\": 123\n  }\n}\n</code></pre> <p>If the bytes are not valid JSON, this leads to JSON broken documents. Thus a JSON validity check needs to be in place at some point of the process.</p>"},{"location":"guides/tools/cosmos-rfc/","title":"RFC 004: Account System Refactor","text":""},{"location":"guides/tools/cosmos-rfc/#status","title":"Status","text":"<ul> <li>Draft v2 (May 2023)</li> </ul>"},{"location":"guides/tools/cosmos-rfc/#current-limitations","title":"Current Limitations","text":"<ol> <li>Account Representation: Limited by <code>google.Protobuf.Any</code> encapsulation and basic authentication methods</li> <li>Interface Constraints: Lacks support for advanced functionalities like vesting and complex auth systems</li> <li>Implementation Rigidity: Poor differentiation between account types (e.g., <code>ModuleAccount</code>)</li> <li>Authorization System: Basic <code>x/auth</code> module with limited scope beyond <code>x/bank</code> functionality</li> <li>Dependency Issues: Cyclic dependencies between modules (e.g., <code>x/auth</code> \u2194 <code>x/bank</code> for vesting)</li> </ol>"},{"location":"guides/tools/cosmos-rfc/#proposal","title":"Proposal","text":"<p>This proposal aims to transform the way accounts are managed within the Cosmos SDK by introducing significant changes to their structure and functionality.</p>"},{"location":"guides/tools/cosmos-rfc/#rethinking-account-representation-and-business-logic","title":"Rethinking Account Representation and Business Logic","text":"<p>Instead of representing accounts as simple <code>google.Protobuf.Any</code> structures stored in state with no business logic attached, this proposal suggests a more sophisticated account representation that is closer to module entities. In fact, accounts should be able to receive messages and process them in the same way modules do, and be capable of storing state in a isolated (prefixed) portion of state belonging only to them, in the same way as modules do.</p>"},{"location":"guides/tools/cosmos-rfc/#account-message-reception","title":"Account Message Reception","text":"<p>We propose that accounts should be able to receive messages in the same way modules can, allowing them to manage their own state modifications without relying on other modules. This change would enable more advanced account functionality, such as the <code>VestingAccount</code> example, where the x/bank module previously needed to change the vestingState by casting the abstracted account to <code>VestingAccount</code> and triggering the <code>TrackDelegation</code> call. Accounts are already capable of sending messages when a state transition, originating from a transaction, is executed.</p> <p>When accounts receive messages, they will be able to identify the sender of the message and decide how to process the state transition, if at all.</p>"},{"location":"guides/tools/cosmos-rfc/#consequences","title":"Consequences","text":"<p>These changes would have significant implications for the Cosmos SDK, resulting in a system of actors that are equal from the runtime perspective. The runtime would only be responsible for propagating messages between actors and would not manage the authorization system. Instead, actors would manage their own authorizations. For instance, there would be no need for the <code>x/auth</code> module to manage minting or burning of coins permissions, as it would fall within the scope of the <code>x/bank</code> module.</p> <p>The key difference between accounts and modules would lie in the origin of the message (state transition). Accounts (ExternallyOwnedAccount), which have credentials (e.g., a public/private key pairing), originate state transitions from transactions. In contrast, module state transitions do not have authentication credentials backing them and can be caused by two factors: either as a consequence of a state transition coming from a transaction or triggered by a scheduler (e.g., the runtime's Begin/EndBlock).</p> <p>By implementing these proposed changes, the Cosmos SDK will benefit from a more extensible, versatile, and efficient account management system that is better suited to address the requirements of the Cosmos ecosystem.</p>"},{"location":"guides/tools/cosmos-rfc/#standardization","title":"Standardization","text":"<p>With <code>x/accounts</code> allowing a modular api there becomes a need for standardization of accounts or the interfaces wallets and other clients should expect to use. For this reason we will be using the <code>CIP</code> repo in order to standardize interfaces in order for wallets to know what to expect when interacting with accounts.</p>"},{"location":"guides/tools/cosmos-rfc/#implementation","title":"Implementation","text":""},{"location":"guides/tools/cosmos-rfc/#account-definition","title":"Account Definition","text":"<p>We define the new <code>Account</code> type, which is what an account needs to implement to be treated as such. An <code>Account</code> type is defined at APP level, so it cannot be dynamically loaded as the chain is running without upgrading the node code, unless we create something like a <code>CosmWasmAccount</code> which is an account backed by an <code>x/wasm</code> contract.</p> <pre><code>// Account is what the developer implements to define an account.\ntype Account[InitMsg proto.Message] interface {\n    // Init is the function that initialises an account instance of a given kind.\n    // InitMsg is used to initialise the initial state of an account.\n    Init(ctx *Context, msg InitMsg) error\n    // RegisterExecuteHandlers registers an account's execution messages.\n    RegisterExecuteHandlers(executeRouter *ExecuteRouter)\n    // RegisterQueryHandlers registers an account's query messages.\n    RegisterQueryHandlers(queryRouter *QueryRouter)\n    // RegisterMigrationHandlers registers an account's migration messages.\n    RegisterMigrationHandlers(migrationRouter *MigrationRouter)\n}\n</code></pre>"},{"location":"guides/tools/cosmos-rfc/#the-internalaccount-definition","title":"The InternalAccount definition","text":"<p>The public <code>Account</code> interface implementation is then converted by the runtime into an <code>InternalAccount</code> implementation, which contains all the information and business logic needed to operate the account.</p> <pre><code>type Schema struct {\n    state StateSchema // represents the state of an account\n    init InitSchema // represents the init msg schema\n    exec ExecSchema // represents the multiple execution msg schemas, containing also responses\n    query QuerySchema // represents the multiple query msg schemas, containing also responses\n    migrate *MigrateSchema // represents the multiple migrate msg schemas, containing also responses, it's optional\n}\n\ntype InternalAccount struct {\n    init    func(ctx *Context, msg proto.Message) (*InitResponse, error)\n    execute func(ctx *Context, msg proto.Message) (*ExecuteResponse, error)\n    query   func(ctx *Context, msg proto.Message) (proto.Message, error)\n    schema  func() *Schema\n    migrate func(ctx *Context, msg proto.Message) (*MigrateResponse, error)\n}\n</code></pre> <p>This is an internal view of the account as intended by the system. It is not meant to be what developers implement. An example implementation of the <code>InternalAccount</code> type can be found in this example of account whose credentials can be recovered. In fact, even if the <code>Internal</code> implementation is untyped (with respect to <code>proto.Message</code>), the concrete implementation is fully typed.</p> <p>During any of the execution methods of <code>InternalAccount</code>, <code>schema</code> excluded, the account is given a <code>Context</code> which provides:</p> <ul> <li>A namespaced <code>KVStore</code> for the account, which isolates the account state from others (NOTE: no <code>store keys</code> needed,   the account address serves as <code>store key</code>).</li> <li>Information regarding itself (its address)</li> <li>Information regarding the sender.</li> <li>...</li> </ul>"},{"location":"guides/tools/cosmos-rfc/#init","title":"Init","text":"<p>Init defines the entrypoint that allows for a new account instance of a given kind to be initialised. The account is passed some opaque protobuf message which is then interpreted and contains the instructions that constitute the initial state of an account once it is deployed.</p> <p>An <code>Account</code> code can be deployed multiple times through the <code>Init</code> function, similar to how a <code>CosmWasm</code> contract code can be deployed (Instantiated) multiple times.</p>"},{"location":"guides/tools/cosmos-rfc/#execute","title":"Execute","text":"<p>Execute defines the entrypoint that allows an <code>Account</code> to process a state transition, the account can decide then how to process the state transition based on the message provided and the sender of the transition.</p>"},{"location":"guides/tools/cosmos-rfc/#query","title":"Query","text":"<p>Query defines a read-only entrypoint that provides a stable interface that links an account with its state. The reason for which <code>Query</code> is still being preferred as an addition to raw state reflection is to:</p> <ul> <li>Provide a stable interface for querying (state can be optimised and change more frequently than a query)</li> <li>Provide a way to define an account <code>Interface</code> with respect to its <code>Read/Write</code> paths.</li> <li>Provide a way to query information that cannot be processed from raw state reflection, ex: compute information from lazy   state that has not been yet concretely processed (eg: balances with respect to lazy inputs/outputs)</li> </ul>"},{"location":"guides/tools/cosmos-rfc/#schema","title":"Schema","text":"<p>Schema provides the definition of an account from <code>API</code> perspective, and it's the only thing that should be taken into account when interacting with an account from another account or module, for example: an account is an <code>authz-interface</code> account if it has the following message in its execution messages <code>MsgProxyStateTransition{ state_transition: google.Protobuf.Any }</code>.</p>"},{"location":"guides/tools/cosmos-rfc/#migrate","title":"Migrate","text":"<p>Migrate defines the entrypoint that allows an <code>Account</code> to migrate its state from a previous version to a new one. Migrations can be initiated only by the account itself, concretely this means that the migrate action sender can only be the account address itself, if the account wants to allow another address to migrate it on its behalf then it could create an execution message that makes the account migrate itself.</p>"},{"location":"guides/tools/cosmos-rfc/#xaccounts-module","title":"x/accounts module","text":"<p>In order to create accounts we define a new module <code>x/accounts</code>, note that <code>x/accounts</code> deploys account with no authentication credentials attached to it which means no action of an account can be incepted from a TX, we will later explore how the <code>x/authn</code> module uses <code>x/accounts</code> to deploy authenticated accounts.</p> <p>This also has another important implication for which account addresses are now fully decoupled from the authentication mechanism which makes in turn off-chain operations a little more complex, as the chain becomes the real link between account identifier and credentials.</p> <p>We could also introduce a way to deterministically compute the account address.</p> <p>Note, from the transaction point of view, the <code>init_message</code> and <code>execute_message</code> are opaque <code>google.Protobuf.Any</code>.</p> <p>The module protobuf definition for <code>x/accounts</code> are the following:</p> <pre><code>// Msg defines the Msg service.\nservice Msg {\n  rpc Deploy(MsgDeploy) returns (MsgDeployResponse);\n  rpc Execute(MsgExecute) returns (MsgExecuteResponse);\n  rpc Migrate(MsgMigrate) returns (MsgMigrateResponse);\n}\n\nmessage MsgDeploy {\n  string sender = 1;\n  string kind = 2;\n  google.Protobuf.Any init_message = 3;\n  repeated google.Protobuf.Any authorize_messages = 4 [(gogoproto.nullable) = false];\n}\n\nmessage MsgDeployResponse {\n  string address = 1;\n  uint64 id = 2;\n  google.Protobuf.Any data = 3;\n}\n\nmessage MsgExecute {\n  string sender = 1;\n  string address = 2;\n  google.Protobuf.Any message = 3;\n  repeated google.Protobuf.Any authorize_messages = 4 [(gogoproto.nullable) = false];\n}\n\nmessage MsgExecuteResponse {\n  google.Protobuf.Any data = 1;\n}\n\nmessage MsgMigrate {\n  string sender = 1;\n  string new_account_kind = 2;\n  google.Protobuf.Any migrate_message = 3;\n}\n\nmessage MsgMigrateResponse {\n  google.Protobuf.Any data = 1;\n}\n\n</code></pre>"},{"location":"guides/tools/cosmos-rfc/#msgdeploy","title":"MsgDeploy","text":"<p>Deploys a new instance of the given account <code>kind</code> with initial settings represented by the <code>init_message</code> which is a <code>google.Protobuf.Any</code>. Of course the <code>init_message</code> can be empty. A response is returned containing the account ID and humanised address, alongside some response that the account instantiation might produce.</p>"},{"location":"guides/tools/cosmos-rfc/#address-derivation","title":"Address derivation","text":"<p>In order to decouple public keys from account addresses, we introduce a new address derivation mechanism which is</p>"},{"location":"guides/tools/cosmos-rfc/#msgexecute","title":"MsgExecute","text":"<p>Sends a <code>StateTransition</code> execution request, where the state transition is represented by the <code>message</code> which is a <code>google.Protobuf.Any</code>. The account can then decide if to process it or not based on the <code>sender</code>.</p>"},{"location":"guides/tools/cosmos-rfc/#msgmigrate","title":"MsgMigrate","text":"<p>Migrates an account to a new version of itself, the new version is represented by the <code>new_account_kind</code>. The state transition can only be incepted by the account itself, which means that the <code>sender</code> must be the account address itself. During the migration the account current state is given to the new version of the account, which then executes the migration logic using the <code>migrate_message</code>, it might change state or not, it's up to the account to decide. The response contains possible data that the account might produce after the migration.</p>"},{"location":"guides/tools/cosmos-rfc/#authorize-messages","title":"Authorize Messages","text":"<p>The <code>Deploy</code> and <code>Execute</code> messages have a field in common called <code>authorize_messages</code>, these messages are messages that the account can execute on behalf of the sender. For example, in case an account is expecting some funds to be sent from the sender, the sender can attach a <code>MsgSend</code> that the account can execute on the sender's behalf. These authorizations are short-lived, they live only for the duration of the <code>Deploy</code> or <code>Execute</code> message execution, or until they are consumed.</p> <p>An alternative would have been to add a <code>funds</code> field, like it happens in cosmwasm, which guarantees the called contract that the funds are available and sent in the context of the message execution. This would have been a simpler approach, but it would have been limited to the context of <code>MsgSend</code> only, where the asset is <code>sdk.Coins</code>. The proposed generic way, instead, allows the account to execute any message on behalf of the sender, which is more flexible, it could include NFT send execution, or more complex things like <code>MsgMultiSend</code> or <code>MsgDelegate</code>, etc.</p>"},{"location":"guides/tools/cosmos-rfc/#further-discussion","title":"Further discussion","text":""},{"location":"guides/tools/cosmos-rfc/#sub-accounts","title":"Sub-accounts","text":"<p>We could provide a way to link accounts to other accounts. Maybe during deployment the sender could decide to link the newly created to its own account, although there might be use-cases for which the deployer is different from the account that needs to be linked, in this case a handshake protocol on linking would need to be defined.</p>"},{"location":"guides/tools/cosmos-rfc/#predictable-address-creation","title":"Predictable address creation","text":"<p>We need to provide a way to create an account with a predictable address, this might serve a lot of purposes, like accounts wanting to generate an address that:</p> <ul> <li>nobody else can claim besides the account used to generate the new account</li> <li>is predictable</li> </ul> <p>For example:</p> <pre><code>\nmessage MsgDeployPredictable {\n  string sender = 1;\n  uint32 nonce = 2;\n  ...\n}\n</code></pre> <p>And then the address becomes <code>bechify(concat(sender, nonce))</code></p> <p><code>x/accounts</code> would still use the monotonically increasing sequence as account number.</p>"},{"location":"guides/tools/cosmos-rfc/#joining-multiple-accounts","title":"Joining Multiple Accounts","text":"<p>As developers are building new kinds of accounts, it becomes necessary to provide a default way to combine the functionalities of different account types. This allows developers to avoid duplicating code and enables end-users to create or migrate to accounts with multiple functionalities without requiring custom development.</p> <p>To address this need, we propose the inclusion of a default account type called \"MultiAccount\". The MultiAccount type is designed to merge the functionalities of other accounts by combining their execution, query, and migration APIs. The account joining process would only fail in the case of API (intended as non-state Schema APIs) conflicts, ensuring compatibility and consistency.</p> <p>With the introduction of the MultiAccount type, users would have the option to either migrate their existing accounts to a MultiAccount type or extend an existing MultiAccount with newer APIs. This flexibility empowers users to leverage various account functionalities without compromising compatibility or resorting to manual code duplication.</p> <p>The MultiAccount type serves as a standardized solution for combining different account functionalities within the cosmos-sdk ecosystem. By adopting this approach, developers can streamline the development process and users can benefit from a modular and extensible account system.</p>"},{"location":"guides/tools/cosmos-rfc/#adr-071-cryptography-v2-multi-curve-support","title":"ADR 071: Cryptography v2- Multi-curve support","text":""},{"location":"guides/tools/cosmos-rfc/#change-log","title":"Change log","text":"<ul> <li>May 7th 2024: Initial Draft (Zondax AG: @raynaudoe @juliantoledano @jleni @educlerici-zondax @lucaslopezf)</li> <li>June 13th 2024: Add CometBFT implementation proposal (Zondax AG: @raynaudoe @juliantoledano @jleni @educlerici-zondax @lucaslopezf)</li> <li>July 2nd 2024: Split ADR proposal, add link to ADR in cosmos/crypto (Zondax AG: @raynaudoe @juliantoledano @jleni @educlerici-zondax @lucaslopezf)</li> </ul>"},{"location":"guides/tools/cosmos-rfc/#status_1","title":"Status","text":"<p>DRAFT</p>"},{"location":"guides/tools/cosmos-rfc/#abstract","title":"Abstract","text":"<p>This ADR proposes the refactoring of the existing <code>Keyring</code> and <code>cosmos-sdk/crypto</code> code to implement ADR-001-CryptoProviders.</p> <p>For in-depth details of the <code>CryptoProviders</code> and their design please refer to ADR mentioned above.</p>"},{"location":"guides/tools/cosmos-rfc/#introduction","title":"Introduction","text":"<p>The introduction of multi-curve support in the cosmos-sdk cryptographic package offers significant advantages. By not being restricted to a single cryptographic curve, developers can choose the most appropriate curve based on security, performance, and compatibility requirements. This flexibility enhances the application's ability to adapt to evolving security standards and optimizes performance for specific use cases, helping to future-proofing the sdk's cryptographic capabilities.</p> <p>The enhancements in this proposal not only render the \"Keyring ADR\" obsolete, but also encompass its key aspects, replacing it with a more flexible and comprehensive approach. Furthermore, the gRPC service proposed in the mentioned ADR can be easily implemented as a specialized <code>CryptoProvider</code>.</p>"},{"location":"guides/tools/cosmos-rfc/#glossary","title":"Glossary","text":"<ol> <li> <p>Interface: In the context of this document, \"interface\" refers to Go's interface.</p> </li> <li> <p>Module: In this document, \"module\" refers to a Go module.</p> </li> <li> <p>Package: In the context of Go, a \"package\" refers to a unit of code organization.</p> </li> </ol>"},{"location":"guides/tools/cosmos-rfc/#context","title":"Context","text":"<p>In order to fully understand the need for changes and the proposed improvements, it's crucial to consider the current state of affairs:</p> <ul> <li> <p>The Cosmos SDK currently lacks a comprehensive ADR for the cryptographic package.</p> </li> <li> <p>If a blockchain project requires a cryptographic curve that is not supported by the current SDK, the most likely scenario is that they will need to fork the SDK repository and make modifications. These modifications could potentially make the fork incompatible with future updates from the upstream SDK, complicating maintenance and integration.</p> </li> <li> <p>Type leakage of specific crypto data types expose backward compatibility and extensibility challenges.</p> </li> <li> <p>The demand for a more flexible and extensible approach to cryptography and address management is high.</p> </li> <li> <p>Architectural changes are necessary to resolve many of the currently open issues related to new curves support.</p> </li> <li> <p>There is a current trend towards modularity in the Interchain stack (e.g., runtime modules).</p> </li> <li> <p>Security implications are a critical consideration during the redesign work.</p> </li> </ul>"},{"location":"guides/tools/cosmos-rfc/#objectives","title":"Objectives","text":"<p>The key objectives for this proposal are:</p> <ul> <li>Leverage <code>CryptoProviders</code>: Utilize them as APIs for cryptographic tools, ensuring modularity, flexibility, and ease of integration.</li> </ul> <p>Developer-Centric Approach</p> <ul> <li>Prioritize clear, intuitive interfaces and best-practice design principles.</li> </ul> <p>Quality Assurance</p> <ul> <li>Enhanced Test Coverage: Improve testing methodologies to ensure the robustness and reliability of the module.</li> </ul>"},{"location":"guides/tools/cosmos-rfc/#technical-goals","title":"Technical Goals","text":"<p>New Keyring:</p> <ul> <li>Design a new <code>Keyring</code> interface with modular backends injection system to support hardware devices and cloud-based HSMs. This feature is optional and tied to complexity; if it proves too complex, it will be deferred to a future release as an enhancement.</li> </ul>"},{"location":"guides/tools/cosmos-rfc/#proposed-architecture","title":"Proposed architecture","text":""},{"location":"guides/tools/cosmos-rfc/#components","title":"Components","text":"<p>The main components to be used will be the same as those found in the ADR-001.</p>"},{"location":"guides/tools/cosmos-rfc/#storage-and-persistence","title":"Storage and persistence","text":"<p>The storage and persistence layer is tasked with storing a <code>CryptoProvider</code>s. Specifically, this layer must:</p> <ul> <li>Securely store the crypto provider's associated private key (only if stored locally, otherwise a reference to the private key will be stored instead).</li> <li>Store the <code>ProviderMetadata</code> struct which contains the data that distinguishes that provider.</li> </ul> <p>The purpose of this layer is to ensure that upon retrieval of the persisted data, we can access the provider's type, version, and specific configuration (which varies based on the provider type). This information will subsequently be utilized to initialize the appropriate factory, as detailed in the following section on the factory pattern.</p> <p>The storage proposal involves using a modified version of the Record struct, which is already defined in Keyring/v1. Additionally, we propose utilizing the existing keyring backends (keychain, filesystem, memory, etc.) to store these <code>Record</code>s in the same manner as the current Keyring/v1.</p> <p>Note: This approach will facilitate a smoother migration path from the current Keyring/v1 to the proposed architecture.</p> <p>Below is the proposed protobuf message to be included in the modified <code>Record.proto</code> file</p>"},{"location":"guides/tools/cosmos-rfc/#protobuf-message-structure","title":"Protobuf message structure","text":"<p>The record.proto file will be modified to include the <code>CryptoProvider</code> message as an optional field as follows.</p> <pre><code>\n// record.proto\n\nmessage Record {\n  string name = 1;\n  google.protobuf.Any pub_key = 2;\n\n  oneof item {\n    Local local = 3;\n    Ledger ledger = 4;\n    Multi multi = 5;\n    Offline offline = 6;\n    CryptoProvider crypto_provider = 7; // &lt;- New\n  }\n\n  message Local {\n    google.protobuf.Any priv_key = 1;\n  }\n\n  message Ledger {\n    hd.v1.BIP44Params path = 1;\n  }\n\n  message Multi {}\n\n  message Offline {}\n}\n</code></pre>"},{"location":"guides/tools/cosmos-rfc/#creating-and-loading-a-cryptoprovider","title":"Creating and loading a <code>CryptoProvider</code>","text":"<p>For creating providers, we propose a factory pattern and a registry for these builders. Examples of these patterns can be found here</p>"},{"location":"guides/tools/cosmos-rfc/#keyring","title":"Keyring","text":"<p>The new <code>Keyring</code> interface will serve as a central hub for managing and fetching <code>CryptoProviders</code>. To ensure a smoother migration path, the new Keyring will be backward compatible with the previous version. Since this will be the main API from which applications will obtain their <code>CryptoProvider</code> instances, the proposal is to extend the Keyring interface to include the methods:</p> <pre><code>type KeyringV2 interface {\n  // methods from Keyring/v1\n\n  // ListCryptoProviders returns a list of all the stored CryptoProvider metadata.\n  ListCryptoProviders() ([]ProviderMetadata, error)\n\n  // GetCryptoProvider retrieves a specific CryptoProvider by its id.\n  GetCryptoProvider(id string) (CryptoProvider, error)\n}\n</code></pre> <p>Note: Methods to obtain a provider from a public key or other means that make it easier to load the desired provider can be added.</p>"},{"location":"guides/tools/cosmos-rfc/#especial-use-case-remote-signers","title":"Especial use case: remote signers","text":"<p>It's important to note that the <code>CryptoProvider</code> interface is versatile enough to be implemented as a remote signer. This capability allows for the integration of remote cryptographic operations, which can be particularly useful in distributed or cloud-based environments where local cryptographic resources are limited or need to be managed centrally.</p>"},{"location":"guides/tools/cosmos-rfc/#alternatives","title":"Alternatives","text":"<p>It is important to note that all the code presented in this document is not in its final form and could be subject to changes at the time of implementation. The examples and implementations discussed should be interpreted as alternatives, providing a conceptual framework rather than definitive solutions. This flexibility allows for adjustments based on further insights, technical evaluations, or changing requirements as development progresses.</p>"},{"location":"guides/tools/cosmos-rfc/#decision","title":"Decision","text":"<p>We will:</p> <ul> <li>Leverage crypto providers</li> <li>Refactor the module structure as described above.</li> <li>Define types and interfaces as the code attached.</li> <li>Refactor existing code into new structure and interfaces.</li> <li>Implement Unit Tests to ensure no backward compatibility issues.</li> </ul>"},{"location":"guides/tools/cosmos-rfc/#consequences_1","title":"Consequences","text":""},{"location":"guides/tools/cosmos-rfc/#impact-on-the-sdk-codebase","title":"Impact on the SDK codebase","text":"<p>We can divide the impact of this ADR into two main categories: state machine code and client related code.</p>"},{"location":"guides/tools/cosmos-rfc/#client","title":"Client","text":"<p>The major impact will be on the client side, where the current <code>Keyring</code> interface will be replaced by the new <code>KeyringV2</code> interface. At first, the impact will be low since <code>CryptoProvider</code> is an optional field in the <code>Record</code> message, so there's no mandatory requirement for migrating to this new concept right away. This allows a progressive transition where the risks of breaking changes or regressions are minimized.</p>"},{"location":"guides/tools/cosmos-rfc/#state-machine","title":"State Machine","text":"<p>The impact on the state machine code will be minimal, the modules affected (at the time of writing this ADR) are the <code>x/accounts</code> module, specifically the <code>Authenticate</code> function and the <code>x/auth/ante</code> module. This function will need to be adapted to use a <code>CryptoProvider</code> service to make use of the <code>Verifier</code> instance.</p> <p>Worth mentioning that there's also the alternative of using <code>Verifier</code> instances in a standalone fashion (see note below).</p> <p>The specific way to adapt these modules will be deeply analyzed and decided at implementation time of this ADR.</p> <p>Note: All cryptographic tools (hashers, verifiers, signers, etc.) will continue to be available as standalone packages that can be imported and utilized directly without the need for a <code>CryptoProvider</code> instance. However, the <code>CryptoProvider</code> is the recommended method for using these tools as it offers a more secure way to handle sensitive data, enhanced modularity, and the ability to store configurations and metadata within the <code>CryptoProvider</code> definition.</p>"},{"location":"guides/tools/cosmos-rfc/#backwards-compatibility","title":"Backwards Compatibility","text":"<p>The proposed migration path is similar to what the cosmos-sdk has done in the past. To ensure a smooth transition, the following steps will be taken:</p> <p>Once ADR-001 is implemented with a stable release:</p> <ul> <li>Deprecate the old crypto package. The old crypto package will still be usable, but it will be marked as deprecated and users can opt to use the new package.</li> <li>Migrate the codebase to use the new cosmos/crypto package and remove the old crypto one.</li> </ul>"},{"location":"guides/tools/cosmos-rfc/#positive","title":"Positive","text":"<ul> <li>Single place of truth</li> <li>Easier to use interfaces</li> <li>Easier to extend</li> <li>Unit test for each crypto package</li> <li>Greater maintainability</li> <li>Incentivize addition of implementations instead of forks</li> <li>Decoupling behavior from implementation</li> <li>Sanitization of code</li> </ul>"},{"location":"guides/tools/cosmos-rfc/#negative","title":"Negative","text":"<ul> <li>It will involve an effort to adapt existing code.</li> <li>It will require attention to detail and audition.</li> </ul>"},{"location":"guides/tools/cosmos-rfc/#neutral","title":"Neutral","text":"<ul> <li>It will involve extensive testing.</li> </ul>"},{"location":"guides/tools/cosmos-rfc/#test-cases","title":"Test Cases","text":"<ul> <li>The code will be unit tested to ensure a high code coverage</li> <li>There should be integration tests around Keyring and CryptoProviders.</li> </ul> <p>While an ADR is in the DRAFT or PROPOSED stage, this section should contain a summary of issues to be solved in future iterations (usually referencing comments from a pull-request discussion).</p> <p>Later, this section can optionally list ideas or improvements the author or reviewers found during the analysis of this ADR.</p>"},{"location":"guides/tools/cosmos-rfc/#adr-71-bank-v2","title":"ADR-71 Bank V2","text":""},{"location":"guides/tools/cosmos-rfc/#status_2","title":"Status","text":"<p>DRAFT</p>"},{"location":"guides/tools/cosmos-rfc/#changelog","title":"Changelog","text":"<ul> <li>2024-05-08: Initial Draft (@samricotta, @julienrbrt)</li> </ul>"},{"location":"guides/tools/cosmos-rfc/#abstract_1","title":"Abstract","text":"<p>The primary objective of refactoring the bank module is to simplify and enhance the functionality of the Cosmos SDK. Over time the bank module has been burdened with numerous responsibilities including transaction handling, account restrictions, delegation counting, and the minting and burning of coins.</p> <p>In addition to the above, the bank module is currently too rigid and handles too many tasks, so this proposal aims to streamline the module by focusing on core functions <code>Send</code>, <code>Mint</code>, and <code>Burn</code>.</p> <p>Currently, the module is split across different keepers with scattered and duplicates functionalities (with 4 send functions for instance).</p> <p>Additionally, the integration of the token factory into the bank module allows for standardization, and better integration within the core modules.</p> <p>This rewrite will reduce complexity and enhance the efficiency and UX of the bank module.</p>"},{"location":"guides/tools/cosmos-rfc/#context_1","title":"Context","text":"<p>The current implementation of the bank module is characterised by its handling of a broad array of functions, leading to significant complexity in using and extending the bank module.</p> <p>These issues have underscored the need for a refactoring strategy that simplifies the module\u2019s architecture and focuses on its most essential operations.</p> <p>Additionally, there is an overlap in functionality with a Token Factory module, which could be integrated to streamline oper.</p>"},{"location":"guides/tools/cosmos-rfc/#decision_1","title":"Decision","text":"<p>Permission Tightening: Access to the module can be restricted to selected denominations only, ensuring that it operates within designated boundaries and does not exceed its intended scope. Currently, the permissions allow all denoms, so this should be changed. Send restrictions functionality will be maintained.</p> <p>Simplification of Logic: The bank module will focus on core functionalities <code>Send</code>, <code>Mint</code>, and <code>Burn</code>. This refinement aims to streamline the architecture, enhancing both maintainability and performance.</p> <p>Integration of Token Factory: The Token Factory will be merged into the bank module. This consolidation of related functionalities aims to reduce redundancy and enhance coherence within the system. Migrations functions will be provided for migrating from Osmosis' Token Factory module to bank/v2.</p> <p>Legacy Support: A legacy wrapper will be implemented to ensure compatibility with about 90% of existing functions. This measure will facilitate a smooth transition while keeping older systems functional.</p> <p>Denom Implementation: A asset interface will be added to standardise interactions such as transfers, balance inquiries, minting, and burning across different tokens. This will allow the bank module to support arbitrary asset types, enabling developers to implement custom, ERC20-like denominations.</p> <p>For example, currently if a team would like to extend the transfer method the changes would apply universally, affecting all denom\u2019s. With the proposed Asset Interface, it allows teams to customise or extend the transfer method specifically for their own tokens without impacting others.</p> <p>These improvements are expected to enhance the flexibility of the bank module, allowing for the creation of custom tokens similar to ERC20 standards and assets backed by CosmWasm (CW) contracts. The integration efforts will also aim to unify CW20 with bank coins across the Cosmos chains.</p> <p>Example of denom interface:</p> <pre><code>type AssetInterface interface {\n    Transfer(ctx sdk.Context, from sdk.AccAddress, to sdk.AccAddress, amount sdk.Coin) error\n    Mint(ctx sdk.Context, to sdk.AccAddress, amount sdk.Coin) error\n    Burn(ctx sdk.Context, from sdk.AccAddress, amount sdk.Coin) error\n    QueryBalance(ctx sdk.Context, account sdk.AccAddress) (sdk.Coin, error)\n}\n</code></pre> <p>Overview of flow:</p> <ol> <li>Alice initiates a transfer by entering Bob's address and the amount (100 ATOM)</li> <li>The Bank module verifies that the ATOM token implements the <code>AssetInterface</code> by querying the <code>ATOM_Denom_Account</code>, which is an <code>x/account</code> denom account.</li> <li>The Bank module executes the transfer by subtracting 100 ATOM from Alice\u2019s balance and adding 100 ATOM to Bob\u2019s balance.</li> <li>The Bank module calls the Transfer method on the <code>ATOM_Denom_Account</code>. The Transfer method, defined in the <code>AssetInterface</code>, handles the logic to subtract 100 ATOM from Alice\u2019s balance and add 100 ATOM to Bob\u2019s balance.</li> <li>The Bank module updates the chain and returns the new balances.</li> <li>Both Alice and Bob successfully receive the updated balances.</li> </ol>"},{"location":"guides/tools/cosmos-rfc/#migration-plans","title":"Migration Plans","text":"<p>Bank is a widely used module, so getting a v2 needs to be thought thoroughly. In order to not force all dependencies to immediately migrate to bank/v2, the same upgrading path will be taken as for the <code>gov</code> module.</p> <p>This means <code>cosmossdk.io/bank</code> will stay one module and there won't be a new <code>cosmossdk.io/bank/v2</code> go module. Instead the bank protos will be versioned from <code>v1beta1</code> (current bank) to <code>v2</code>.</p> <p>Bank <code>v1beta1</code> endpoints will use the new bank v2 implementation for maximum backward compatibility.</p> <p>The bank <code>v1beta1</code> keepers will be deprecated and potentially eventually removed, but its proto and messages definitions will remain.</p> <p>Additionally, as bank plans to integrate token factory, migrations functions will be provided to migrate from Osmosis token factory implementation (most widely used implementation) to the new bank/v2 token factory.</p>"},{"location":"guides/tools/cosmos-rfc/#consequences_2","title":"Consequences","text":""},{"location":"guides/tools/cosmos-rfc/#positive_1","title":"Positive","text":"<ul> <li>Simplified interaction with bank APIs</li> <li>Backward compatible changes (no contracts or apis broken)</li> <li>Optional migration (note: bank <code>v1beta1</code> won't get any new feature after bank <code>v2</code> release)</li> </ul>"},{"location":"guides/tools/cosmos-rfc/#neutral_1","title":"Neutral","text":"<ul> <li>Asset implementation not available cross-chain (IBC-ed custom asset should possibly fallback to the default implementation)</li> <li>Many assets may slow down bank balances requests</li> </ul>"},{"location":"guides/tools/cosmos-rfc/#negative_1","title":"Negative","text":"<ul> <li>Temporarily duplicate functionalities as bank <code>v1beta1</code> are <code>v2</code> are living alongside</li> <li>Difficultity to ever completely remove bank <code>v1beta1</code></li> </ul>"},{"location":"guides/tools/cosmos-rfc/#references","title":"References","text":"<ul> <li>Current bank module implementation: https://github.com/cosmos/cosmos-sdk/blob/v0.50.6/x/bank/keeper/keeper.go#L22-L53</li> <li>Osmosis token factory: https://github.com/osmosis-labs/osmosis/tree/v25.0.0/x/tokenfactory/keeper</li> </ul>"},{"location":"guides/tools/cosmos-sdk/","title":"Cosmos SDK Core Components","text":""},{"location":"guides/tools/cosmos-sdk/#overview","title":"Overview","text":"<p>The Cosmos SDK is a framework for building secure blockchain applications on CometBFT. It provides:</p> <ul> <li>ABCI implementation in Go</li> <li>Multi-store persistence layer  </li> <li>Transaction routing system</li> </ul>"},{"location":"guides/tools/cosmos-sdk/#transaction-flow","title":"Transaction Flow","text":"<ol> <li>CometBFT consensus delivers transaction bytes</li> <li>SDK decodes transactions and extracts messages</li> <li>Messages routed to appropriate modules</li> <li>State changes committed to stores</li> </ol> <pre><code>graph TD\n    A[CometBFT] --&gt;|Tx Bytes| B[SDK Decode]\n    B --&gt;|Messages| C[Module Router] \n    C --&gt;|State Changes| D[Multi-store]\n</code></pre>"},{"location":"guides/tools/cosmos-sdk/#baseapp","title":"<code>baseapp</code>","text":"<p><code>baseapp</code> is the boilerplate implementation of a Cosmos SDK application. It comes with an implementation of the ABCI to handle the connection with the underlying consensus engine. Typically, a Cosmos SDK application extends <code>baseapp</code> by embedding it in <code>app.go</code>.</p> <p>Here is an example of this from <code>simapp</code>, the Cosmos SDK demonstration app:</p> <p>```go reference https://github.com/cosmos/cosmos-sdk/blob/v0.52.0-beta.1/simapp/app.go#L145-L186</p> <pre><code>\nThe goal of `baseapp` is to provide a secure interface between the store and the extensible state machine while defining as little about the state machine as possible (staying true to the ABCI).\n\nFor more on `baseapp`, please click [here](../advanced/00-baseapp.md).\n\n## Multistore\n\nThe Cosmos SDK provides a [`multistore`](../advanced/04-store.md#multistore) for persisting state. The multistore allows developers to declare any number of [`KVStores`](../advanced/04-store.md#base-layer-kvstores). These `KVStores` only accept the `[]byte` type as value and therefore any custom structure needs to be marshalled using [a codec](../advanced/05-encoding.md) before being stored.\n\nThe multistore abstraction is used to divide the state in distinct compartments, each managed by its own module. For more on the multistore, click [here](../advanced/04-store.md#multistore).\n\n## Modules\n\nThe power of the Cosmos SDK lies in its modularity. Cosmos SDK applications are built by aggregating a collection of interoperable modules. Each module defines a subset of the state and contains its own message/transaction processor, while the Cosmos SDK is responsible for routing each message to its respective module.\n\nHere is a simplified view of how a transaction is processed by the application of each full-node when it is received in a valid block:\n\n```mermaid\n flowchart TD\n    A[Transaction relayed from the full-node's CometBFT engine to the node's application via DeliverTx] --&gt; B[APPLICATION]\n    B --&gt;|\"Using baseapp's methods: Decode the Tx, extract and route the message(s)\"| C[Message routed to the correct module to be processed]\n    C --&gt; D1[AUTH MODULE]\n    C --&gt; D2[BANK MODULE]\n    C --&gt; D3[STAKING MODULE]\n    C --&gt; D4[GOV MODULE]\n    D1 --&gt;|Handle message, Update state| E[\"Return result to CometBFT (0=Ok, 1=Err)\"]\n    D2 --&gt;|Handle message, Update state| E[\"Return result to CometBFT (0=Ok, 1=Err)\"]\n    D3 --&gt;|Handle message, Update state| E[\"Return result to CometBFT (0=Ok, 1=Err)\"]\n    D4 --&gt;|Handle message, Update state| E[\"Return result to CometBFT (0=Ok, 1=Err)\"]\n</code></pre> <p>Each module can be seen as a little state-machine. Developers need to define the subset of the state handled by the module, as well as custom message types that modify the state (Note: <code>messages</code> are extracted from <code>transactions</code> by <code>baseapp</code>). In general, each module declares its own <code>KVStore</code> in the <code>multistore</code> to persist the subset of the state it defines. Most developers will need to access other 3rd party modules when building their own modules. Given that the Cosmos SDK is an open framework, some of the modules may be malicious, which means there is a need for security principles to reason about inter-module interactions. These principles are based on object-capabilities. In practice, this means that instead of having each module keep an access control list for other modules, each module implements special objects called <code>keepers</code> that can be passed to other modules to grant a pre-defined set of capabilities.</p> <p>Cosmos SDK modules are defined in the <code>x/</code> folder of the Cosmos SDK. Some core modules include:</p> <ul> <li><code>x/auth</code>: Used to manage accounts and signatures.</li> <li><code>x/bank</code>: Used to enable tokens and token transfers.</li> <li><code>x/staking</code> + <code>x/slashing</code>: Used to build Proof-of-Stake blockchains.</li> </ul> <p>In addition to the already existing modules in <code>x/</code>, which anyone can use in their app, the Cosmos SDK lets you build your own custom modules. You can check an example of that in the tutorial.# Keepers</p> <p>:::note Synopsis <code>Keeper</code>s refer to a Cosmos SDK abstraction whose role is to manage access to the subset of the state defined by various modules. <code>Keeper</code>s are module-specific, i.e. the subset of state defined by a module can only be accessed by a <code>keeper</code> defined in said module. If a module needs to access the subset of state defined by another module, a reference to the second module's internal <code>keeper</code> needs to be passed to the first one. This is done in <code>app.go</code> during the instantiation of module keepers. :::</p> <p>:::note Pre-requisite Readings</p> <ul> <li>Introduction to Cosmos SDK Modules</li> </ul> <p>:::</p>"},{"location":"guides/tools/cosmos-sdk/#motivation","title":"Motivation","text":"<p>The Cosmos SDK is a framework that makes it easy for developers to build complex decentralized applications from scratch, mainly by composing modules together. As the ecosystem of open-source modules for the Cosmos SDK expands, it will become increasingly likely that some of these modules contain vulnerabilities, as a result of the negligence or malice of their developer.</p> <p>The Cosmos SDK adopts an object-capabilities-based approach to help developers better protect their application from unwanted inter-module interactions, and <code>keeper</code>s are at the core of this approach. A <code>keeper</code> can be considered quite literally to be the gatekeeper of a module's store(s). Each store (typically an <code>IAVL</code> Store) defined within a module comes with a <code>storeKey</code>, which grants unlimited access to it. The module's <code>keeper</code> holds this <code>storeKey</code> (which should otherwise remain unexposed), and defines methods for reading and writing to the store(s).</p> <p>The core idea behind the object-capabilities approach is to only reveal what is necessary to get the work done. In practice, this means that instead of handling permissions of modules through access-control lists, module <code>keeper</code>s are passed a reference to the specific instance of the other modules' <code>keeper</code>s that they need to access (this is done in the application's constructor function). As a consequence, a module can only interact with the subset of state defined in another module via the methods exposed by the instance of the other module's <code>keeper</code>. This is a great way for developers to control the interactions that their own module can have with modules developed by external developers.</p>"},{"location":"guides/tools/cosmos-sdk/#type-definition","title":"Type Definition","text":"<p><code>keeper</code>s are generally implemented in a <code>/keeper/keeper.go</code> file located in the module's folder. By convention, the type <code>keeper</code> of a module is simply named <code>Keeper</code> and usually follows the following structure:</p> <pre><code>type Keeper struct {\n    // External keepers, if any\n\n    // Store key(s)\n\n    // codec\n\n    // authority\n}\n</code></pre> <p>For example, here is the type definition of the <code>keeper</code> from the <code>staking</code> module:</p> <p>```go reference https://github.com/cosmos/cosmos-sdk/blob/v0.52.0-beta.1/x/staking/keeper/keeper.go#L54-L115</p> <pre><code>\nLet us go through the different parameters:\n\n- An expected `keeper` is a `keeper` external to a module that is required by the internal `keeper` of said module. External `keeper`s are listed in the internal `keeper`'s type definition as interfaces. These interfaces are themselves defined in an `expected_keepers.go` file in the root of the module's folder. In this context, interfaces are used to reduce the number of dependencies, as well as to facilitate the maintenance of the module itself.\n- `KVStoreService`s grant access to the store(s) of the [multistore](../../learn/advanced/04-store.md) managed by the module. They should always remain unexposed to external modules.\n- `cdc` is the [codec](../../learn/advanced/05-encoding.md) used to marshal and unmarshal structs to/from `[]byte`. The `cdc` can be any of `codec.BinaryCodec`, `codec.JSONCodec` or `codec.Codec` based on your requirements. It can be either a proto or amino codec as long as they implement these interfaces.\n- The authority listed is a module account or user account that has the right to change module level parameters. Previously this was handled by the param module, which has been deprecated.\n\nOf course, it is possible to define different types of internal `keeper`s for the same module (e.g. a read-only `keeper`). Each type of `keeper` comes with its own constructor function, which is called from the [application's constructor function](../../learn/beginner/00-app-anatomy.md). This is where `keeper`s are instantiated, and where developers make sure to pass correct instances of modules' `keeper`s to other modules that require them.\n\n## Implementing Methods\n\n`Keeper`s primarily expose methods for business logic, as validity checks should have already been performed by the [`Msg` server](./03-msg-services.md) when `keeper`s' methods are called.\n\n&lt;!-- markdown-link-check-disable --&gt;\n\nState management is recommended to be done via [Collections](../packages/collections)\n\n&lt;!-- The above link is created via the script to generate docs  --&gt;\n\n## State Management\n\nIn the Cosmos SDK, it is crucial to be methodical and selective when managing state within a module, as improper state management can lead to inefficiency, security risks, and scalability issues. Not all data belongs in the on-chain state; it's important to store only essential blockchain data that needs to be verified by consensus. Storing unnecessary information, especially client-side data, can bloat the state and slow down performance. Instead, developers should focus on using an off-chain database to handle supplementary data, extending the API as needed. This approach minimizes on-chain complexity, optimizes resource usage, and keeps the blockchain state lean and efficient, ensuring scalability and smooth operations.\n\nThe Cosmos SDK leverages Protocol Buffers (protobuf) for efficient state management, providing a well-structured, binary encoding format that ensures compatibility and performance across different modules. The SDK\u2019s recommended approach for managing state is through the [collections package](../pacakges/02-collections.md), which simplifies state handling by offering predefined data structures like maps and indexed sets, reducing the complexity of managing raw state data. While users can opt for custom encoding schemes if they need more flexibility or have specialized requirements, they should be aware that such custom implementations may not integrate seamlessly with indexers that decode state data on the fly. This could lead to challenges in data retrieval, querying, and interoperability, making protobuf a safer and more future-proof choice for most use cases.\n\n# Folder Structure\n\n:::note Synopsis\nThis document outlines the structure of Cosmos SDK modules. These ideas are meant to be applied as suggestions. Application developers are encouraged to improve upon and contribute to module structure and development design.\n\nThe required interface for a module is located in the module.go. Everything beyond this is suggestive.\n:::\n\n## Structure\n\nA typical Cosmos SDK module can be structured as follows:\n\n```shell\nproto\n\u2514\u2500\u2500 {project_name}\n \u00a0\u00a0 \u2514\u2500\u2500 {module_name}\n \u00a0\u00a0     \u2514\u2500\u2500 {proto_version}\n \u00a0\u00a0  \u00a0\u00a0     \u251c\u2500\u2500 {module_name}.proto\n \u00a0\u00a0  \u00a0\u00a0     \u251c\u2500\u2500 genesis.proto\n \u00a0\u00a0  \u00a0\u00a0     \u251c\u2500\u2500 query.proto\n \u00a0\u00a0  \u00a0\u00a0     \u2514\u2500\u2500 tx.proto\n</code></pre> <ul> <li><code>{module_name}.proto</code>: The module's common message type definitions.</li> <li><code>genesis.proto</code>: The module's message type definitions related to genesis state.</li> <li><code>query.proto</code>: The module's Query service and related message type definitions.</li> <li><code>tx.proto</code>: The module's Msg service and related message type definitions.</li> </ul> <pre><code>x/{module_name}\n\u251c\u2500\u2500 client\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 cli\n\u2502\u00a0\u00a0 \u2502   \u251c\u2500\u2500 query.go\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 tx.go\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 testutil\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 cli_test.go\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 suite.go\n\u251c\u2500\u2500 exported\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 exported.go\n\u251c\u2500\u2500 keeper\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 genesis.go\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 grpc_query.go\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 hooks.go\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 invariants.go\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 keeper.go\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 keys.go\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 msg_server.go\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 querier.go\n\u251c\u2500\u2500 simulation\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 decoder.go\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 genesis.go\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 operations.go\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 params.go\n\u251c\u2500\u2500 types\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 {module_name}.pb.go\n\u2502   \u251c\u2500\u2500 codec.go\n\u2502   \u251c\u2500\u2500 errors.go\n\u2502   \u251c\u2500\u2500 events.go\n\u2502   \u251c\u2500\u2500 events.pb.go\n\u2502   \u251c\u2500\u2500 expected_keepers.go\n\u2502   \u251c\u2500\u2500 genesis.go\n\u2502   \u251c\u2500\u2500 genesis.pb.go\n\u2502   \u251c\u2500\u2500 keys.go\n\u2502   \u251c\u2500\u2500 msgs.go\n\u2502   \u251c\u2500\u2500 params.go\n\u2502   \u251c\u2500\u2500 query.pb.go\n\u2502   \u2514\u2500\u2500 tx.pb.go\n\u251c\u2500\u2500 module.go\n\u251c\u2500\u2500 abci.go\n\u251c\u2500\u2500 autocli.go\n\u251c\u2500\u2500 depinject.go\n\u2514\u2500\u2500 README.md\n</code></pre> <ul> <li><code>client/</code>: The module's CLI client functionality implementation and the module's CLI testing suite.</li> <li><code>exported/</code>: The module's exported types - typically interface types. If a module relies on keepers from another module, it is expected to receive the keepers as interface contracts through the <code>expected_keepers.go</code> file (see below) in order to avoid a direct dependency on the module implementing the keepers. However, these interface contracts can define methods that operate on and/or return types that are specific to the module that is implementing the keepers and this is where <code>exported/</code> comes into play. The interface types that are defined in <code>exported/</code> use canonical types, allowing for the module to receive the keepers as interface contracts through the <code>expected_keepers.go</code> file. This pattern allows for code to remain DRY and also alleviates import cycle chaos.</li> <li><code>keeper/</code>: The module's <code>Keeper</code> and <code>MsgServer</code> implementation.</li> <li><code>abci.go</code>: The module's <code>BeginBlocker</code> and <code>EndBlocker</code> implementations (this file is only required if <code>BeginBlocker</code> and/or <code>EndBlocker</code> need to be defined).</li> <li><code>simulation/</code>: The module's simulation package defines functions used by the blockchain simulator application (<code>simapp</code>).</li> <li><code>README.md</code>: The module's specification documents outlining important concepts, state storage structure, and message and event type definitions. Learn more how to write module specs in the spec guidelines.</li> <li><code>types/</code>: includes type definitions for messages, events, and genesis state, including the type definitions generated by Protocol Buffers.</li> <li><code>codec.go</code>: The module's registry methods for interface types.</li> <li><code>errors.go</code>: The module's sentinel errors.</li> <li><code>events.go</code>: The module's event types and constructors.</li> <li><code>expected_keepers.go</code>: The module's expected keeper interfaces.</li> <li><code>genesis.go</code>: The module's genesis state methods and helper functions.</li> <li><code>keys.go</code>: The module's store keys and associated helper functions.</li> <li><code>msgs.go</code>: The module's message type definitions and associated methods.</li> <li><code>params.go</code>: The module's parameter type definitions and associated methods.</li> <li><code>*.pb.go</code>: The module's type definitions generated by Protocol Buffers (as defined in the respective <code>*.proto</code> files above).</li> <li>The root directory includes the module's <code>AppModule</code> implementation.</li> <li><code>autocli.go</code>: The module autocli options.</li> <li><code>depinject.go</code>: The module depinject options.</li> </ul> <p>Note: although the above pattern is followed by most of the Cosmos SDK modules, there are some modules that don't follow this pattern. E.g <code>x/group</code> and <code>x/nft</code> dont have a <code>types</code> folder, instead all of the type definitions for messages, events, and genesis state are live in the root directory and the module's <code>AppModule</code> implementation lives in the <code>module</code> folder.</p>"},{"location":"guides/tools/cosmos-sdk/#sidebar_position-1","title":"sidebar_position: 1","text":""},{"location":"guides/tools/cosmos-sdk/#msg-services","title":"<code>Msg</code> Services","text":"<p>:::note Synopsis A Protobuf <code>Msg</code> service processes messages. Protobuf <code>Msg</code> services are specific to the module in which they are defined, and only process messages defined within the said module. They are called from <code>BaseApp</code> during <code>FinalizeBlock</code>. :::</p> <p>:::note Pre-requisite Readings</p> <ul> <li>Module Manager</li> <li>Messages and Queries</li> </ul> <p>:::</p>"},{"location":"guides/tools/cosmos-sdk/#implementation-of-a-module-msg-service","title":"Implementation of a module <code>Msg</code> service","text":"<p>Each module should define a Protobuf <code>Msg</code> service, which will be responsible for processing requests (implementing <code>sdk.Msg</code>) and returning responses.</p> <p>As further described in ADR 031, this approach has the advantage of clearly specifying return types and generating server and client code.</p> <p>Protobuf generates a <code>MsgServer</code> interface based on the definition of <code>Msg</code> service. It is the role of the module developer to implement this interface, by implementing the state transition logic that should happen upon receival of each <code>transaction.Msg</code>. As an example, here is the generated <code>MsgServer</code> interface for <code>x/bank</code>, which exposes two <code>transaction.Msg</code>s:</p> <p>```go reference https://github.com/cosmos/cosmos-sdk/blob/28fa3b8/x/bank/types/tx.pb.go#L564-L579</p> <pre><code>\nWhen possible, the existing module's [`Keeper`](./06-keeper.md) should implement `MsgServer`, otherwise a `msgServer` struct that embeds the `Keeper` can be created, typically in `./keeper/msg_server.go`:\n\n```go reference\nhttps://github.com/cosmos/cosmos-sdk/blob/28fa3b8/x/bank/keeper/msg_server.go#L16-L19\n</code></pre> <p><code>msgServer</code> methods can retrieve the auxiliary information or services using the environment variable, it is always located in the keeper:</p> <p>Environment:</p> <p>```go reference https://github.com/cosmos/cosmos-sdk/blob/07151304e2ec6a185243d083f59a2d543253cb15/core/appmodule/v2/environment.go#L14-L29</p> <pre><code>\nKeeper Example:\n\n```go reference\nhttps://github.com/cosmos/cosmos-sdk/blob/07151304e2ec6a185243d083f59a2d543253cb15/x/bank/keeper/keeper.go#L56-L58\n</code></pre> <p><code>transaction.Msg</code> processing usually follows these 3 steps:</p>"},{"location":"guides/tools/cosmos-sdk/#validation","title":"Validation","text":"<p>The message server must perform all validation required (both stateful and stateless) to make sure the <code>message</code> is valid. The <code>signer</code> is charged for the gas cost of this validation.</p> <p>For example, a <code>msgServer</code> method for a <code>transfer</code> message should check that the sending account has enough funds to actually perform the transfer.</p> <p>It is recommended to implement all validation checks in a separate function that passes state values as arguments. This implementation simplifies testing. As expected, expensive validation functions charge additional gas. Example:</p> <pre><code>ValidateMsgA(msg MsgA, now Time, gm GasMeter) error {\n    if now.Before(msg.Expire) {\n        return sdkerrors.ErrInvalidRequest.Wrap(\"msg expired\")\n    }\n    gm.ConsumeGas(1000, \"signature verification\")\n    return signatureVerificaton(msg.Prover, msg.Data)\n}\n</code></pre> <p>:::warning Previously, the <code>ValidateBasic</code> method was used to perform simple and stateless validation checks. This way of validating is deprecated, this means the <code>msgServer</code> must perform all validation checks. :::</p>"},{"location":"guides/tools/cosmos-sdk/#state-transition","title":"State Transition","text":"<p>After the validation is successful, the <code>msgServer</code> method uses the <code>keeper</code> functions to access the state and perform a state transition.</p>"},{"location":"guides/tools/cosmos-sdk/#events","title":"Events","text":"<p>Before returning, <code>msgServer</code> methods generally emit one or more events by using the <code>EventManager</code> held in <code>environment</code>.</p> <p>There are two ways to emit events, typed events using protobuf or arbitrary key &amp; values.</p> <p>Typed Events:</p> <pre><code>ctx.EventManager().EmitTypedEvent(\n    &amp;group.EventABC{Key1: Value1,  Key2, Value2})\n</code></pre> <p>Arbitrary Events:</p> <pre><code>ctx.EventManager().EmitEvent(\n    sdk.NewEvent(\n        eventType,  // e.g. sdk.EventTypeMessage for a message, types.CustomEventType for a custom event defined in the module\n        sdk.NewAttribute(key1, value1),\n        sdk.NewAttribute(key2, value2),\n    ),\n)\n</code></pre> <p>These events are relayed back to the underlying consensus engine and can be used by service providers to implement services around the application. Click here to learn more about events.</p> <p>The invoked <code>msgServer</code> method returns a <code>proto.Message</code> response and an <code>error</code>. These return values are then wrapped into an <code>*sdk.Result</code> or an <code>error</code>:</p> <p>```go reference https://github.com/cosmos/cosmos-sdk/blob/v0.50.0-alpha.0/baseapp/msg_service_router.go#L160</p> <pre><code>\nThis method takes care of marshaling the `res` parameter to protobuf and attaching any events on the `EventManager()` to the `sdk.Result`.\n\n```protobuf reference\nhttps://github.com/cosmos/cosmos-sdk/blob/v0.50.0-alpha.0/proto/cosmos/base/abci/v1beta1/abci.proto#L93-L113\n</code></pre> <p>This diagram shows a typical structure of a Protobuf <code>Msg</code> service, and how the message propagates through the module.</p> <pre><code>sequenceDiagram\n    participant User\n    participant baseApp\n    participant router\n    participant handler\n    participant msgServer\n    participant keeper\n    participant EventManager\n\n    User-&gt;&gt;baseApp: Transaction Type&lt;Tx&gt;\n    baseApp-&gt;&gt;router: Route(ctx, msgRoute)\n    router-&gt;&gt;handler: handler\n    handler-&gt;&gt;msgServer: Msg&lt;Tx&gt;(Context, Msg(..))\n\n    alt addresses invalid, denominations wrong, etc.\n        msgServer-&gt;&gt;handler: error\n        handler-&gt;&gt;router: error\n        router-&gt;&gt;baseApp: result, error code\n    else\n        msgServer-&gt;&gt;keeper: perform action, update context\n        keeper-&gt;&gt;msgServer: results, error code\n        msgServer-&gt;&gt;EventManager: Emit relevant events\n        msgServer-&gt;&gt;msgServer: maybe wrap results in more structure\n        msgServer-&gt;&gt;handler: result, error code\n        handler-&gt;&gt;router: result, error code\n        router-&gt;&gt;baseApp: result, error code\n    end\n\n    baseApp-&gt;&gt;User: result, error code\n</code></pre>"},{"location":"guides/tools/cosmos-sdk/#telemetry","title":"Telemetry","text":"<p>New telemetry metrics can be created from <code>msgServer</code> methods when handling messages.</p> <p>This is an example from the <code>x/auth/vesting</code> module:</p> <p>```go reference https://github.com/cosmos/cosmos-sdk/blob/v0.50.0-alpha.0/x/auth/vesting/msg_server.go#L76-L88</p> <pre><code>\n:::Warning\nTelemetry adds a performance overhead to the chain. It is recommended to only use this in critical paths\n:::\n\n---\n\n## sidebar_position: 1\n\n# Query Services\n\n:::note Synopsis\nA Protobuf Query service processes [`queries`](./02-messages-and-queries.md#queries). Query services are specific to the module in which they are defined, and only process `queries` defined within said module. They are called from `BaseApp`'s [`Query` method](../../learn/advanced/00-baseapp.md#query).\n:::\n\n:::note Pre-requisite Readings\n\n- [Module Manager](./01-module-manager.md)\n- [Messages and Queries](./02-messages-and-queries.md)\n\n:::\n\n## Implementation of a module query service\n\n### gRPC Service\n\nWhen defining a Protobuf `Query` service, a `QueryServer` interface is generated for each module with all the service methods:\n\n```go\ntype QueryServer interface {\n    QueryBalance(context.Context, *QueryBalanceParams) (*types.Coin, error)\n    QueryAllBalances(context.Context, *QueryAllBalancesParams) (*QueryAllBalancesResponse, error)\n}\n</code></pre> <p>These custom queries methods should be implemented by a module's keeper, typically in <code>./keeper/grpc_query.go</code>. The first parameter of these methods is a generic <code>context.Context</code>. Therefore, the Cosmos SDK provides a function <code>sdk.UnwrapSDKContext</code> to retrieve the <code>context.Context</code> from the provided <code>context.Context</code>.</p> <p>Here's an example implementation for the bank module:</p> <p>```go reference https://github.com/cosmos/cosmos-sdk/blob/v0.50.0-alpha.0/x/bank/keeper/grpc_query.go</p> <pre><code>\n### Calling queries from the State Machine\n\nThe Cosmos SDK v0.47 introduces a new `cosmos.query.v1.module_query_safe` Protobuf annotation which is used to state that a query that is safe to be called from within the state machine, for example:\n\n- a Keeper's query function can be called from another module's Keeper,\n- ADR-033 intermodule query calls,\n- CosmWasm contracts can also directly interact with these queries.\n\nIf the `module_query_safe` annotation set to `true`, it means:\n\n- The query is deterministic: given a block height it will return the same response upon multiple calls, and doesn't introduce any state-machine breaking changes across SDK patch versions.\n- Gas consumption never fluctuates across calls and across patch versions.\n\nIf you are a module developer and want to use `module_query_safe` annotation for your own query, you have to ensure the following things:\n\n- the query is deterministic and won't introduce state-machine-breaking changes without coordinated upgrades\n- it has its gas tracked, to avoid the attack vector where no gas is accounted for\n  on potentially high-computation queries.\n\n  ***\n\n  sidebar_position: 1\n\n---\n\n# Blockchain Architecture\n\n## Introduction\n\nBlockchain architecture is a complex topic that involves many different components. In this section, we will cover the main layers of a blockchain application built with the Cosmos SDK.\n\nAt its core, a blockchain is a replicated deterministic state machine. This document explores the various layers of blockchain architecture, focusing on the execution, settlement, consensus, data availability, and interoperability layers.\n\n```mermaid\ngraph TD\n    A[Modular SDK Blockchain Architecture]\n    A --&gt; B[Execution Layer]\n    A --&gt; C[Settlement Layer]\n    A --&gt; D[Consensus Layer]\n    D --&gt; E[Data Availability Layer]\n    A --&gt; F[Interoperability Layer]\n</code></pre>"},{"location":"guides/tools/cosmos-sdk/#layered-architecture","title":"Layered Architecture","text":"<p>Understanding blockchain architecture through the lens of different layers helps in comprehending its complex functionalities. We will give a high-level overview of the execution layer, settlement layer, consensus layer, data availability layer, and interoperability layer.</p>"},{"location":"guides/tools/cosmos-sdk/#execution-layer","title":"Execution Layer","text":"<p>The Execution Layer is where the blockchain processes and executes transactions. The state machine within the blockchain handles the execution of transaction logic. This is done by the blockchain itself, ensuring that every transaction follows the predefined rules and state transitions. When a transaction is submitted, the execution layer processes it, updates the state, and ensures that the output is deterministic and consistent across all nodes. In the context of the Cosmos SDK, this typically involves predefined modules and transaction types rather than general-purpose smart contracts, which are used in chains with CosmWasm.</p>"},{"location":"guides/tools/cosmos-sdk/#state-machine","title":"State machine","text":"<p>At its core, a blockchain is a replicated deterministic state machine.</p> <p>A state machine is a computer science concept whereby a machine can have multiple states, but only one at any given time. There is a <code>state</code>, which describes the current state of the system, and <code>transactions</code>, that trigger state transitions.</p> <p>Given a state S and a transaction T, the state machine will return a new state S'.</p> <pre><code>flowchart LR\n    A[S]\n    B[S']\n    A --&gt;|\"apply(T)\"| B\n</code></pre> <p>In practice, the transactions are bundled in blocks to make the process more efficient. Given a state S and a block of transactions B, the state machine will return a new state S'.</p> <pre><code>flowchart LR\n    A[S]\n    B[S']\n    A --&gt;|\"For each T in B: apply(T)\"| B\n</code></pre> <p>In a blockchain context, the state machine is deterministic. This means that if a node is started at a given state and replays the same sequence of transactions, it will always end up with the same final state.</p> <p>The Cosmos SDK gives developers maximum flexibility to define the state of their application, transaction types and state transition functions. The process of building state machines with the Cosmos SDK will be described more in-depth in the following sections. But first, let us see how the state machine is replicated using various consensus engines, such as CometBFT.</p>"},{"location":"guides/tools/cosmos-sdk/#settlement-layer","title":"Settlement Layer","text":"<p>The Settlement Layer is responsible for finalising and recording transactions on the blockchain. This layer ensures that all transactions are accurately settled and immutable, providing a verifiable record of all activities on the blockchain. It is critical for maintaining the integrity and trustworthiness of the blockchain.</p> <p>The settlement layer can be performed on the chain itself or it can be externalised, allowing for the possibility of plugging in a different settlement layer as needed. For example if we were to use Rollkit and celestia for our Data Availability and Consensus, we could separate our settlement layer by introducing fraud or validity proofs. From there the settlement layer can create trust-minimised light clients, further enhancing security and efficiency. This process ensures that all transactions are accurately finalized and immutable, providing a verifiable record of all activities.</p>"},{"location":"guides/tools/cosmos-sdk/#consensus-layer","title":"Consensus Layer","text":"<p>The Consensus Layer ensures that all nodes in the network agree on the order and validity of transactions. This layer uses consensus algorithms like Byzantine Fault Tolerance (BFT) or Proof of Stake (PoS) to achieve agreement, even in the presence of malicious nodes. Consensus is crucial for maintaining the security and reliability of the blockchain.</p> <p>What has been a default consensus engine in the Cosmos SDK has been CometBFT. In the most recent releases we have been moving away from this and allowing users to plug and play their own consensus engines. This is a big step forward for the Cosmos SDK as it allows for more flexibility and customisation. Other consensus engine options for example can be Rollkit with Celestias Data Availability Layer.</p> <p>Here is an example of how the consensus layer works with CometBFT in the context of the Cosmos SDK:</p>"},{"location":"guides/tools/cosmos-sdk/#cometbft","title":"CometBFT","text":"<p>Thanks to the Cosmos SDK, developers just have to define the state machine, and CometBFT will handle replication over the network for them.</p> <pre><code>flowchart TD\n    subgraph Blockchain_Node[Blockchain Node]\n        subgraph SM[State-machine]\n            direction TB\n            SM1[Cosmos SDK]\n        end\n        subgraph CometBFT[CometBFT]\n            direction TB\n            Consensus\n            Networking\n        end\n    end\n\n    SM &lt;--&gt; CometBFT\n\n\n    Blockchain_Node --&gt;|Includes| SM\n    Blockchain_Node --&gt;|Includes| CometBFT\n</code></pre> <p>CometBFT is an application-agnostic engine that is responsible for handling the networking and consensus layers of a blockchain. In practice, this means that CometBFT is responsible for propagating and ordering transaction bytes. CometBFT relies on an eponymous Byzantine-Fault-Tolerant (BFT) algorithm to reach consensus on the order of transactions.</p> <p>The consensus algorithm adopted by CometBFT works with a set of special nodes called Validators. Validators are responsible for adding blocks of transactions to the blockchain. At any given block, there is a validator set V. A validator in V is chosen by the algorithm to be the proposer of the next block. This block is considered valid if more than two thirds of V signed a <code>prevote</code> and a <code>precommit</code> on it, and if all the transactions that it contains are valid. The validator set can be changed by rules written in the state-machine.</p>"},{"location":"guides/tools/cosmos-sdk/#abci","title":"ABCI","text":"<p>CometBFT passes transactions to the application through an interface called the ABCI, which the application must implement.</p> <pre><code>graph TD\n    A[Application]\n    B[CometBFT]\n    A &lt;--&gt;|ABCI| B\n\n</code></pre> <p>Note that CometBFT only handles transaction bytes. It has no knowledge of what these bytes mean. All CometBFT does is order these transaction bytes deterministically. CometBFT passes the bytes to the application via the ABCI, and expects a return code to inform it if the messages contained in the transactions were successfully processed or not.</p> <p>Here are the most important messages of the ABCI:</p> <ul> <li><code>CheckTx</code>: When a transaction is received by CometBFT, it is passed to the application to check if a few basic requirements are met. <code>CheckTx</code> is used to protect the mempool of full-nodes against spam transactions. A special handler called the <code>AnteHandler</code> is used to execute a series of validation steps such as checking for sufficient fees and validating the signatures. If the checks are valid, the transaction is added to the mempool and relayed to peer nodes. Note that transactions are not processed (i.e. no modification of the state occurs) with <code>CheckTx</code> since they have not been included in a block yet.</li> <li><code>DeliverTx</code>: When a valid block is received by CometBFT, each transaction in the block is passed to the application via <code>DeliverTx</code> in order to be processed. It is during this stage that the state transitions occur. The <code>AnteHandler</code> executes again, along with the actual <code>Msg</code> service RPC for each message in the transaction.</li> <li><code>BeginBlock</code>/<code>EndBlock</code>: These messages are executed at the beginning and the end of each block, whether the block contains transactions or not. It is useful to trigger automatic execution of logic. Proceed with caution though, as computationally expensive loops could slow down your blockchain, or even freeze it if the loop is infinite.</li> </ul> <p>Find a more detailed view of the ABCI methods from the CometBFT docs.</p> <p>Any application built on CometBFT needs to implement the ABCI interface in order to communicate with the underlying local CometBFT engine. Fortunately, you do not have to implement the ABCI interface. The Cosmos SDK provides a boilerplate implementation of it in the form of baseapp.</p>"},{"location":"guides/tools/cosmos-sdk/#data-availability-layer","title":"Data Availability Layer","text":"<p>The Data Availability (DA) Layer is a critical component of within the umbrella of the consensus layer that ensures all necessary data for transactions is available to all network participants. This layer is essential for preventing data withholding attacks, where some nodes might attempt to disrupt the network by not sharing critical transaction data.</p> <p>If we use the example of Rollkit, a user initiates a transaction, which is then propagated through the rollup network by a light node. The transaction is validated by full nodes and aggregated into a block by the sequencer. This block is posted to a data availability layer like Celestia, ensuring the data is accessible and correctly ordered. The rollup light node verifies data availability from the DA layer. Full nodes then validate the block and generate necessary proofs, such as fraud proofs for optimistic rollups or zk-SNARKs/zk-STARKs for zk-rollups. These proofs are shared across the network and verified by other nodes, ensuring the rollup's integrity. Once all validations are complete, the rollup's state is updated, finalising the transaction</p>"},{"location":"guides/tools/cosmos-sdk/#interoperability-layer","title":"Interoperability Layer","text":"<p>The Interoperability Layer enables communication and interaction between different blockchains. This layer facilitates cross-chain transactions and data sharing, allowing various blockchain networks to interoperate seamlessly. Interoperability is key for building a connected ecosystem of blockchains, enhancing their functionality and reach.</p> <p>In this case we have separated the layers even further to really illustrate the components that make-up the blockchain architecture and it is important to note that the Cosmos SDK is designed to be interoperable with other blockchains. This is achieved through the use of the Inter-Blockchain Communication (IBC) protocol, which allows different blockchains to communicate and transfer assets between each other.</p>"},{"location":"guides/tools/cosmos-sdk/#sidebar_position-1_1","title":"sidebar_position: 1","text":""},{"location":"guides/tools/cosmos-sdk/#application-specific-blockchains","title":"Application-Specific Blockchains","text":"<p>:::note Synopsis This document explains what application-specific blockchains are, and why developers would want to build one as opposed to writing Smart Contracts. :::</p>"},{"location":"guides/tools/cosmos-sdk/#what-are-application-specific-blockchains","title":"What are application-specific blockchains","text":"<p>Application-specific blockchains are blockchains customized to operate a single application. Instead of building a decentralized application on top of an underlying blockchain like Ethereum, developers build their own blockchain from the ground up. This means building a full-node client, a light-client, and all the necessary interfaces (CLI, REST, ...) to interact with the nodes.</p> <pre><code>flowchart TD\n    subgraph Blockchain_Node[Blockchain Node]\n        subgraph SM[State-machine]\n            direction TB\n            SM1[Cosmos SDK]\n        end\n        subgraph Consensus[Consensus]\n            direction TB\n        end\n        subgraph Networking[Networking]\n            direction TB\n        end\n    end\n\n    SM &lt;--&gt; Consensus\n    Consensus &lt;--&gt; Networking\n\n\n    Blockchain_Node --&gt;|Includes| SM\n    Blockchain_Node --&gt;|Includes| Consensus\n    Blockchain_Node --&gt;|Includes| Networking\n</code></pre>"},{"location":"guides/tools/cosmos-sdk/#what-are-the-shortcomings-of-smart-contracts","title":"What are the shortcomings of Smart Contracts","text":"<p>Virtual-machine blockchains like Ethereum addressed the demand for more programmability back in 2014. At the time, the options available for building decentralized applications were quite limited. Most developers would build on top of the complex and limited Bitcoin scripting language, or fork the Bitcoin codebase which was hard to work with and customize.</p> <p>Virtual-machine blockchains came in with a new value proposition. Their state-machine incorporates a virtual-machine that is able to interpret turing-complete programs called Smart Contracts. These Smart Contracts are very good for use cases like one-time events (e.g. ICOs), but they can fall short for building complex decentralized platforms. Here is why:</p> <ul> <li>Smart Contracts are generally developed with specific programming languages that can be interpreted by the underlying virtual-machine. These programming languages are often immature and inherently limited by the constraints of the virtual-machine itself. For example, the Ethereum Virtual Machine does not allow developers to implement automatic execution of code. Developers are also limited to the account-based system of the EVM, and they can only choose from a limited set of functions for their cryptographic operations. These are examples, but they hint at the lack of flexibility that a smart contract environment often entails.</li> <li>Smart Contracts are all run by the same virtual machine. This means that they compete for resources, which can severely restrain performance. And even if the state-machine were to be split in multiple subsets (e.g. via sharding), Smart Contracts would still need to be interpreted by a virtual machine, which would limit performance compared to a native application implemented at state-machine level (our benchmarks show an improvement on the order of 10x in performance when the virtual-machine is removed).</li> <li>Another issue with the fact that Smart Contracts share the same underlying environment is the resulting limitation in sovereignty. A decentralized application is an ecosystem that involves multiple players. If the application is built on a general-purpose virtual-machine blockchain, stakeholders have very limited sovereignty over their application, and are ultimately superseded by the governance of the underlying blockchain. If there is a bug in the application, very little can be done about it.</li> </ul> <p>Application-Specific Blockchains are designed to address these shortcomings.</p>"},{"location":"guides/tools/cosmos-sdk/#application-specific-blockchains-benefits","title":"Application-Specific Blockchains Benefits","text":""},{"location":"guides/tools/cosmos-sdk/#flexibility","title":"Flexibility","text":"<p>Application-specific blockchains give maximum flexibility to developers:</p> <ul> <li> <p>In Cosmos blockchains, the state-machine is typically connected to the underlying consensus engine via an interface called the ABCI (Application Blockchain Interface). This interface can be wrapped in any programming language, meaning developers can build their state-machine in the programming language of their choice.</p> </li> <li> <p>Developers can choose among multiple frameworks to build their state-machine. The most widely used today is the Cosmos SDK, but others exist (e.g. Lotion, Weave, ...). Typically the choice will be made based on the programming language they want to use (Cosmos SDK and Weave are in Golang, Lotion is in Javascript, ...).</p> </li> <li>The ABCI also allows developers to swap the consensus engine of their application-specific blockchain. Today, only CometBFT is production-ready, but in the future other consensus engines are expected to emerge.</li> <li>Even when they settle for a framework and consensus engine, developers still have the freedom to tweak them if they don't perfectly match their requirements in their pristine forms.</li> <li>Developers are free to explore the full spectrum of tradeoffs (e.g. number of validators vs transaction throughput, safety vs availability in asynchrony, ...) and design choices (DB or IAVL tree for storage, UTXO or account model, ...).</li> <li>Developers can implement automatic execution of code. In the Cosmos SDK, logic can be automatically triggered at the beginning and the end of each block. They are also free to choose the cryptographic library used in their application, as opposed to being constrained by what is made available by the underlying environment in the case of virtual-machine blockchains.</li> </ul> <p>The list above contains a few examples that show how much flexibility application-specific blockchains give to developers. The goal of Cosmos and the Cosmos SDK is to make developer tooling as generic and composable as possible, so that each part of the stack can be forked, tweaked and improved without losing compatibility. As the community grows, more alternatives for each of the core building blocks will emerge, giving more options to developers.</p>"},{"location":"guides/tools/cosmos-sdk/#performance","title":"Performance","text":"<p>Decentralized applications built with Smart Contracts are inherently capped in performance by the underlying environment. For a decentralized application to optimise performance, it needs to be built as an application-specific blockchain. Next are some of the benefits an application-specific blockchain brings in terms of performance:</p> <ul> <li>Developers of application-specific blockchains can choose to operate with a novel consensus engine such as CometBFT.</li> <li>An application-specific blockchain only operates a single application, so that the application does not compete with others for computation and storage. This is the opposite of most non-sharded virtual-machine blockchains today, where smart contracts all compete for computation and storage.</li> <li>Even if a virtual-machine blockchain offered application-based sharding coupled with an efficient consensus algorithm, performance would still be limited by the virtual-machine itself. The real throughput bottleneck is the state-machine, and requiring transactions to be interpreted by a virtual-machine significantly increases the computational complexity of processing them.</li> </ul>"},{"location":"guides/tools/cosmos-sdk/#security","title":"Security","text":"<p>Security is hard to quantify, and greatly varies from platform to platform. That said here are some important benefits an application-specific blockchain can bring in terms of security:</p> <ul> <li>Developers can choose proven programming languages like Go when building their application-specific blockchains, as opposed to smart contract programming languages that are often more immature.</li> <li>Developers are not constrained by the cryptographic functions made available by the underlying virtual-machines. They can use their own custom cryptography, and rely on well-audited crypto libraries.</li> <li>Developers do not have to worry about potential bugs or exploitable mechanisms in the underlying virtual-machine, making it easier to reason about the security of the application.</li> </ul>"},{"location":"guides/tools/cosmos-sdk/#sovereignty","title":"Sovereignty","text":"<p>One of the major benefits of application-specific blockchains is sovereignty. A decentralized application is an ecosystem that involves many actors: users, developers, third-party services, and more. When developers build on virtual-machine blockchain where many decentralized applications coexist, the community of the application is different than the community of the underlying blockchain, and the latter supersedes the former in the governance process. If there is a bug or if a new feature is needed, stakeholders of the application have very little leeway to upgrade the code. If the community of the underlying blockchain refuses to act, nothing can happen.</p> <p>The fundamental issue here is that the governance of the application and the governance of the network are not aligned. This issue is solved by application-specific blockchains. Because application-specific blockchains specialize to operate a single application, stakeholders of the application have full control over the entire chain. This ensures that the community will not be stuck if a bug is discovered, and that it has the freedom to choose how it is going to evolve.</p>"},{"location":"guides/tools/ibc-accounts/","title":"Interchain Accounts","text":"<p>:::note Synopsis Learn about what the Interchain Accounts module is :::</p>"},{"location":"guides/tools/ibc-accounts/#what-is-the-interchain-accounts-module","title":"What is the Interchain Accounts module?","text":"<p>Interchain Accounts is the Cosmos SDK implementation of the ICS-27 protocol, which enables cross-chain account management built upon IBC.</p> <ul> <li>How does an interchain account differ from a regular account?</li> </ul> <p>Regular accounts use a private key to sign transactions. Interchain Accounts are instead controlled programmatically by counterparty chains via IBC packets.</p>"},{"location":"guides/tools/ibc-accounts/#concepts","title":"Concepts","text":"<p><code>Host Chain</code>: The chain where the interchain account is registered. The host chain listens for IBC packets from a controller chain which should contain instructions (e.g. Cosmos SDK messages) for which the interchain account will execute.</p> <p><code>Controller Chain</code>: The chain registering and controlling an account on a host chain. The controller chain sends IBC packets to the host chain to control the account.</p> <p><code>Interchain Account</code>: An account on a host chain created using the ICS-27 protocol. An interchain account has all the capabilities of a normal account. However, rather than signing transactions with a private key, a controller chain will send IBC packets to the host chain which signals what transactions the interchain account should execute.</p> <p><code>Authentication Module</code>: A custom application module on the controller chain that uses the Interchain Accounts module to build custom logic for the creation &amp; management of interchain accounts. It can be either an IBC application module using the legacy API, or a regular Cosmos SDK application module sending messages to the controller submodule's <code>MsgServer</code> (this is the recommended approach from ibc-go v6 if access to packet callbacks is not needed). Please note that the legacy API will eventually be removed and IBC applications will not be able to use them in later releases.</p>"},{"location":"guides/tools/ibc-accounts/#sdk-security-model","title":"SDK security model","text":"<p>SDK modules on a chain are assumed to be trustworthy. For example, there are no checks to prevent an untrustworthy module from accessing the bank keeper.</p> <p>The implementation of ICS-27 in ibc-go uses this assumption in its security considerations.</p> <p>The implementation assumes other IBC application modules will not bind to ports within the ICS-27 namespace.</p>"},{"location":"guides/tools/ibc-accounts/#channel-closure","title":"Channel Closure","text":"<p>The provided interchain account host and controller implementations do not support <code>ChanCloseInit</code>. However, they do support <code>ChanCloseConfirm</code>. This means that the host and controller modules cannot close channels, but they will confirm channel closures initiated by other implementations of ICS-27.</p> <p>In the event of a channel closing (due to a packet timeout in an ordered channel, for example), the interchain account associated with that channel can become accessible again if a new channel is created with a (JSON-formatted) version string that encodes the exact same <code>Metadata</code> information of the previous channel. The channel can be reopened using either <code>MsgRegisterInterchainAccount</code> or <code>MsgChannelOpenInit</code>. If <code>MsgRegisterInterchainAccount</code> is used, then it is possible to leave the <code>version</code> field of the message empty, since it will be filled in by the controller submodule. If <code>MsgChannelOpenInit</code> is used, then the <code>version</code> field must be provided with the correct JSON-encoded <code>Metadata</code> string. See section Understanding Active Channels for more information.</p> <p>When reopening a channel with the default controller submodule, the ordering of the channel cannot be changed. In order to change the ordering of the channel, the channel has to go through a channel upgrade handshake or reopen the channel with a custom controller implementation.</p>"},{"location":"guides/tools/ibc-fee-middleware/","title":"Overview","text":"<p>:::note Synopsis Learn about what the Fee Middleware module is, and how to build custom modules that utilize the Fee Middleware functionality :::</p>"},{"location":"guides/tools/ibc-fee-middleware/#what-is-the-fee-middleware-module","title":"What is the Fee Middleware module?","text":"<p>IBC does not depend on relayer operators for transaction verification. However, the relayer infrastructure ensures liveness of the Interchain network \u2014 operators listen for packets sent through channels opened between chains, and perform the vital service of ferrying these packets (and proof of the transaction on the sending chain/receipt on the receiving chain) to the clients on each side of the channel.</p> <p>Though relaying is permissionless and completely decentralized and accessible, it does come with operational costs. Running full nodes to query transaction proofs and paying for transaction fees associated with IBC packets are two of the primary cost burdens which have driven the overall discussion on a general, in-protocol incentivization mechanism for relayers.</p> <p>Initially, a simple proposal was created to incentivize relaying on ICS20 token transfers on the destination chain. However, the proposal was specific to ICS20 token transfers and would have to be reimplemented in this format on every other IBC application module.</p> <p>After much discussion, the proposal was expanded to a general incentivisation design that can be adopted by any ICS application protocol as middleware.</p>"},{"location":"guides/tools/ibc-fee-middleware/#concepts","title":"Concepts","text":"<p>ICS29 fee payments in this middleware design are built on the assumption that sender chains are the source of incentives \u2014 the chain on which packets are incentivized is the chain that distributes fees to relayer operators. However, as part of the IBC packet flow, messages have to be submitted on both sender and destination chains. This introduces the requirement of a mapping of relayer operator's addresses on both chains.</p> <p>To achieve the stated requirements, the fee middleware module has two main groups of functionality:</p> <ul> <li>Registering of relayer addresses associated with each party involved in relaying the packet on the source chain. This registration process can be automated on start up of relayer infrastructure and happens only once, not every packet flow.</li> </ul> <p>This is described in the Fee distribution section.</p> <ul> <li>Escrowing fees by any party which will be paid out to each rightful party on completion of the packet lifecycle.</li> </ul> <p>This is described in the Fee messages section.</p> <p>We complete the introduction by giving a list of definitions of relevant terminology.</p> <p><code>Forward relayer</code>: The relayer that submits the <code>MsgRecvPacket</code> message for a given packet (on the destination chain).</p> <p><code>Reverse relayer</code>: The relayer that submits the <code>MsgAcknowledgement</code> message for a given packet (on the source chain).</p> <p><code>Timeout relayer</code>: The relayer that submits the <code>MsgTimeout</code> or <code>MsgTimeoutOnClose</code> messages for a given packet (on the source chain).</p> <p><code>Payee</code>: The account address on the source chain to be paid on completion of the packet lifecycle. The packet lifecycle on the source chain completes with the receipt of a <code>MsgTimeout</code>/<code>MsgTimeoutOnClose</code> or a <code>MsgAcknowledgement</code>.</p> <p><code>Counterparty payee</code>: The account address to be paid on completion of the packet lifecycle on the destination chain. The package lifecycle on the destination chain completes with a successful <code>MsgRecvPacket</code>.</p> <p><code>Refund address</code>: The address of the account paying for the incentivization of packet relaying. The account is refunded timeout fees upon successful acknowledgement. In the event of a packet timeout, both acknowledgement and receive fees are refunded.</p>"},{"location":"guides/tools/ibc-fee-middleware/#known-limitations","title":"Known Limitations","text":"<ul> <li>At the time of the release of the feature (ibc-go v4) fee payments middleware only supported incentivisation of new channels; however, with the release of channel upgradeability (ibc-go v8.1) it is possible to enable incentivisation of all existing channels.</li> <li>Even though unlikely, there exists a DoS attack vector on a fee-enabled channel if 1) there exists a relayer software implementation that is incentivised to timeout packets if the timeout fee is greater than the sum of the fees to receive and acknowledge the packet, and 2) only this type of implementation is used by operators relaying on the channel. In this situation, an attacker could continuously incentivise the relayers to never deliver the packets by incrementing the timeout fee of the packets above the sum of the receive and acknowledge fees. However, this situation is unlikely to occur because 1) another relayer behaving honestly could relay the packets before they timeout, and 2) the attack would be costly because the attacker would need to incentivise the timeout fee of the packets with their own funds. Given the low impact and unlikelihood of the attack we have decided to accept this risk and not implement any mitigation mesaures.</li> </ul>"},{"location":"guides/tools/ibc-fee-middleware/#module-integration","title":"Module Integration","text":"<p>The Fee Middleware module, as the name suggests, plays the role of an IBC middleware and as such must be configured by chain developers to route and handle IBC messages correctly. For Cosmos SDK chains this setup is done via the <code>app/app.go</code> file, where modules are constructed and configured in order to bootstrap the blockchain application.</p>"},{"location":"guides/tools/ibc-fee-middleware/#example-integration-of-the-fee-middleware-module","title":"Example integration of the Fee Middleware module","text":"<pre><code>// app.go\n\n// Register the AppModule for the fee middleware module\nModuleBasics = module.NewBasicManager(\n  ...\n  ibcfee.AppModuleBasic{},\n  ...\n)\n\n...\n\n// Add module account permissions for the fee middleware module\nmaccPerms = map[string][]string{\n  ...\n  ibcfeetypes.ModuleName:            nil,\n}\n\n...\n\n// Add fee middleware Keeper\ntype App struct {\n  ...\n\n  IBCFeeKeeper ibcfeekeeper.Keeper\n\n  ...\n}\n\n...\n\n// Create store keys\nkeys := sdk.NewKVStoreKeys(\n  ...\n  ibcfeetypes.StoreKey,\n  ...\n)\n\n...\n\napp.IBCFeeKeeper = ibcfeekeeper.NewKeeper(\n  appCodec, keys[ibcfeetypes.StoreKey],\n  app.IBCKeeper.ChannelKeeper, // may be replaced with IBC middleware\n  app.IBCKeeper.ChannelKeeper,\n  &amp;app.IBCKeeper.PortKeeper, app.AccountKeeper, app.BankKeeper,\n)\n\n\n// See the section below for configuring an application stack with the fee middleware module\n\n...\n\n// Register fee middleware AppModule\napp.moduleManager = module.NewManager(\n  ...\n  ibcfee.NewAppModule(app.IBCFeeKeeper),\n)\n\n...\n\n// Add fee middleware to begin blocker logic\napp.moduleManager.SetOrderBeginBlockers(\n  ...\n  ibcfeetypes.ModuleName,\n  ...\n)\n\n// Add fee middleware to end blocker logic\napp.moduleManager.SetOrderEndBlockers(\n  ...\n  ibcfeetypes.ModuleName,\n  ...\n)\n\n// Add fee middleware to init genesis logic\napp.moduleManager.SetOrderInitGenesis(\n  ...\n  ibcfeetypes.ModuleName,\n  ...\n)\n</code></pre>"},{"location":"guides/tools/ibc-fee-middleware/#configuring-an-application-stack-with-fee-middleware","title":"Configuring an application stack with Fee Middleware","text":"<p>As mentioned in IBC middleware development an application stack may be composed of many or no middlewares that nest a base application. These layers form the complete set of application logic that enable developers to build composable and flexible IBC application stacks. For example, an application stack may be just a single base application like <code>transfer</code>, however, the same application stack composed with <code>29-fee</code> will nest the <code>transfer</code> base application by wrapping it with the Fee Middleware module.</p>"},{"location":"guides/tools/ibc-fee-middleware/#transfer","title":"Transfer","text":"<p>See below for an example of how to create an application stack using <code>transfer</code> and <code>29-fee</code>. The following <code>transferStack</code> is configured in <code>app/app.go</code> and added to the IBC <code>Router</code>. The in-line comments describe the execution flow of packets between the application stack and IBC core.</p> <pre><code>// Create Transfer Stack\n// SendPacket, since it is originating from the application to core IBC:\n// transferKeeper.SendPacket -&gt; fee.SendPacket -&gt; channel.SendPacket\n\n// RecvPacket, message that originates from core IBC and goes down to app, the flow is the other way\n// channel.RecvPacket -&gt; fee.OnRecvPacket -&gt; transfer.OnRecvPacket\n\n// transfer stack contains (from top to bottom):\n// - IBC Fee Middleware\n// - Transfer\n\n// create IBC module from bottom to top of stack\nvar transferStack porttypes.IBCModule\ntransferStack = transfer.NewIBCModule(app.TransferKeeper)\ntransferStack = ibcfee.NewIBCMiddleware(transferStack, app.IBCFeeKeeper)\n\n// Add transfer stack to IBC Router\nibcRouter.AddRoute(ibctransfertypes.ModuleName, transferStack)\n</code></pre>"},{"location":"guides/tools/ibc-fee-middleware/#interchain-accounts","title":"Interchain Accounts","text":"<p>See below for an example of how to create an application stack using <code>27-interchain-accounts</code> and <code>29-fee</code>. The following <code>icaControllerStack</code> and <code>icaHostStack</code> are configured in <code>app/app.go</code> and added to the IBC <code>Router</code> with the associated authentication module. The in-line comments describe the execution flow of packets between the application stack and IBC core.</p> <pre><code>// Create Interchain Accounts Stack\n// SendPacket, since it is originating from the application to core IBC:\n// icaAuthModuleKeeper.SendTx -&gt; icaController.SendPacket -&gt; fee.SendPacket -&gt; channel.SendPacket\n\n// initialize ICA module with mock module as the authentication module on the controller side\nvar icaControllerStack porttypes.IBCModule\nicaControllerStack = ibcmock.NewIBCModule(&amp;mockModule, ibcmock.NewMockIBCApp(\"\", scopedICAMockKeeper))\napp.ICAAuthModule = icaControllerStack.(ibcmock.IBCModule)\nicaControllerStack = icacontroller.NewIBCMiddleware(icaControllerStack, app.ICAControllerKeeper)\nicaControllerStack = ibcfee.NewIBCMiddleware(icaControllerStack, app.IBCFeeKeeper)\n\n// RecvPacket, message that originates from core IBC and goes down to app, the flow is:\n// channel.RecvPacket -&gt; fee.OnRecvPacket -&gt; icaHost.OnRecvPacket\n\nvar icaHostStack porttypes.IBCModule\nicaHostStack = icahost.NewIBCModule(app.ICAHostKeeper)\nicaHostStack = ibcfee.NewIBCMiddleware(icaHostStack, app.IBCFeeKeeper)\n\n// Add authentication module, controller and host to IBC router\nibcRouter.\n  // the ICA Controller middleware needs to be explicitly added to the IBC Router because the\n  // ICA controller module owns the port capability for ICA. The ICA authentication module\n  // owns the channel capability.\n  AddRoute(ibcmock.ModuleName+icacontrollertypes.SubModuleName, icaControllerStack) // ica with mock auth module stack route to ica (top level of middleware stack)\n  AddRoute(icacontrollertypes.SubModuleName, icaControllerStack).\n  AddRoute(icahosttypes.SubModuleName, icaHostStack).\n</code></pre>"},{"location":"guides/tools/ibc-fee-middleware/#fee-distribution","title":"Fee Distribution","text":"<p>Packet fees are divided into 3 distinct amounts in order to compensate relayer operators for packet relaying on fee enabled IBC channels.</p> <ul> <li><code>RecvFee</code>: The sum of all packet receive fees distributed to a payee for successful execution of <code>MsgRecvPacket</code>.</li> <li><code>AckFee</code>: The sum of all packet acknowledgement fees distributed to a payee for successful execution of <code>MsgAcknowledgement</code>.</li> <li><code>TimeoutFee</code>: The sum of all packet timeout fees distributed to a payee for successful execution of <code>MsgTimeout</code>.</li> </ul>"},{"location":"guides/tools/ibc-fee-middleware/#register-a-counterparty-payee-address-for-forward-relaying","title":"Register a counterparty payee address for forward relaying","text":"<p>As mentioned in ICS29 Concepts, the forward relayer describes the actor who performs the submission of <code>MsgRecvPacket</code> on the destination chain. Fee distribution for incentivized packet relays takes place on the packet source chain.</p> <p>Relayer operators are expected to register a counterparty payee address, in order to be compensated accordingly with <code>RecvFee</code>s upon completion of a packet lifecycle.</p> <p>The counterparty payee address registered on the destination chain is encoded into the packet acknowledgement and communicated as such to the source chain for fee distribution. If a counterparty payee is not registered for the forward relayer on the destination chain, the escrowed fees will be refunded upon fee distribution.</p>"},{"location":"guides/tools/ibc-fee-middleware/#relayer-operator-actions","title":"Relayer operator actions","text":"<p>A transaction must be submitted to the destination chain including a <code>CounterpartyPayee</code> address of an account on the source chain. The transaction must be signed by the <code>Relayer</code>.</p> <p>Note: If a module account address is used as the <code>CounterpartyPayee</code> but the module has been set as a blocked address in the <code>BankKeeper</code>, the refunding to the module account will fail. This is because many modules use invariants to compare internal tracking of module account balances against the actual balance of the account stored in the <code>BankKeeper</code>. If a token transfer to the module account occurs without going through this module and updating the account balance of the module on the <code>BankKeeper</code>, then invariants may break and unknown behaviour could occur depending on the module implementation. Therefore, if it is desirable to use a module account that is currently blocked, the module developers should be consulted to gauge to possibility of removing the module account from the blocked list.</p> <pre><code>type MsgRegisterCounterpartyPayee struct {\n  // unique port identifier\n  PortId string\n  // unique channel identifier\n  ChannelId string\n  // the relayer address\n  Relayer string\n  // the counterparty payee address\n  CounterpartyPayee string\n}\n</code></pre> <p>This message is expected to fail if:</p> <ul> <li><code>PortId</code> is invalid (see 24-host naming requirements.</li> <li><code>ChannelId</code> is invalid (see 24-host naming requirements).</li> <li><code>Relayer</code> is an invalid address (see Cosmos SDK Addresses).</li> <li><code>CounterpartyPayee</code> is empty or contains more than 2048 bytes.</li> </ul> <p>See below for an example CLI command:</p> <pre><code>simd tx ibc-fee register-counterparty-payee transfer channel-0 \\\n  cosmos1rsp837a4kvtgp2m4uqzdge0zzu6efqgucm0qdh \\\n  osmo1v5y0tz01llxzf4c2afml8s3awue0ymju22wxx2 \\\n  --from cosmos1rsp837a4kvtgp2m4uqzdge0zzu6efqgucm0qdh\n</code></pre>"},{"location":"guides/tools/ibc-fee-middleware/#register-an-alternative-payee-address-for-reverse-and-timeout-relaying","title":"Register an alternative payee address for reverse and timeout relaying","text":"<p>As mentioned in ICS29 Concepts, the reverse relayer describes the actor who performs the submission of <code>MsgAcknowledgement</code> on the source chain. Similarly the timeout relayer describes the actor who performs the submission of <code>MsgTimeout</code> (or <code>MsgTimeoutOnClose</code>) on the source chain.</p> <p>Relayer operators may choose to register an optional payee address, in order to be compensated accordingly with <code>AckFee</code>s and <code>TimeoutFee</code>s upon completion of a packet life cycle.</p> <p>If a payee is not registered for the reverse or timeout relayer on the source chain, then fee distribution assumes the default behaviour, where fees are paid out to the relayer account which delivers <code>MsgAcknowledgement</code> or <code>MsgTimeout</code>/<code>MsgTimeoutOnClose</code>.</p>"},{"location":"guides/tools/ibc-fee-middleware/#relayer-operator-actions_1","title":"Relayer operator actions","text":"<p>A transaction must be submitted to the source chain including a <code>Payee</code> address of an account on the source chain. The transaction must be signed by the <code>Relayer</code>.</p> <p>Note: If a module account address is used as the <code>Payee</code> it is recommended to turn off invariant checks for that module.</p> <pre><code>type MsgRegisterPayee struct {\n  // unique port identifier\n  PortId string\n  // unique channel identifier\n  ChannelId string\n  // the relayer address\n  Relayer string\n  // the payee address\n  Payee string\n}\n</code></pre> <p>This message is expected to fail if:</p> <ul> <li><code>PortId</code> is invalid (see 24-host naming requirements.</li> <li><code>ChannelId</code> is invalid (see 24-host naming requirements).</li> <li><code>Relayer</code> is an invalid address (see Cosmos SDK Addresses).</li> <li><code>Payee</code> is an invalid address (see Cosmos SDK Addresses).</li> </ul> <p>See below for an example CLI command:</p> <pre><code>simd tx ibc-fee register-payee transfer channel-0 \\\n  cosmos1rsp837a4kvtgp2m4uqzdge0zzu6efqgucm0qdh \\\n  cosmos153lf4zntqt33a4v0sm5cytrxyqn78q7kz8j8x5 \\\n  --from cosmos1rsp837a4kvtgp2m4uqzdge0zzu6efqgucm0qdh\n</code></pre>"},{"location":"guides/tools/ibc-transfer/","title":"Overview","text":"<p>:::note Synopsis Learn about what the token Transfer module is :::</p>"},{"location":"guides/tools/ibc-transfer/#what-is-the-transfer-module","title":"What is the Transfer module?","text":"<p>Transfer is the Cosmos SDK implementation of the ICS-20 protocol, which enables cross-chain fungible token transfers.</p>"},{"location":"guides/tools/ibc-transfer/#concepts","title":"Concepts","text":""},{"location":"guides/tools/ibc-transfer/#acknowledgements","title":"Acknowledgements","text":"<p>ICS20 uses the recommended acknowledgement format as specified by ICS 04.</p> <p>A successful receive of a transfer packet will result in a Result Acknowledgement being written with the value <code>[]byte{byte(1)}</code> in the <code>Response</code> field.</p> <p>An unsuccessful receive of a transfer packet will result in an Error Acknowledgement being written with the error message in the <code>Response</code> field.</p>"},{"location":"guides/tools/ibc-transfer/#denomination-trace","title":"Denomination trace","text":"<p>The denomination trace corresponds to the information that allows a token to be traced back to its origin chain. It contains a sequence of port and channel identifiers ordered from the most recent to the oldest in the timeline of transfers.</p> <p>This information is included on the token's base denomination field in the form of a hash to prevent an unbounded denomination length. For example, the token <code>transfer/channelToA/uatom</code> will be displayed as <code>ibc/7F1D3FCF4AE79E1554D670D1AD949A9BA4E4A3C76C63093E17E446A46061A7A2</code>. The human readable denomination is stored using <code>x/bank</code> module's denom metadata feature. You may display the human readable denominations by querying balances with the <code>--resolve-denom</code> flag, as in:</p> <pre><code>simd query bank balances [address] --resolve-denom\n</code></pre> <p>Each send to any chain other than the one it was previously received from is a movement forwards in the token's timeline. This causes trace to be added to the token's history and the destination port and destination channel to be prefixed to the denomination. In these instances the sender chain is acting as the \"source zone\". When the token is sent back to the chain it previously received from, the prefix is removed. This is a backwards movement in the token's timeline and the sender chain is acting as the \"sink zone\".</p> <p>It is strongly recommended to read the full details of ADR 001: Coin Source Tracing to understand the implications and context of the IBC token representations.</p>"},{"location":"guides/tools/ibc-transfer/#ux-suggestions-for-clients","title":"UX suggestions for clients","text":"<p>For clients (wallets, exchanges, applications, block explorers, etc) that want to display the source of the token, it is recommended to use the following alternatives for each of the cases below:</p>"},{"location":"guides/tools/ibc-transfer/#direct-connection","title":"Direct connection","text":"<p>If the denomination trace contains a single identifier prefix pair (as in the example above), then the easiest way to retrieve the chain and light client identifier is to map the trace information directly. In summary, this requires querying the channel from the denomination trace identifiers, and then the counterparty client state using the counterparty port and channel identifiers from the retrieved channel.</p> <p>A general pseudo algorithm would look like the following:</p> <ol> <li>Query the full denomination trace.</li> <li>Query the channel with the <code>portID/channelID</code> pair, which corresponds to the first destination of the    token.</li> <li>Query the client state using the identifiers pair. Note that this query will return a <code>\"Not Found\"</code> response if the current chain is not connected to this channel.</li> <li>Retrieve the client identifier or chain identifier from the client state (eg: on    Tendermint clients) and store it locally.</li> </ol> <p>Using the gRPC gateway client service the steps above would be, with a given IBC token <code>ibc/7F1D3FCF4AE79E1554D670D1AD949A9BA4E4A3C76C63093E17E446A46061A7A2</code> stored on <code>chainB</code>:</p> <ol> <li><code>GET /ibc/apps/transfer/v1/denom_traces/7F1D3FCF4AE79E1554D670D1AD949A9BA4E4A3C76C63093E17E446A46061A7A2</code> -&gt; <code>{\"path\": \"transfer/channelToA\", \"base_denom\": \"uatom\"}</code></li> <li><code>GET /ibc/apps/transfer/v1/channels/channelToA/ports/transfer/client_state\"</code> -&gt; <code>{\"client_id\": \"clientA\", \"chain-id\": \"chainA\", ...}</code></li> <li><code>GET /ibc/apps/transfer/v1/channels/channelToA/ports/transfer\"</code> -&gt; <code>{\"channel_id\": \"channelToA\", port_id\": \"transfer\", counterparty: {\"channel_id\": \"channelToB\", port_id\": \"transfer\"}, ...}</code></li> <li><code>GET /ibc/apps/transfer/v1/channels/channelToB/ports/transfer/client_state\" -&gt; {\"client_id\": \"clientB\", \"chain-id\": \"chainB\", ...}</code></li> </ol> <p>Then, the token transfer chain path for the <code>uatom</code> denomination would be: <code>chainA</code> -&gt; <code>chainB</code>.</p>"},{"location":"guides/tools/ibc-transfer/#multiple-hops","title":"Multiple hops","text":"<p>The multiple channel hops case applies when the token has passed through multiple chains between the original source and final destination chains.</p> <p>The IBC protocol doesn't know the topology of the overall network (i.e connections between chains and identifier names between them). For this reason, in the multiple hops case, a particular chain in the timeline of the individual transfers can't query the chain and client identifiers of the other chains.</p> <p>Take for example the following sequence of transfers <code>A -&gt; B -&gt; C</code> for an IBC token, with a final prefix path (trace info) of <code>transfer/channelChainC/transfer/channelChainB</code>. What the paragraph above means is that even in the case that chain <code>C</code> is directly connected to chain <code>A</code>, querying the port and channel identifiers that chain <code>B</code> uses to connect to chain <code>A</code> (eg: <code>transfer/channelChainA</code>) can be completely different from the one that chain <code>C</code> uses to connect to chain <code>A</code> (eg: <code>transfer/channelToChainA</code>).</p> <p>Thus the proposed solution for clients that the IBC team recommends are the following:</p> <ul> <li>Connect to all chains: Connecting to all the chains in the timeline would allow clients to   perform the queries outlined in the direct connection section to each   relevant chain. By repeatedly following the port and channel denomination trace transfer timeline,   clients should always be able to find all the relevant identifiers. This comes at the tradeoff   that the client must connect to nodes on each of the chains in order to perform the queries.</li> <li>Relayer as a Service (RaaS): A longer term solution is to use/create a relayer service that   could map the denomination trace to the chain path timeline for each token (i.e <code>origin chain -&gt; chain #1 -&gt; ... -&gt; chain #(n-1) -&gt; final chain</code>). These services could provide merkle proofs in   order to allow clients to optionally verify the path timeline correctness for themselves by   running light clients. If the proofs are not verified, they should be considered as trusted third   parties services. Additionally, client would be advised in the future to use RaaS that support the   largest number of connections between chains in the ecosystem. Unfortunately, none of the existing   public relayers (in Golang and   Rust), provide this service to clients.</li> </ul> <p>:::tip The only viable alternative for clients (at the time of writing) to tokens with multiple connection hops, is to connect to all chains directly and perform relevant queries to each of them in the sequence. :::</p>"},{"location":"guides/tools/ibc-transfer/#forwarding","title":"Forwarding","text":"<p>:::info Token forwarding and unwinding is supported only on ICS20 v2 transfer channels. :::</p> <p>Forwarding allows tokens to be routed to a final destination through multiple (up to 8) intermediary chains. With forwarding, it's also possible to unwind IBC vouchers to their native chain, and forward  them afterwards to another destination, all with just a single transfer transaction on the sending chain.</p>"},{"location":"guides/tools/ibc-transfer/#forward-tokens","title":"Forward tokens","text":"<p>Native tokens or IBC vouchers on any chain can be forwarded through intermediary chains to reach their  final destination. For example, given the topology below, with 3 chains and a transfer channel between chains A and B and between chains B and C:</p> <p></p> <p>Native tokens on chain <code>A</code> can be sent to chain <code>C</code> through chain <code>B</code>. The routing is specified by the  source port ID and channel ID of choice on every intermediary chain. In this example, there is only one forwarding hop on chain <code>B</code> and the port ID, channel ID pair is <code>transfer</code>, <code>channelBToC</code>. Forwarding of  a multi-denom collections of tokens is also allowed (i.e. forwarding of tokens of different denominations).</p>"},{"location":"guides/tools/ibc-transfer/#unwind-tokens","title":"Unwind tokens","text":"<p>Taking again as an example the topology from the previous section, we assume that native tokens on chain <code>A</code> have been transferred to chain <code>C</code>. The IBC vouchers on chain <code>C</code> have the denomination trace <code>transfer/channelCtoB/transfer/channelBtoA</code>, and with forwarding it is possible to submit a transfer message  on chain <code>C</code> and automatically unwind the vouchers through chain <code>B</code> to chain <code>A</code>, so that the tokens recovered on the origin chain regain their native denomination. In order to execute automatic unwinding, the transfer module does not require extra user input: the unwind route is encoded in the denomination trace with the  pairs of destination port ID, channel ID that are added on every chain where the tokens are received.</p> <p>Please note that unwinding of vouchers is only allowed when vouchers transferred all share the same denomination trace (signifying coins that all originate from the same source). It is not possible to unwind vouchers of two different  IBC denominations, since they come from different source chains.</p>"},{"location":"guides/tools/ibc-transfer/#unwind-tokens-and-then-forward","title":"Unwind tokens and then forward","text":"<p>Unwinding and forwarding can be used in combination, so that vouchers are first unwound to their origin chain and then forwarded to a final destination. The same restriction as in the unwinding case applies: only vouchers of a single IBC denomination can be used.</p>"},{"location":"guides/tools/ibc-transfer/#locked-funds","title":"Locked funds","text":"<p>In some exceptional cases, a client state associated with a given channel cannot be updated. This causes that funds from fungible tokens in that channel will be permanently locked and thus can no longer be transferred.</p> <p>To mitigate this, a client update governance proposal can be submitted to update the frozen client with a new valid header. Once the proposal passes the client state will be unfrozen and the funds from the associated channels will then be unlocked. This mechanism only applies to clients that allow updates via governance, such as Tendermint clients.</p> <p>In addition to this, it's important to mention that a token must be sent back along the exact route that it took originally in order to return it to its original form on the source chain (eg: the Cosmos Hub for the <code>uatom</code>). Sending a token back to the same chain across a different channel will not move the token back across its timeline. If a channel in the chain history closes before the token can be sent back across that channel, then the token will not be returnable to its original form.</p>"},{"location":"guides/tools/ibc-transfer/#security-considerations","title":"Security considerations","text":"<p>For safety, no other module must be capable of minting tokens with the <code>ibc/</code> prefix. The IBC transfer module needs a subset of the denomination space that only it can create tokens in.</p>"},{"location":"guides/tools/ibc-transfer/#channel-closure","title":"Channel Closure","text":"<p>The IBC transfer module does not support channel closure.</p>"},{"location":"modules/sonr-did/","title":"<code>x/did</code>","text":"<p>The Decentralized Identity module is responsible for managing native Sonr Accounts, their derived wallets, and associated user identification information.</p>"},{"location":"modules/sonr-did/#state","title":"State","text":"<p>The DID module maintains several key state structures:</p>"},{"location":"modules/sonr-did/#controller-state","title":"Controller State","text":"<p>The Controller state represents a Sonr DWN Vault. It includes: - Unique identifier (number) - DID - Sonr address - Ethereum address - Bitcoin address - Public key - Keyshares pointer - Claimed block - Creation block</p>"},{"location":"modules/sonr-did/#assertion-state","title":"Assertion State","text":"<p>The Assertion state includes: - DID - Controller - Subject - Public key - Assertion type - Accumulator (metadata) - Creation block</p>"},{"location":"modules/sonr-did/#authentication-state","title":"Authentication State","text":"<p>The Authentication state includes: - DID - Controller - Subject - Public key - Credential ID - Metadata - Creation block</p>"},{"location":"modules/sonr-did/#verification-state","title":"Verification State","text":"<p>The Verification state includes: - DID - Controller - DID method - Issuer - Subject - Public key - Verification type - Metadata - Creation block</p>"},{"location":"modules/sonr-did/#state-transitions","title":"State Transitions","text":"<p>State transitions are triggered by the following messages: - LinkAssertion - LinkAuthentication - UnlinkAssertion - UnlinkAuthentication - ExecuteTx - UpdateParams</p>"},{"location":"modules/sonr-did/#messages","title":"Messages","text":"<p>The DID module defines the following messages:</p> <ol> <li>MsgLinkAuthentication</li> <li>MsgLinkAssertion</li> <li>MsgExecuteTx</li> <li>MsgUnlinkAssertion</li> <li>MsgUnlinkAuthentication</li> <li>MsgUpdateParams</li> </ol> <p>Each message triggers specific state machine behaviors related to managing DIDs, authentications, assertions, and module parameters.</p>"},{"location":"modules/sonr-did/#query","title":"Query","text":"<p>The DID module provides the following query endpoints:</p> <ol> <li>Params: Query all parameters of the module</li> <li>Resolve: Query the DID document by its ID</li> <li>Sign: Sign a message with the DID document</li> <li>Verify: Verify a message with the DID document</li> </ol>"},{"location":"modules/sonr-did/#params","title":"Params","text":"<p>The module parameters include: - Allowed public keys (map of KeyInfo) - Conveyance preference - Attestation formats</p>"},{"location":"modules/sonr-did/#client","title":"Client","text":"<p>The module provides gRPC and REST endpoints for all defined messages and queries.</p>"},{"location":"modules/sonr-did/#future-improvements","title":"Future Improvements","text":"<p>Potential future improvements could include: 1. Enhanced privacy features for DID operations 2. Integration with more blockchain networks 3. Support for additional key types and cryptographic algorithms 4. Improved revocation mechanisms for credentials and assertions</p>"},{"location":"modules/sonr-did/#tests","title":"Tests","text":"<p>Acceptance tests should cover all major functionality, including: - Creating and managing DIDs - Linking and unlinking assertions and authentications - Executing transactions with DIDs - Querying and resolving DIDs - Parameter updates</p>"},{"location":"modules/sonr-did/#appendix","title":"Appendix","text":""},{"location":"modules/sonr-did/#account","title":"Account","text":"<p>An Account represents a user's identity within the Sonr ecosystem. It includes information such as the user's public key, associated wallets, and other identification details.</p>"},{"location":"modules/sonr-did/#decentralized-identifier-did","title":"Decentralized Identifier (DID)","text":"<p>A Decentralized Identifier (DID) is a unique identifier that is created, owned, and controlled by the user. It is used to establish a secure and verifiable digital identity.</p>"},{"location":"modules/sonr-did/#verifiable-credential-vc","title":"Verifiable Credential (VC)","text":"<p>A Verifiable Credential (VC) is a digital statement that can be cryptographically verified. It contains claims about a subject (e.g., a user) and is issued by a trusted authority.</p>"},{"location":"modules/sonr-did/#key-types","title":"Key Types","text":"<p>The module supports various key types, including: - Role - Algorithm (e.g., ES256, EdDSA, ES256K) - Encoding (e.g., hex, base64, multibase) - Curve (e.g., P256, P384, P521, X25519, X448, Ed25519, Ed448, secp256k1)</p>"},{"location":"modules/sonr-did/#json-web-key-jwk","title":"JSON Web Key (JWK)","text":"<p>The module supports JSON Web Keys (JWK) for representing cryptographic keys, including properties such as key type (kty), curve (crv), and coordinates (x, y) for EC and OKP keys, as well as modulus (n) and exponent (e) for RSA keys.</p>"},{"location":"modules/sonr-dwn/","title":"<code>x/dwn</code>","text":"<p>The DWN module is responsible for the management of IPFS deployed Decentralized Web Nodes (DWNs) and their associated data.</p>"},{"location":"modules/sonr-dwn/#concepts","title":"Concepts","text":"<p>The DWN module introduces several key concepts:</p> <ol> <li>Decentralized Web Node (DWN): A distributed network for storing and sharing data.</li> <li>Schema: A structure defining the format of various data types in the dwn.</li> <li>IPFS Integration: The module can interact with IPFS for decentralized data storage.</li> </ol>"},{"location":"modules/sonr-dwn/#state","title":"State","text":"<p>The DWN module maintains the following state:</p>"},{"location":"modules/sonr-dwn/#dwn-state","title":"DWN State","text":"<p>The DWN state is stored using the following structure:</p> <pre><code>message DWN {\n  uint64 id = 1;\n  string alias = 2;\n  string cid = 3;\n  string resolver = 4;\n}\n</code></pre> <p>This state is indexed by ID, alias, and CID for efficient querying.</p>"},{"location":"modules/sonr-dwn/#params-state","title":"Params State","text":"<p>The module parameters are stored in the following structure:</p> <pre><code>message Params {\n  bool ipfs_active = 1;\n  bool local_registration_enabled = 2;\n  Schema schema = 4;\n}\n</code></pre>"},{"location":"modules/sonr-dwn/#schema-state","title":"Schema State","text":"<p>The Schema state defines the structure for various data types:</p> <pre><code>message Schema {\n  int32 version = 1;\n  string account = 2;\n  string asset = 3;\n  string chain = 4;\n  string credential = 5;\n  string did = 6;\n  string jwk = 7;\n  string grant = 8;\n  string keyshare = 9;\n  string profile = 10;\n}\n</code></pre>"},{"location":"modules/sonr-dwn/#state-transitions","title":"State Transitions","text":"<p>State transitions in the DWN module are primarily triggered by:</p> <ol> <li>Updating module parameters</li> <li>Allocating new dwns</li> <li>Syncing DID documents</li> </ol>"},{"location":"modules/sonr-dwn/#messages","title":"Messages","text":"<p>The DWN module defines the following message:</p> <ol> <li><code>MsgUpdateParams</code>: Used to update the module parameters.</li> </ol> <pre><code>message MsgUpdateParams {\n  string authority = 1;\n  Params params = 2;\n}\n</code></pre>"},{"location":"modules/sonr-dwn/#begin-block","title":"Begin Block","text":"<p>No specific begin-block operations are defined for this module.</p>"},{"location":"modules/sonr-dwn/#end-block","title":"End Block","text":"<p>No specific end-block operations are defined for this module.</p>"},{"location":"modules/sonr-dwn/#hooks","title":"Hooks","text":"<p>The DWN module does not define any hooks.</p>"},{"location":"modules/sonr-dwn/#events","title":"Events","text":"<p>The DWN module does not explicitly define any events. However, standard Cosmos SDK events may be emitted during state transitions.</p>"},{"location":"modules/sonr-dwn/#client","title":"Client","text":"<p>The DWN module provides the following gRPC query endpoints:</p> <ol> <li><code>Params</code>: Queries all parameters of the module.</li> <li><code>Schema</code>: Queries the DID document schema.</li> <li><code>Allocate</code>: Initializes a Target DWN available for claims.</li> <li><code>Sync</code>: Queries the DID document by its ID and returns required information.</li> </ol>"},{"location":"modules/sonr-dwn/#params","title":"Params","text":"<p>The module parameters include:</p> <ul> <li><code>ipfs_active</code> (bool): Indicates if IPFS integration is active.</li> <li><code>local_registration_enabled</code> (bool): Indicates if local registration is enabled.</li> <li><code>schema</code> (Schema): Defines the structure for various data types in the dwn.</li> </ul>"},{"location":"modules/sonr-dwn/#future-improvements","title":"Future Improvements","text":"<p>Potential future improvements could include:</p> <ol> <li>Enhanced IPFS integration features.</li> <li>Additional authentication mechanisms beyond WebAuthn.</li> <li>Improved DID document management and querying capabilities.</li> </ol>"},{"location":"modules/sonr-dwn/#tests","title":"Tests","text":"<p>Acceptance tests should cover:</p> <ol> <li>Parameter updates</li> <li>DWN state management</li> <li>Schema queries</li> <li>DWN allocation process</li> <li>DID document syncing</li> </ol>"},{"location":"modules/sonr-dwn/#appendix","title":"Appendix","text":"Concept Description Decentralized Web Node (DWN) A decentralized, distributed, and secure network of nodes that store and share data. It is a decentralized alternative to traditional web hosting services. Decentralized Identifier (DID) A unique identifier that is created, owned, and controlled by the user. It is used to establish a secure and verifiable digital identity. HTMX (Hypertext Markup Language eXtensions) A set of extensions to HTML that allow for the creation of interactive web pages. It is used to enhance the user experience and provide additional functionality to web applications. IPFS (InterPlanetary File System) A decentralized, peer-to-peer network for storing and sharing data. It is a distributed file system that allows for the creation and sharing of content across a network of nodes. WebAuthn (Web Authentication) A set of APIs that allow websites to request user authentication using biometric or non-biometric factors. WebAssembly (Web Assembly) A binary instruction format for a stack-based virtual machine. Verifiable Credential (VC) A digital statement that can be cryptographically verified."},{"location":"modules/sonr-service/","title":"<code>x/svc</code>","text":"<p>The svc module is responsible for managing the registration and authorization of services within the Sonr ecosystem. It provides a secure and verifiable mechanism for registering and authorizing services using Decentralized Identifiers (DIDs).</p>"},{"location":"modules/sonr-service/#concepts","title":"Concepts","text":"<ul> <li>Service: A decentralized svc on the Sonr Blockchain with properties such as ID, authority, origin, name, description, category, tags, and expiry height.</li> <li>Profile: Represents a DID alias with properties like ID, subject, origin, and controller.</li> <li>Metadata: Contains information about a svc, including name, description, category, icon, and tags.</li> </ul>"},{"location":"modules/sonr-service/#dependencies","title":"Dependencies","text":"<ul> <li>x/did</li> <li>x/group</li> <li>x/nft</li> </ul>"},{"location":"modules/sonr-service/#state","title":"State","text":"<p>The module uses the following state structures:</p>"},{"location":"modules/sonr-service/#metadata","title":"Metadata","text":"<p>Stores information about services:</p> <ul> <li>Primary key: <code>id</code> (auto-increment)</li> <li>Unique index: <code>origin</code></li> <li>Fields: id, origin, name, description, category, icon (URI), tags</li> </ul>"},{"location":"modules/sonr-service/#profile","title":"Profile","text":"<p>Stores DID alias information:</p> <ul> <li>Primary key: <code>id</code></li> <li>Unique index: <code>subject,origin</code></li> <li>Fields: id, subject, origin, controller</li> </ul>"},{"location":"modules/sonr-service/#messages","title":"Messages","text":""},{"location":"modules/sonr-service/#msgupdateparams","title":"MsgUpdateParams","text":"<p>Updates the module parameters. Can only be executed by the governance account.</p>"},{"location":"modules/sonr-service/#msgregisterservice","title":"MsgRegisterService","text":"<p>Registers a new svc on the blockchain. Requires a valid TXT record in DNS for the origin.</p>"},{"location":"modules/sonr-service/#params","title":"Params","text":"<p>The module has the following parameters:</p> <ul> <li><code>categories</code>: List of allowed svc categories</li> <li><code>types</code>: List of allowed svc types</li> </ul>"},{"location":"modules/sonr-service/#query","title":"Query","text":"<p>The module provides the following query:</p>"},{"location":"modules/sonr-service/#params_1","title":"Params","text":"<p>Retrieves all parameters of the module.</p>"},{"location":"modules/sonr-service/#client","title":"Client","text":""},{"location":"modules/sonr-service/#grpc","title":"gRPC","text":"<p>The module provides a gRPC Query svc with the following RPC:</p> <ul> <li><code>Params</code>: Get all parameters of the module</li> </ul>"},{"location":"modules/sonr-service/#cli","title":"CLI","text":"<p>(TODO: Add CLI commands for interacting with the module)</p>"},{"location":"modules/sonr-service/#events","title":"Events","text":"<p>(TODO: List and describe event tags used by the module)</p>"},{"location":"modules/sonr-service/#future-improvements","title":"Future Improvements","text":"<ul> <li>Implement svc discovery mechanisms</li> <li>Add support for svc reputation and rating systems</li> <li>Enhance svc metadata with more detailed information</li> <li>Implement svc update and deactivation functionality</li> </ul>"},{"location":"modules/sonr-service/#tests","title":"Tests","text":"<p>(TODO: Add acceptance tests for the module)</p>"},{"location":"modules/sonr-service/#appendix","title":"Appendix","text":"<p>This module is part of the Sonr blockchain project and interacts with other modules such as DID and NFT modules to provide a comprehensive decentralized svc ecosystem.</p>"},{"location":"modules/ucan-spec/","title":"User Controlled Authorization Network (UCAN) Specification","text":""},{"location":"modules/ucan-spec/#abstract","title":"Abstract","text":"<p>User-Controlled Authorization Network (UCAN) is a trustless, secure, local-first, user-originated, distributed authorization scheme. This document provides a high level overview of the components of the system, concepts, and motivation. Exact formats are given in sub-specifications.</p>"},{"location":"modules/ucan-spec/#introduction","title":"Introduction","text":"<p>User-Controlled Authorization Network (UCAN) is a trustless, secure, local-first, user-originated, distributed authorization scheme. It provides public-key verifiable, delegable, expressive, openly extensible capabilities. UCANs achieve public verifiability with late-bound certificate chains and principals represented by decentralized identifiers (DIDs).</p> <p>UCAN improves the familiarity and adoptability of schemes like SPKI/SDSI for web and native application contexts. UCAN allows for the creation, delegation, and invocation of authority by any agent with a DID, including traditional systems and peer-to-peer architectures beyond traditional cloud computing.</p>"},{"location":"modules/ucan-spec/#motivation","title":"Motivation","text":"<p>If we practice our principles, we could have both security and functionality. Treating security as a separate concern has not succeeded in bridging the gap between principle and practice, because it operates without knowledge of what constitutes least authority.</p> <p>\u2014 Miller et al, The Structure of Authority</p> <p>Since at least Multics, access control lists (ACLs) have been the most popular form of digital authorization, where a list of what each user is allowed to do is maintained on the resource. ACLs (and later RBAC) have been a successful model suited to architectures where persistent access to a single list is viable. ACLs require that rules are sufficiently well specified, such as in a centralized database with rules covering all possible permutations of scenario. This both imposes a very high maintenance burden on programmers as a systems grows in complexity, and is a key vector for confused deputies.</p> <p>With increasing interconnectivity between machines becoming commonplace, authorization needs to scale to meet the load demands of distributed systems while providing partition tolerance. However, it is not always practical to maintain a single central authorization source. Even when copies of the authorization list are distributed to the relevant servers, latency and partitions introduce troublesome challenges with conflicting updates, to say nothing of storage requirements.</p> <p>A large portion of personal information now also moves through connected systems. As a result, data privacy is a prominent theme when considering the design of modern applications, to the point of being legislated in parts of the world.</p> <p>Ahead-of-time coordination is often a barrier to development in many projects. Flexibility to define specialized authorization semantics for resources and the ability to integrate with external systems trustlessly are essential as the number of autonomous, specialized, and coordinated applications increases.</p> <p>Many high-value applications run in hostile environments. In recognition of this, many vendors now include public key functionality, such as non-extractable keys in browsers, certificate systems for external keys, platform keys, and [secure hardware enclaves] in widespread consumer devices.</p> <p>Two related models that work exceptionally well in the above context are Simple Public Key Infrastructure (SPKI) and object capabilities (OCAP). Since offline operation and self-verifiability are two requirements, UCAN adopts a certificate capability model related to SPKI.</p>"},{"location":"modules/ucan-spec/#intuition-for-auth-system-differences","title":"Intuition for Auth System Differences","text":"<p>The following analogies illustrate several significant trade-offs between these systems but are only accurate enough to build intuition. A good resource for a more thorough presentation of these trade-offs is Capability Myths Demolished. In this framework, UCAN approximates SPKI with some dynamic features.</p>"},{"location":"modules/ucan-spec/#access-control-lists","title":"Access Control Lists","text":"<p>By analogy, ACLs are like a bouncer at an exclusive event. This bouncer has a list attendees allowed in and which of those are VIPs that get extra access. People trying to get in show their government-issued ID and are accepted or rejected. In addition, they may get a lanyard to identify that they have previously been allowed in. If someone is disruptive, they can simply be crossed off the list and denied further entry.</p> <p>If there are many such events at many venues, the organizers need to coordinate ahead of time, denials need to be synchronized, and attendees need to show their ID cards to many bouncers. The likelihood of the bouncer letting in the wrong person due to synchronization lag or confusion by someone sharing a name is nonzero.</p>"},{"location":"modules/ucan-spec/#certificate-capabilities","title":"Certificate Capabilities","text":"<p>UCANs work more like movie tickets or a festival pass. No one needs to check your ID; who you are is irrelevant. For example, if you have a ticket issued by the theater to see Citizen Kane, you are admitted to Theater 3. If you cannot attend an event, you can hand this ticket to a friend who wants to see the film instead, and there is no coordination required with the theater ahead of time. However, if the theater needs to cancel tickets for some reason, they need a way of uniquely identifying them and sharing this information between them.</p>"},{"location":"modules/ucan-spec/#object-capabilities","title":"Object Capabilities","text":"<p>Object capability (\"ocap\") systems use a combination of references, encapsulated state, and proxy forwarding. As the name implies, this is fairly close to object-oriented or actor-based systems. Object capabilities are robust, flexible, and expressive.</p> <p>To achieve these properties, object capabilities have two requirements: fail-safe, and locality preservation. The emphasis on consistency rules out partition tolerance[^pcec].</p>"},{"location":"modules/ucan-spec/#security-considerations","title":"Security Considerations","text":"<p>Each UCAN includes an assertions of what it is allowed to do. \"Proofs\" are positive evidence (elsewhere called \"witnesses\") of the possession of rights. They are cryptographically verifiable chains showing that the UCAN issuer either claims to directly own a resource, or that it was delegated to them by some claimed owner. In the most common case, the root owner's ID is the only globally unique identity for the resource.</p> <p>Root capability issuers function as verifiable, distributed roots of trust. The delegation chain is by definition a provenance log. Private keys themselves SHOULD NOT move from one context to another. Keeping keys unique to each physical device and unique per use case is RECOMMENDED to reduce opportunity for keys to leak, and limit blast radius in the case of compromises. \"Sharing authority without sharing keys\" is provided by capabilities, so there is no reason to share keys directly.</p> <p>Note that a structurally and cryptographically valid UCAN chain can be semantically invalid. The executor MUST verify the ownership of any external resources at execution time. While not possible for all use cases (e.g. replicated state machines and eventually consistent data), having the Executor be the resource itself is RECOMMENDED.</p> <p>While certificate chains go a long way toward improving security, they do not provide confinement on their own. The principle of least authority SHOULD be used when delegating a UCAN: minimizing the amount of time that a UCAN is valid for and reducing authority to the bare minimum required for the delegate to complete their task. This delegate should be trusted as little as is practical since they can further sub-delegate their authority to others without alerting their delegator. UCANs do not offer confinement (as that would require all processes to be online), so it is impossible to guarantee knowledge of all of the sub-delegations that exist. The ability to revoke some or all downstream UCANs exists as a last resort.</p>"},{"location":"modules/ucan-spec/#inversion-of-control","title":"Inversion of Control","text":"<p>Inversion of control is achieved due to two properties: self-certifying delegation and reference passing. There is no Authorization Server (AS) that sits between requestors and resources. In traditional terms, the owner of a UCAN resource is the resource server (RS) directly.</p> <p>This inverts the usual relationship between resources and users: the resource grants some (or all) authority over itself to agents, as opposed to an Authorization Server managing the relationship between them. This has several major advantages:</p> <ul> <li>Fully distributed and scalable</li> <li>Self-contained request without intermediary</li> <li>Partition tolerance, support for replicated data and machines</li> <li>Flexible granularity</li> <li>Compositionality: no distinction between resources residing together or apart</li> </ul> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502             \u2502   \u2502             \u2502   \u2502             \u2502\n\u2502             \u2502   \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502   \u2502             \u2502\n\u2502             \u2502   \u2502 \u2502  Bob's  \u2502 \u2502   \u2502             \u2502\n\u2502             \u2502   \u2502 \u2502  Photo  \u2502 \u2502   \u2502             \u2502\n\u2502             \u2502   \u2502 \u2502 Gallery \u2502 \u2502   \u2502             \u2502\n\u2502             \u2502   \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502   \u2502             \u2502\n\u2502             \u2502   \u2502             \u2502   \u2502             \u2502\n\u2502   Alice's   \u2502   \u2502    Bob's    \u2502   \u2502   Carol's   \u2502\n\u2502    Stuff    \u2502   \u2502    Stuff    \u2502   \u2502    Stuff    \u2502\n\u2502             \u2502   \u2502             \u2502   \u2502             \u2502\n\u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2510          \u2502\n\u2502     \u2502       \u2502   \u2502             \u2502   \u2502  \u2502          \u2502\n\u2502     \u2502       \u2502   \u2502         \u250c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502     \u2502       \u2502   \u2502 Alice's \u2502   \u2502   \u2502  \u2502        \u2502 \u2502\n\u2502     \u2502       \u2502   \u2502  Music  \u2502   \u2502   \u2502  \u2502Carol's \u2502 \u2502\n\u2502     \u2502       \u2502   \u2502 Player  \u2502   \u2502   \u2502  \u2502  Game  \u2502 \u2502\n\u2502     \u2502       \u2502   \u2502         \u2502   \u2502   \u2502  \u2502        \u2502 \u2502\n\u2502     \u2502       \u2502   \u2502         \u2514\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502     \u2502       \u2502   \u2502             \u2502   \u2502  \u2502          \u2502\n\u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2518          \u2502\n\u2502             \u2502   \u2502             \u2502   \u2502             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>This additionally allows UCAN to model auth for eventually consistent and replicated state.</p>"},{"location":"modules/ucan-spec/#roles","title":"Roles","text":"<p>There are several roles that an agent MAY assume:</p> Name Description Agent The general class of entities and principals that interact with a UCAN Audience The Principal delegated to in the current UCAN. Listed in the <code>aud</code> field Executor The Agent that actually performs the action described in an invocation Invoker A Principal that requests an Executor perform some action that uses the Invoker's authority Issuer The Principal of the current UCAN. Listed in the <code>iss</code> field Owner A Subject that controls some external resource Principal An agent identified by DID (listed in a UCAN's <code>iss</code> or <code>aud</code> field) Revoker The Issuer listed in a proof chain that revokes a UCAN Subject The Principal who's authority is delegated or invoked Validator Any Agent that interprets a UCAN to determine that it is valid, and which capabilities it grants <pre><code>flowchart TD\n    subgraph Agent\n        subgraph Principal\n            direction TB\n\n            subgraph Issuer\n                direction TB\n\n                subgraph Subject\n                    direction TB\n\n                    Executor\n                    Owner\n                end\n\n                Revoker\n            end\n\n            subgraph Audience\n                Invoker\n            end\n        end\n\n        Validator\n    end\n</code></pre>"},{"location":"modules/ucan-spec/#subject","title":"Subject","text":"<p>At the very least every object should have a URL</p> <p>\u2014 Alan Kay, The computer revolution hasn't happened yet</p> <p>Every Erlang process in the universe should be addressable and introspective</p> <p>\u2014 Joe Armstrong, Code Mesh 2016</p> <p>A [Subject] represents the Agent that a capability is for. A Subject MUST be referenced by DID. This behaves much like a GUID, with the addition of public key verifiability. This unforgeability prevents malicious namespace collisions which can lead to confused deputies.</p>"},{"location":"modules/ucan-spec/#resource","title":"Resource","text":"<p>A resource is some data or process that can be uniquely identified by a URI. It can be anything from a row in a database, a user account, storage quota, email address, etc. Resource MAY be as coarse or fine grained as desired. Finer-grained is RECOMMENDED where possible, as it is easier to model the principle of least authority (PoLA).</p> <p>A resource describes the noun of a capability. The resource pointer MUST be provided in URI format. Arbitrary and custom URIs MAY be used, provided that the intended recipient can decode the URI. The URI is merely a unique identifier to describe the pointer to \u2014 and within \u2014 a resource.</p> <p>Having a unique agent represent a resource (and act as its manager) is RECOMMENDED. However, to help traditional ACL-based systems transition to certificate capabilities, an agent MAY manage multiple resources, and act as the registrant in the ACL system.</p> <p>Unless explicitly stated, the Resource of a UCAN MUST be the Subject.</p>"},{"location":"modules/ucan-spec/#issuer-audience","title":"Issuer &amp; Audience","text":"<p>The Issuer (<code>iss</code>) and Audience (<code>aud</code>) can be conceptualized as the sender and receiver (respectively) of a postal letter. Every UCAN MUST be signed with the private key associated with the DID in the <code>iss</code> field.</p> <p>For example:</p> <pre><code>\"aud\": \"did:key:z6MkiTBz1ymuepAQ4HEHYSF1H8quG5GLVVQR3djdX3mDooWp\",\n\"iss\": \"did:key:zDnaerDaTF5BXEavCrfRZEk316dpbLsfPDZ3WJ5hRTPFU2169\",\n</code></pre> <p>Please see the Cryptosuite section for more detail on DIDs.</p>"},{"location":"modules/ucan-spec/#lifecycle","title":"Lifecycle","text":"<p>The UCAN lifecycle has four components:</p> Spec Description Requirement Level Delegation Pass, attenuate, and secure authority in a partition-tolerant way REQUIRED Invocation Exercise authority that has been delegated through one or more delegates REQUIRED Promise Await the result of an Invocation inside another Invocation RECOMMENDED Revocation Undo a delegation, breaking a delegation chain for malicious users RECOMMENDED <pre><code>flowchart TD\n    prm(Promise)\n    inv(Invocation)\n    del(Delegation)\n    rev(Revocation)\n\n    prm --&gt;|awaits| inv\n    del --&gt;|proves| inv\n    rev -.-&gt;|kind of| inv\n    rev --&gt;|invalidates| del\n\n    click del href \"https://github.com/ucan-wg/delegation\" \"UCAN Delegation Spec\"\n    click inv href \"https://github.com/ucan-wg/invocation\" \"UCAN Invocation Spec\"\n    click rev href \"https://github.com/ucan-wg/revocation\" \"UCAN Revocation Spec\"\n</code></pre>"},{"location":"modules/ucan-spec/#time","title":"Time","text":"<p>It is often useful to talk about a UCAN in the context of some action. For example, a UCAN delegation may be valid when it was created, but expired when invoked.</p> <pre><code>sequenceDiagram\n    Alice --&gt;&gt; Bob: Delegate\n    Bob -&gt;&gt; Bob: Validate\n    Bob --&gt;&gt; Carol: Delegate\n    Carol -&gt;&gt; Carol: Validate\n    Carol -&gt;&gt; Alice: Invoke\n    Alice -&gt;&gt; Alice: Validate\n    Alice -&gt;&gt; Alice: Execute\n</code></pre>"},{"location":"modules/ucan-spec/#validity-interval","title":"Validity Interval","text":"<p>The period of time that a capability is valid from and until. This is the range from the latest \"not before\" to the earliest expiry in the UCAN delegation chain.</p>"},{"location":"modules/ucan-spec/#delegation-time","title":"Delegation-Time","text":"<p>The moment at which a delegation is asserted. This MAY be captured by an <code>iat</code> field, but is generally superfluous to capture in the token.</p>"},{"location":"modules/ucan-spec/#invocation-time","title":"Invocation-Time","text":"<p>The moment a UCAN Invocation is created. It must be within the Validity Interval.</p>"},{"location":"modules/ucan-spec/#validation-time","title":"Validation-Time","text":"<p>Validation MAY occur at multiple points during a UCAN's lifecycle. The main two are:</p> <ul> <li>On receipt of a delegation</li> <li>When executing an invocation</li> </ul>"},{"location":"modules/ucan-spec/#execution-time","title":"Execution-Time","text":"<p>To avoid the overloaded word \"runtime\", UCAN adopts the term \"execution-time\" to express the moment that the executor attempts to use the authority captured in an invocation and associated delegation chain. Validation MUST occur at this time.</p>"},{"location":"modules/ucan-spec/#time-bounds","title":"Time Bounds","text":"<p><code>nbf</code> and <code>exp</code> stand for \"not before\" and \"expires at,\" respectively. These MUST be expressed as seconds since the Unix epoch in UTC, without time zone or other offset. Taken together, they represent the time bounds for a token. These timestamps MUST be represented as the number of integer seconds since the Unix epoch. Due to limitations[^js-num-size] in numerics for certain common languages, timestamps outside of the range from $-2^{53} \u2013 1$ to $2^{53} \u2013 1$ MUST be rejected as invalid.</p> <p>The <code>nbf</code> field is OPTIONAL. When omitted, the token MUST be treated as valid beginning from the Unix epoch. Setting the <code>nbf</code> field to a time in the future MUST delay invoking a UCAN. For example, pre-provisioning access to conference materials ahead of time but not allowing access until the day it starts is achievable with judicious use of <code>nbf</code>.</p> <p>The <code>exp</code> field is RECOMMENDED. Following the principle of least authority, it is RECOMMENDED to give a timestamp expiry for UCANs. If the token explicitly never expires, the <code>exp</code> field MUST be set to <code>null</code>. If the time is in the past at validation time, the token MUST be treated as expired and invalid.</p> <p>Keeping the window of validity as short as possible is RECOMMENDED. Limiting the time range can mitigate the risk of a malicious user abusing a UCAN. However, this is situationally dependent. It may be desirable to limit the frequency of forced reauthorizations for trusted devices. Due to clock drift, time bounds SHOULD NOT be considered exact. A buffer of \u00b160 seconds is RECOMMENDED.</p> <p>Several named points of time in the UCAN lifecycle can be found in the [high level spec][UCAN].</p> <p>Below are a couple examples:</p> <pre><code>{\n  // ...\n  \"nbf\": 1529496683,\n  \"exp\": 1575606941\n}\n</code></pre> <pre><code>{\n  // ...\n  \"exp\": 1575606941\n}\n</code></pre> <pre><code>{\n  // ...\n  \"nbf\": 1529496683,\n  \"exp\": null\n}\n</code></pre>"},{"location":"modules/ucan-spec/#lifecycle-example","title":"Lifecycle Example","text":"<p>Here is a concrete example of all stages of the UCAN lifecycle for database write access.</p> <pre><code>sequenceDiagram\n    participant Database\n\n    actor DBAgent\n    actor Alice\n    actor Bob\n\n    Note over Database, DBAgent: Set Up Agent-Owned Resource\n    DBAgent -&gt;&gt; Database: createDB()\n\n    autonumber 1\n\n    Note over DBAgent, Bob: Delegation\n    DBAgent --&gt;&gt; Alice: delegate(DBAgent, write)\n    Alice --&gt;&gt; Bob: delegate(DBAgent, write)\n\n    Note over Database, Bob: Invocation\n    Bob -&gt;&gt; DBAgent: invoke(DBAgent, [write, [key, value]], proof: [\u278a,\u278b])\n    DBAgent -&gt;&gt; Database: write(key, value)\n    DBAgent -&gt;&gt; Bob: ACK\n\n    Note over DBAgent, Bob: Revocation\n    Alice -&gt;&gt; DBAgent: revoke(\u278b, proof: [\u278a,\u278b])\n    Bob -&gt;&gt; DBAgent: invoke(DBAgent, [write, [key, newValue]], proof: [\u278a,\u278b])\n    DBAgent -X Bob: NAK(\u278f) [rejected]\n</code></pre>"},{"location":"modules/ucan-spec/#capability","title":"Capability","text":"<p>A capability is the association of an ability to a subject: <code>subject x command x policy</code>.</p> <p>The Subject and Command fields are REQUIRED. Any non-normative extensions are OPTIONAL.</p> <p>For example, a capability may used to represent the ability to send email from a certain address to others at <code>@example.com</code>.</p> Field Example Subject <code>did:key:z6MkhaXgBZDvotDkL5257faiztiGiC2QtKLGpbnnEGta2doK</code> Command <code>/msg/send</code> Policy <code>[\"or\", [\"==\", \".from\", \"mailto:me@example.com\"], [\"match\", \".cc\", \"mailto:*@example.com\"]]</code> <p>For a more complete treatment, please see the UCAN Delegation spec.</p>"},{"location":"modules/ucan-spec/#authority","title":"Authority","text":"<p>Whether to enable cooperation or to limit vulnerability, we care about authority rather than permissions. Permissions determine what actions an individual program may perform on objects it can directly access. Authority describes the effects that a program may cause on objects it can access, either directly by permission, or indirectly by permitted interactions with other programs.</p> <p>\u2014Mark Miller, Robust Composition</p> <p>The set of capabilities delegated by a UCAN is called its \"authority.\" To frame it another way, it's the set of effects that a principal can cause, and acts as a declarative description of delegated abilities.</p> <p>Merging capability authorities MUST follow set semantics, where the result includes all capabilities from the input authorities. Since broader capabilities automatically include narrower ones, this process is always additive. Capability authorities can be combined in any order, with the result always being at least as broad as each of the original authorities.</p> <pre><code>                   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2510\n                   \u2502                       \u2502  \u2502\n                   \u2502                       \u2502  \u2502\n                   \u2502                       \u2502  \u2502\n                   \u2502                       \u2502  \u2502\n                   \u2502       Subject B       \u2502  \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c \u2500 \u2500       x           \u2502  \u2502\n\u2502                       \u2502  Ability Z       \u2502  \u251c\u2500\u2500    BxZ\n\u2502                  \u2502                       \u2502  \u2502  Capability\n\u2502                       \u2502                  \u2502  \u2502\n\u2502                  \u2502                       \u2502  \u2502\n\u2502       Subject A       \u2502                  \u2502  \u2502\n\u2502           x      \u2502                       \u2502  \u2502\n\u2502       Ability Y   \u2500  \u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2518\n\u2502                       \u2502\n\u2502                       \u2502\n\u2502                       \u2502\n\u2502                       \u2502\n\u2502                       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                      \u2502\n                  AxY U BxZ\n                  Capability\n</code></pre> <p>The capability authority is the total rights of the authorization space down to the relevant volume of authorizations. Individual capabilities MAY overlap; the authority is the union. Every unique delegated capability MUST have equal or narrower capabilities from their delegator. Inside this content space, you can draw a boundary around some resource(s) (their type, identifiers, and paths or children) and their capabilities.</p>"},{"location":"modules/ucan-spec/#command","title":"Command","text":"<p>Commands are concrete messages (\"verbs\") that MUST be unambiguously interpretable by the Subject of a UCAN. Commands are REQUIRED in invocations. Some examples include <code>/msg/send</code>, <code>/crud/read</code>, and <code>/ucan/revoke</code>.</p> <p>Much like other message-passing systems, the specific resource MUST define the behavior for a particular message. For instance, <code>/crud/update</code> MAY be used to destructively update a database row, or append to a append-only log. Specific messages MAY be created at will; the only restriction is that the Executor understand how to interpret that message in the context of a specific resource.</p> <p>While arbitrary semantics MAY be described, they MUST apply to the target resource. For instance, it does not make sense to apply <code>/msg/send</code> to a typical file system.</p>"},{"location":"modules/ucan-spec/#segment-structure","title":"Segment Structure","text":"<p>Commands MUST be lowercase, and begin with a slash (<code>/</code>). Segments MUST be separated by a slash. A trailing slash MUST NOT be present. All of the following are syntactically valid Commands:</p> <ul> <li><code>/</code></li> <li><code>/crud</code></li> <li><code>/crud/create</code></li> <li><code>/stack/pop</code></li> <li><code>/crypto/sign</code></li> <li><code>/foo/bar/baz/qux/quux</code></li> <li><code>/\u307b\u3052/\u3075\u304c</code></li> </ul> <p>Segment structure is important since shorter Commands prove longer paths. For example, <code>/</code> can be used as a proof of any other Command. For example, <code>/crypto</code> MAY be used to prove <code>/crypto/sign</code> but MUST NOT prove <code>/stack/pop</code> or <code>/cryptocurrency</code>.</p>"},{"location":"modules/ucan-spec/#aka-top","title":"<code>/</code> AKA \"Top\"","text":"<p>\"Top\" (<code>/</code>) is the most powerful ability, and as such it SHOULD be handled with care and used sparingly.</p> <p>The \"top\" (or \"any\", or \"wildcard\") ability MUST be denoted <code>/</code>. This can be thought of as something akin to a super user permission in RBAC.</p> <p>The wildcard ability grants access to all other capabilities for the specified resource, across all possible namespaces. The wildcard ability is useful when \"linking\" agents by delegating all access to another device controlled by the same user, and that should behave as the same agent. It is extremely powerful, and should be used with care. Among other things, it permits the delegate to update a Subject's mutable DID document (change their private keys), revoke UCAN delegations, and use any resources delegated to the Subject by others.</p> <pre><code>%%{ init: { 'flowchart': { 'curve': 'linear' } } }%%\n\nflowchart BT\n  /\n\n  /msg --&gt; /\n  subgraph msgGraph [ ]\n    /msg/send --&gt; /msg\n    /msg/receive --&gt; /msg\n  end\n\n  /crud --&gt; /\n  subgraph crudGraph [ ]\n    /crud/read --&gt; /crud\n    /crud/mutate --&gt; /crud\n\n    subgraph mutationGraph [ ]\n        /crud/mutate/create --&gt; /crud/mutate\n        /crud/mutate/update --&gt; /crud/mutate\n        /crud/mutate/destroy --&gt; /crud/mutate\n    end\n  end\n\n  ... --&gt; /\n</code></pre>"},{"location":"modules/ucan-spec/#reserved-commands","title":"Reserved Commands","text":""},{"location":"modules/ucan-spec/#ucan-namespace","title":"<code>/ucan</code> Namespace","text":"<p>The <code>/ucan</code> Command namespace MUST be reserved. This MUST include any ability string matching the regex <code>^ucan\\/.*</code>. This is important for keeping a space for community-blessed Commands in the future, such as standard library Commands, such as Revocation.</p>"},{"location":"modules/ucan-spec/#attenuation","title":"Attenuation","text":"<p>Attenuation is the process of constraining the capabilities in a delegation chain. Each direct delegation MUST either directly restate or attenuate (diminish) its capabilities.</p>"},{"location":"modules/ucan-spec/#token-resolution","title":"Token Resolution","text":"<p>Token resolution is transport specific. The exact format is left to the relevant UCAN transport specification. At minimum, such a specification MUST define at least the following:</p> <ol> <li>Request protocol</li> <li>Response protocol</li> <li>Collections format</li> </ol> <p>Note that if an instance cannot dereference a CID at runtime, the UCAN MUST fail validation. This is consistent with the constructive semantics of UCAN.</p>"},{"location":"modules/ucan-spec/#nonce","title":"Nonce","text":"<p>The REQUIRED nonce parameter <code>nonce</code> MAY be any value. A randomly generated string is RECOMMENDED to provide a unique UCAN, though it MAY also be a monotonically increasing count of the number of links in the hash chain. This field helps prevent replay attacks and ensures a unique CID per delegation. The <code>iss</code>, <code>aud</code>, and <code>exp</code> fields together will often ensure that UCANs are unique, but adding the nonce ensures uniqueness.</p> <p>The recommended size of the nonce differs by key type. In many cases, a random 12-byte nonce is sufficient. If uncertain, check the nonce in your DID's crypto suite.</p> <p>This field SHOULD NOT be used to sign arbitrary data, such as signature challenges. See the [<code>meta</code>][Metadata] field for more.</p> <p>Here is a simple example.</p> <pre><code>{\n  // ...\n  \"nonce\": {\"/\": {\"bytes\": \"bGlnaHQgd29yay4\"}}\n}\n</code></pre>"},{"location":"modules/ucan-spec/#metadata","title":"Metadata","text":"<p>The OPTIONAL <code>meta</code> field contains a map of arbitrary metadata, facts, and proofs of knowledge. The enclosed data MUST be self-evident and externally verifiable. It MAY include information such as hash preimages, server challenges, a Merkle proof, dictionary data, etc.</p> <p>The data contained in this map MUST NOT be semantically meaningful to delegation chains.</p> <p>Below is an example:</p> <pre><code>{\n  // ...\n  \"meta\": {\n    \"challenges\": {\n      \"example.com\": \"abcdef\",\n      \"another.example.net\": \"12345\"\n    },\n    \"sha3_256\": {\n      \"B94D27B9934D3E08A52E52D7DA7DABFAC484EFE37A5380EE9088F7ACE2EFCDE9\": \"hello world\"\n    }\n  }\n}\n</code></pre>"},{"location":"modules/ucan-spec/#canonicalization","title":"Canonicalization","text":""},{"location":"modules/ucan-spec/#cryptosuite","title":"Cryptosuite","text":"<p>Across all UCAN specifications, the following cryptosuite MUST be supported:</p> Role REQUIRED Algorithms Notes Hash SHA-256 Signature Ed25519, P-256, [<code>secp256k1</code>] Preference of Ed25519 is RECOMMENDED DID [<code>did:key</code>]"},{"location":"modules/ucan-spec/#encoding","title":"Encoding","text":"<p>All UCANs MUST be canonically encoded with DAG-CBOR for signing. A UCAN MAY be presented or stored in other IPLD formats (such as DAG-JSON), but converted to DAG-CBOR for signature validation.</p>"},{"location":"modules/ucan-spec/#content-identifiers","title":"Content Identifiers","text":"<p>A UCAN token MUST be configured as follows:</p> Parameter REQUIRED Configuration Version CIDv1 Multibase [<code>base58btc</code>] Multihash SHA-256 Multicodec DAG-CBOR <p>[!NOTE] All CIDs encoded as above start with the characters <code>zdpu</code>.</p> <p>The resolution of these addresses is left to the implementation and end-user, and MAY (non-exclusively) include the following: local store, a distributed hash table (DHT), gossip network, or RESTful service.</p>"},{"location":"modules/ucan-spec/#envelope","title":"Envelope","text":"<p>All UCAN formats MUST use the following envelope format:</p> Field Type Description <code>.0</code> <code>Bytes</code> A signature by the Payload's <code>iss</code> over the <code>SigPayload</code> field <code>.1</code> <code>SigPayload</code> The content that was signed <code>.1.h</code> <code>VarsigHeader</code> The Varsig v1 header <code>.1.ucan/&lt;subspec-tag&gt;@&lt;version&gt;</code> <code>TokenPayload</code> The UCAN token payload <pre><code>flowchart TD\n    subgraph Ucan [\"UCAN Envelope\"]\n        SignatureBytes[\"Signature (raw bytes)\"]\n\n        subgraph SigPayload [\"Signature Payload\"]\n            VarsigHeader[\"Varsig Header\"]\n\n            subgraph UcanPayload [\"Token Payload\"]\n                fields[\"...\"]\n            end\n        end\n    end\n</code></pre> <p>For example:</p> <pre><code>[\n  {\n    \"/\": {\n      bytes:\n        \"7aEDQLYvb3lygk9yvAbk0OZD0q+iF9c3+wpZC4YlFThkiNShcVriobPFr/wl3akjM18VvIv/Zw2LtA4uUmB5m8PWEAU\",\n    },\n  },\n  {\n    h: { \"/\": { bytes: \"NBIFEgEAcQ\" } },\n    \"ucan/example@1.0.0-rc.1\": {\n      hello: \"world\",\n    },\n  },\n];\n</code></pre>"},{"location":"modules/ucan-spec/#payload","title":"Payload","text":"<p>A UCAN's Payload MUST contain at least the following fields:</p> Field Type Required Description <code>iss</code> <code>DID</code> Yes Issuer DID (sender) <code>aud</code> <code>DID</code> Yes Audience DID (receiver) <code>sub</code> <code>DID</code> Yes Principal that the chain is about (the [Subject]) <code>cmd</code> <code>String</code> Yes The Command to eventually invoke <code>args</code> <code>{String : Any}</code> Yes Any [Arguments] that MUST be present in the Invocation <code>nonce</code> <code>Bytes</code> Yes Nonce <code>meta</code> <code>{String : Any}</code> No [Meta] (asserted, signed data) \u2014 is not delegated authority <code>nbf</code> <code>Integer</code> (53-bits[^js-num-size]) No \"Not before\" UTC Unix Timestamp in seconds (valid from) <code>exp</code> <code>Integer \\| Null</code> (53-bits[^js-num-size]) Yes Expiration UTC Unix Timestamp in seconds (valid until)"},{"location":"modules/ucan-spec/#implementation-recommendations","title":"Implementation Recommendations","text":""},{"location":"modules/ucan-spec/#delegation-store","title":"Delegation Store","text":"<p>A validator MAY keep a local store of UCANs that it has received. UCANs are immutable but also time-bound so that this store MAY evict expired or revoked UCANs.</p> <p>This store SHOULD be indexed by CID (content addressing). Multiple indices built on top of this store MAY be used to improve capability search or selection performance.</p>"},{"location":"modules/ucan-spec/#memoized-validation","title":"Memoized Validation","text":"<p>Aside from revocation, capability validation is idempotent. Marking a CID (or capability index inside that CID) as valid acts as memoization, obviating the need to check the entire structure on every validation. This extends to distinct UCANs that share a proof: if the proof was previously reviewed and is not revoked, it is RECOMMENDED to consider it valid immediately.</p> <p>Revocation is irreversible. Suppose the validator learns of revocation by UCAN CID. In that case, the UCAN and all of its derivatives in such a cache MUST be marked as invalid, and all validations immediately fail without needing to walk the entire structure.</p>"},{"location":"modules/ucan-spec/#replay-attack-prevention","title":"Replay Attack Prevention","text":"<p>Replay attack prevention is REQUIRED. Every UCAN token MUST hash to a unique CIDv1. Some simple strategies for implementing uniqueness tracking include maintaining a set of previously seen CIDs, or requiring that nonces be monotonically increasing per principal. This MAY be the same structure as a validated UCAN memoization table (if one is implemented).</p> <p>Maintaining a secondary token expiry index is RECOMMENDED. This enables garbage collection and more efficient search. In cases of very large stores, normal cache performance techniques MAY be used, such as Bloom filters, multi-level caches, and so on.</p>"},{"location":"modules/ucan-spec/#beyond-single-system-image","title":"Beyond Single System Image","text":"<p>As we continue to increase the number of globally connected devices, we must embrace a design that considers every single member in the system as the primary site for the data that it is generates. It is completely impractical that we can look at a single, or a small number, of globally distributed data centers as the primary site for all global information that we desire to perform computations with.</p> <p>\u2014Meiklejohn, A Certain Tendency Of The Database Community</p> <p>Unlike many authorization systems where a service controls access to resources in their care, location-independent, offline, and leaderless resources require control to live with the user. Therefore, the same data MAY be used across many applications, data stores, and users. Since they don't have a single location, applying UCAN to RSMs and CRDTs MAY be modelled by lifting the requirement that the Executor be the Subject.</p> <p>Ultimately this comes down to a question of push vs pull. In push, the subject MUST be the specific site being pushed to (\"I command you to apply the following updates to your state\").</p> <p>Pull is the broad class of situations where an Invoker doesn't require that a particular replica apply its state. Applying a change to a local CRDT replica and maintaining a UCAN invocation log is a valid update to \"the CRDT\": a version of the CRDT Subject exists locally even if the Subject's private key is not present. Gossiping these changes among agents allows each to apply changes that it becomes aware of. Thanks to the invocation log (or equivalent integrated directly into the CRDT), provenance of authority is made transparent.</p> <pre><code>sequenceDiagram\n    participant CRDT as Initial Grow-Only Set (CRDT)\n\n    actor Alice\n    actor Bob\n    actor Carol\n\n    autonumber\n\n    Note over CRDT, Bob: Setup\n    CRDT --&gt;&gt; Alice: delegate(CRDT_ID, merge)\n    CRDT --&gt;&gt; Bob: delegate(CRDT_ID, merge)\n\n    Note over Bob, Carol: Bob Invites Carol\n    Bob --&gt;&gt; Carol: delegate(CRDT_ID, merge)\n\n    Note over Alice, Carol: Direct P2P Gossip\n    Carol -&gt;&gt; Bob: invoke(CRDT_ID, merge, {\"Carrot\"}, proof: [\u278b,\u2778])\n    Alice -&gt;&gt; Carol: invoke(CRDT_ID, merge, {\"Apple\"}}, proof: [\u278a])\n    Bob -&gt;&gt; Alice: invoke(CRDT_ID, merge, {\"Banana\", \"Carrot\"}, proof: [\u278b])\n</code></pre>"},{"location":"modules/ucan-spec/#wrapping-existing-systems","title":"Wrapping Existing Systems","text":"<p>In the RECOMMENDED scenario, the agent controlling a resource has a unique reference to it. This is always possible in a system that has adopted capabilities end-to-end.</p> <p>Interacting with existing systems MAY require relying on ambient authority contained in an ACL, non-unique reference, or other authorization logic. These cases are still compatible with UCAN, but the security guarantees are weaker since 1. the surface area is larger, and 2. part of the auth system lives outside UCAN.</p> <pre><code>sequenceDiagram\n    participant Database\n    participant ACL as External Auth System\n\n    actor DBAgent\n    actor Alice\n    actor Bob\n\n    Note over ACL, DBAgent: Setup\n    DBAgent -&gt;&gt; ACL: signup(DBAgent)\n    ACL -&gt;&gt; ACL: register(DBAgent)\n\n    autonumber 1\n\n    Note over DBAgent, Bob: Delegation\n    DBAgent --&gt;&gt; Alice: delegate(DBAgent, write)\n    Alice --&gt;&gt; Bob: delegate(DBAgent, write)\n\n    Note over Database, Bob: Invocation\n    Bob -&gt;&gt;+ DBAgent: invoke(DBAgent, [write, key, value], proof: [\u278a,\u278b])\n\n    critical External System\n        DBAgent -&gt;&gt; ACL: getToken(write, key, AuthGrant)\n        ACL -&gt;&gt; DBAgent: AccessToken\n\n        DBAgent -&gt;&gt; Database: request(write, value, AccessToken)\n        Database -&gt;&gt; DBAgent: ACK\n    end\n\n    DBAgent -&gt;&gt;- Bob: ACK\n</code></pre>"},{"location":"modules/ucan-spec/#faq","title":"FAQ","text":""},{"location":"modules/ucan-spec/#what-prevents-an-unauthorized-party-from-using-an-intercepted-ucan","title":"What prevents an unauthorized party from using an intercepted UCAN?","text":"<p>UCANs always contain information about the sender and receiver. A UCAN is signed by the sender (the <code>iss</code> field DID) and can only be created by an agent in possession of the relevant private key. The recipient (the <code>aud</code> field DID) is required to check that the field matches their DID. These two checks together secure the certificate against use by an unauthorized party. UCAN Invocations prevent use by an unauthorized party by signing over a request to use the capability granted in a delegation chain.</p>"},{"location":"modules/ucan-spec/#what-prevents-replay-attacks-on-the-invocation-use-case","title":"What prevents replay attacks on the invocation use case?","text":"<p>All UCAN Invocations MUST have a unique CID. The executing agent MUST check this validation uniqueness against a local store of unexpired UCAN hashes.</p> <p>This is not a concern when simply delegating since receiving a delegation is idempotent.</p>"},{"location":"modules/ucan-spec/#is-ucan-secure-against-person-in-the-middle-attacks","title":"Is UCAN secure against person-in-the-middle attacks?","text":"<p>UCAN does not have any special protection against person-in-the-middle (PITM) attacks.</p> <p>If a PITM attack was successfully performed on a UCAN delegation, the proof chain would contain the attacker's DID(s). It is possible to detect this scenario and revoke the relevant UCAN but this does require special inspection of the topmost <code>iss</code> field to check if it is the expected DID. Therefore, it is strongly RECOMMENDED to only delegate UCANs to agents that are both trusted and authenticated and over secure channels.</p>"},{"location":"modules/ucan-spec/#can-my-implementation-support-more-cryptographic-algorithms","title":"Can my implementation support more cryptographic algorithms?","text":"<p>It is possible to use other algorithms, but doing so limits interoperability with the broader UCAN ecosystem. This is thus considered \"off spec\" (i.e. non-interoperable). If you choose to extend UCAN with additional algorithms, you MUST include this metadata in the (self-describing) Varsig header.</p>"},{"location":"modules/ucan-spec/#related-work-and-prior-art","title":"Related Work and Prior Art","text":"<p>SPKI/SDSI is closely related to UCAN. A different encoding format is used, and some details vary (such as a delegation-locking bit), but the core idea and general usage pattern are very close. UCAN can be seen as making these ideas more palatable to a modern audience and adding a few features such as content IDs that were less widespread at the time SPKI/SDSI were written.</p> <p>ZCAP-LD is closely related to UCAN. The primary differences are in formatting, addressing by URL instead of CID, the mechanism of separating invocation from authorization, and single versus multiple proofs.</p> <p>CACAO is a translation of many of these ideas to a cross-blockchain delegated bearer token model. It contains the same basic concepts as UCAN delegation, but is aimed at small messages and identities that are rooted in mutable documents rooted on a blockchain and lacks the ability to subdelegate capabilities.</p> <p>Local-First Auth is a non-certificate-based approach, instead relying on a CRDT to build up a list of group members, devices, and roles. It has a friendly invitation mechanism based on a Seitan token exchange. It is also straightforward to see which users have access to what, avoiding the confinement problem seen in many decentralized auth systems.</p> <p>Macaroon is a MAC-based capability and cookie system aimed at distributing authority across services in a trusted network (typically in the context of a Cloud). By not relying on asymmetric signatures, Macaroons achieve excellent space savings and performance, given that the MAC can be checked against the relevant services during discharge. The authority is rooted in an originating server rather than with an end-user.</p> <p>Biscuit uses Datalog to describe capabilities. It has a specialized format but is otherwise in line with UCAN.</p> <p>Verifiable credentials are a solution for data about people or organizations. However, they are aimed at a related-but-distinct problem: asserting attributes about the holder of a DID, including things like work history, age, and membership.</p>"},{"location":"modules/ucan-spec/#acknowledgments","title":"Acknowledgments","text":"<p>Thank you to Brendan O'Brien for real-world feedback, technical collaboration, and implementing the first Golang UCAN library.</p> <p>Thank you Blaine Cook for the real-world feedback, ideas on future features, and lessons from other auth standards.</p> <p>Many thanks to Hugo Dias, Mikael Rogers, and the entire DAG House team for the real world feedback, and finding inventive new use cases.</p> <p>Thank to Hannah Howard and Alan Shaw at Storacha for their team's feedback from real world use cases.</p> <p>Many thanks to Brian Ginsburg and Steven Vandevelde for their many copy edits, feedback from real world usage, maintenance of the TypeScript implementation, and tools such as ucan.xyz.</p> <p>Many thanks to Christopher Joel for his real-world feedback, raising many pragmatic considerations, and the Rust implementation and related crates.</p> <p>Many thanks to Christine Lemmer-Webber for her handwritten(!) feedback on the design of UCAN, spearheading the OCapN initiative, and her related work on ZCAP-LD.</p> <p>Many thanks to Alan Karp for sharing his vast experience with capability-based authorization, patterns, and many right words for us to search for.</p> <p>Thanks to Benjamin Goering for the many community threads and connections to W3C standards.</p> <p>Thanks to Juan Caballero for the numerous questions, clarifications, and general advice on putting together a comprehensible spec.</p> <p>Thank you Dan Finlay for being sufficiently passionate about OCAP that we realized that capability systems had a real chance of adoption in an ACL-dominated world.</p> <p>Thanks to Peter van Hardenberg and Martin Kleppmann of Ink &amp; Switch for conversations exploring options for access control on CRDTs and local-first applications.</p> <p>Thanks to the entire SPKI WG for their closely related pioneering work.</p> <p>We want to especially recognize Mark Miller for his numerous contributions to the field of distributed auth, programming languages, and networked security writ large.</p> <p>[^js-num-size]: JavaScript has a single numeric type ([<code>Number</code>][JS Number]) for both integers and floats. This representation is defined as a IEEE-754 double-precision floating point number, which has a 53-bit significand.</p> <p>[^pcec]: To be precise, this is a PC/EC system, which is a critical trade-off for many systems. UCAN can be used to model both PC/EC and PA/EL, but is most typically PC/EL.</p>"},{"location":"tools/cosmos-proto/","title":"Protocol Buffers in Cosmos SDK","text":""},{"location":"tools/cosmos-proto/#overview","title":"Overview","text":"<p>The Cosmos SDK uses Protocol Buffers for serialization and API definitions. Generation is handled via a Docker image: <code>ghcr.io/cosmos/proto-builder:0.15.x</code>.</p>"},{"location":"tools/cosmos-proto/#generation-tools","title":"Generation Tools","text":"<ul> <li>Buf: Primary tool for protobuf management</li> <li>protocgen.sh: Core generation script in <code>scripts/</code> </li> <li>Makefile Commands: Standard commands for generate, lint, format</li> </ul>"},{"location":"tools/cosmos-proto/#key-components","title":"Key Components","text":""},{"location":"tools/cosmos-proto/#buf-configuration","title":"Buf Configuration","text":"<ol> <li>Workspace Setup</li> <li>Root level buf workspace configuration</li> <li> <p>Manages multiple protobuf directories</p> </li> <li> <p>Directory Structure <code>proto/    \u251c\u2500\u2500 buf.gen.gogo.yaml    # GoGo Protobuf generation    \u251c\u2500\u2500 buf.gen.pulsar.yaml  # Pulsar API generation      \u251c\u2500\u2500 buf.gen.swagger.yaml # OpenAPI/Swagger docs    \u251c\u2500\u2500 buf.lock            # Dependencies    \u251c\u2500\u2500 buf.yaml            # Core configuration    \u251c\u2500\u2500 cosmos/            # Core protos    \u2514\u2500\u2500 tendermint/        # Consensus protos</code></p> </li> <li> <p>Module Protos</p> </li> <li>Located in <code>x/{moduleName}/proto</code></li> <li>Module-specific message definitions</li> </ol>"},{"location":"tools/cosmos-proto/#bufgengogoyaml","title":"<code>buf.gen.gogo.yaml</code>","text":"<p><code>buf.gen.gogo.yaml</code> defines how the protobuf files should be generated for use with in the module. This file uses gogoproto, a separate generator from the google go-proto generator that makes working with various objects more ergonomic, and it has more performant encode and decode steps</p> <p>```go reference https://github.com/cosmos/cosmos-sdk/blob/main/proto/buf.gen.gogo.yaml#L1-L9</p> <pre><code>\n#### `buf.gen.pulsar.yaml`\n\n`buf.gen.pulsar.yaml` defines how protobuf files should be generated using the [new golang apiv2 of protobuf](https://go.dev/blog/protobuf-apiv2). This generator is used instead of the google go-proto generator because it has some extra helpers for Cosmos SDK applications and will have more performant encode and decode than the google go-proto generator. You can follow the development of this generator [here](https://github.com/cosmos/cosmos-proto).\n\n```go reference\nhttps://github.com/cosmos/cosmos-sdk/blob/main/proto/buf.gen.pulsar.yaml#L1-L18\n</code></pre>"},{"location":"tools/cosmos-proto/#bufgenswaggeryaml","title":"<code>buf.gen.swagger.yaml</code>","text":"<p><code>buf.gen.swagger.yaml</code> generates the swagger documentation for the query and messages of the chain. This will only define the REST API end points that were defined in the query and msg servers. You can find examples of this here</p> <p>```go reference https://github.com/cosmos/cosmos-sdk/blob/main/proto/buf.gen.swagger.yaml#L1-L6</p> <pre><code>\n#### `buf.lock`\n\nThis is an autogenerated file based off the dependencies required by the `.gen` files. There is no need to copy the current one. If you depend on cosmos-sdk proto definitions a new entry for the Cosmos SDK will need to be provided. The dependency you will need to use is `buf.build/cosmos/cosmos-sdk`.\n\n```go reference\nhttps://github.com/cosmos/cosmos-sdk/blob/main/proto/buf.lock#L1-L16\n</code></pre>"},{"location":"tools/cosmos-proto/#bufyaml","title":"<code>buf.yaml</code>","text":"<p><code>buf.yaml</code> defines the name of your package, which breakage checker to use and how to lint your protobuf files.</p> <p>It is advised to use a tagged version of the buf modules corresponding to the version of the Cosmos SDK being are used.</p> <p>```go reference https://github.com/cosmos/cosmos-sdk/blob/main/proto/buf.yaml#L1-L24</p> <pre><code>\nWe use a variety of linters for the Cosmos SDK protobuf files. The repo also checks this in ci.\nA reference to the github actions can be found [here](https://github.com/cosmos/cosmos-sdk/blob/main/.github/workflows/proto.yml#L1-L32)\n\n# ORM\n\nThe Cosmos SDK ORM is a state management library that provides a rich, but opinionated set of tools for managing a\nmodule's state. It provides support for:\n\n- type safe management of state\n- multipart keys\n- secondary indexes\n- unique indexes\n- easy prefix and range queries\n- automatic genesis import/export\n- automatic query services for clients, including support for light client proofs (still in development)\n- indexing state data in external databases (still in development)\n\n## Design and Philosophy\n\nThe ORM's data model is inspired by the relational data model found in SQL databases. The core abstraction is a table\nwith a primary key and optional secondary indexes.\n\nBecause the Cosmos SDK uses protobuf as its encoding layer, ORM tables are defined directly in .proto files using\nprotobuf options. Each table is defined by a single protobuf `message` type and a schema of multiple tables is\nrepresented by a single .proto file.\n\nTable structure is specified in the same file where messages are defined in order to make it easy to focus on better\ndesign of the state layer. Because blockchain state layout is part of the public API for clients (TODO: link to docs on\nlight client proofs), it is important to think about the state layout as being part of the public API of a module.\nChanging the state layout actually breaks clients, so it is ideal to think through it carefully up front and to aim for\na design that will eliminate or minimize breaking changes down the road. Also, good design of state enables building\nmore performant and sophisticated applications. Providing users with a set of tools inspired by relational databases\nwhich have a long history of database design best practices and allowing schema to be specified declaratively in a\nsingle place are design choices the ORM makes to enable better design and more durable APIs.\n\nAlso, by only supporting the table abstraction as opposed to key-value pair maps, it is easy to add to new\ncolumns/fields to any data structure without causing a breaking change and the data structures can easily be indexed in\nany off-the-shelf SQL database for more sophisticated queries.\n\nThe encoding of fields in keys is designed to support ordered iteration for all protobuf primitive field types\nexcept for `bytes` as well as the well-known types `google.protobuf.Timestamp` and `google.protobuf.Duration`. Encodings\nare optimized for storage space when it makes sense (see the documentation in `cosmos/orm/v1/orm.proto` for more details)\nand table rows do not use extra storage space to store key fields in the value.\n\nWe recommend that users of the ORM attempt to follow database design best practices such as\n[normalization](https://en.wikipedia.org/wiki/Database_normalization) (at least 1NF).\nFor instance, defining `repeated` fields in a table is considered an anti-pattern because breaks first normal form (1NF).\nAlthough we support `repeated` fields in tables, they cannot be used as key fields for this reason. This may seem\nrestrictive but years of best practice (and also experience in the SDK) have shown that following this pattern\nleads to easier to maintain schemas.\n\nTo illustrate the motivation for these principles with an example from the SDK, historically balances were stored\nas a mapping from account -&gt; map of denom to amount. This did not scale well because an account with 100 token balances\nneeded to be encoded/decoded every time a single coin balance changed. Now balances are stored as account,denom -&gt; amount\nas in the example above. With the ORM's data model, if we wanted to add a new field to `Balance` such as\n`unlocked_balance` (if vesting accounts were redesigned in this way), it would be easy to add it to this table without\nrequiring a data migration. Because of the ORM's optimizations, the account and denom are only stored in the key part\nof storage and not in the value leading to both a flexible data model and efficient usage of storage.\n\n## Defining Tables\n\nTo define a table:\n\n1. create a .proto file to describe the module's state (naming it `state.proto` is recommended for consistency),\n   and import \"cosmos/orm/v1/orm.proto\", ex:\n\n```protobuf\nsyntax = \"proto3\";\npackage bank_example;\n\nimport \"cosmos/orm/v1/orm.proto\";\n</code></pre> <ol> <li>define a <code>message</code> for the table, ex:</li> </ol> <pre><code>message Balance {\n  bytes account = 1;\n  string denom = 2;\n  uint64 balance = 3;\n}\n</code></pre> <ol> <li>add the <code>cosmos.orm.v1.table</code> option to the table and give the table an <code>id</code> unique within this .proto file:</li> </ol> <pre><code>message Balance {\n  option (cosmos.orm.v1.table) = {\n    id: 1\n  };\n\n  bytes account = 1;\n  string denom = 2;\n  uint64 balance = 3;\n}\n</code></pre> <ol> <li>define the primary key field or fields, as a comma-separated list of the fields from the message which should make    up the primary key:</li> </ol> <pre><code>message Balance {\n  option (cosmos.orm.v1.table) = {\n    id: 1\n    primary_key: { fields: \"account,denom\" }\n  };\n\n  bytes account = 1;\n  string denom = 2;\n  uint64 balance = 3;\n}\n</code></pre> <ol> <li>add any desired secondary indexes by specifying an <code>id</code> unique within the table and a comma-separate list of the    index fields:</li> </ol> <pre><code>message Balance {\n  option (cosmos.orm.v1.table) = {\n    id: 1;\n    primary_key: { fields: \"account,denom\" }\n    index: { id: 1 fields: \"denom\" } // this allows querying for the accounts which own a denom\n  };\n\n  bytes account = 1;\n  string denom   = 2;\n  uint64 amount  = 3;\n}\n</code></pre>"},{"location":"tools/cosmos-proto/#auto-incrementing-primary-keys","title":"Auto-incrementing Primary Keys","text":"<p>A common pattern in SDK modules and in database design is to define tables with a single integer <code>id</code> field with an automatically generated primary key. In the ORM we can do this by setting the <code>auto_increment</code> option to <code>true</code> on the primary key, ex:</p> <pre><code>message Account {\n  option (cosmos.orm.v1.table) = {\n    id: 2;\n    primary_key: { fields: \"id\", auto_increment: true }\n  };\n\n  uint64 id = 1;\n  bytes address = 2;\n}\n</code></pre>"},{"location":"tools/cosmos-proto/#unique-indexes","title":"Unique Indexes","text":"<p>A unique index can be added by setting the <code>unique</code> option to <code>true</code> on an index, ex:</p> <pre><code>message Account {\n  option (cosmos.orm.v1.table) = {\n    id: 2;\n    primary_key: { fields: \"id\", auto_increment: true }\n    index: {id: 1, fields: \"address\", unique: true}\n  };\n\n  uint64 id = 1;\n  bytes address = 2;\n}\n</code></pre>"},{"location":"tools/cosmos-proto/#singletons","title":"Singletons","text":"<p>The ORM also supports a special type of table with only one row called a <code>singleton</code>. This can be used for storing module parameters. Singletons only need to define a unique <code>id</code> and that cannot conflict with the id of other tables or singletons in the same .proto file. Ex:</p> <pre><code>message Params {\n  option (cosmos.orm.v1.singleton) = {\n    id: 3;\n  };\n\n  google.protobuf.Duration voting_period = 1;\n  uint64 min_threshold = 2;\n}\n</code></pre>"},{"location":"tools/cosmos-proto/#running-codegen","title":"Running Codegen","text":"<p>NOTE: the ORM will only work with protobuf code that implements the google.golang.org/protobuf API. That means it will not work with code generated using gogo-proto.</p> <p>To install the ORM's code generator, run:</p> <pre><code>go install cosmossdk.io/orm/cmd/protoc-gen-go-cosmos-orm@latest\n</code></pre> <p>The recommended way to run the code generator is to use buf build. This is an example <code>buf.gen.yaml</code> that runs <code>protoc-gen-go</code>, <code>protoc-gen-go-grpc</code> and <code>protoc-gen-go-cosmos-orm</code> using buf managed mode:</p> <pre><code>version: v1\nmanaged:\n  enabled: true\n  go_package_prefix:\n    default: foo.bar/api # the go package prefix of your package\n    override:\n      buf.build/cosmos/cosmos-sdk: cosmossdk.io/api # required to import the Cosmos SDK api module\nplugins:\n  - name: go\n    out: .\n    opt: paths=source_relative\n  - name: go-grpc\n    out: .\n    opt: paths=source_relative\n  - name: go-cosmos-orm\n    out: .\n    opt: paths=source_relative\n</code></pre>"},{"location":"tools/cosmos-proto/#using-the-orm-in-a-module","title":"Using the ORM in a module","text":""},{"location":"tools/cosmos-proto/#initialization","title":"Initialization","text":"<p>To use the ORM in a module, first create a <code>ModuleSchemaDescriptor</code>. This tells the ORM which .proto files have defined an ORM schema and assigns them all a unique non-zero id. Ex:</p> <pre><code>var MyModuleSchema = &amp;ormv1alpha1.ModuleSchemaDescriptor{\n    SchemaFile: []*ormv1alpha1.ModuleSchemaDescriptor_FileEntry{\n        {\n            Id:            1,\n            ProtoFileName: mymodule.File_my_module_state_proto.Path(),\n        },\n    },\n}\n</code></pre> <p>In the ORM generated code for a file named <code>state.proto</code>, there should be an interface <code>StateStore</code> that got generated with a constructor <code>NewStateStore</code> that takes a parameter of type <code>ormdb.ModuleDB</code>. Add a reference to <code>StateStore</code> to your module's keeper struct. Ex:</p> <pre><code>type Keeper struct {\n    db StateStore\n}\n</code></pre> <p>Then instantiate the <code>StateStore</code> instance via an <code>ormdb.ModuleDB</code> that is instantiated from the <code>SchemaDescriptor</code> above and one or more store services from <code>cosmossdk.io/core/store</code>. Ex:</p> <pre><code>func NewKeeper(storeService store.KVStoreService) (*Keeper, error) {\n    modDb, err := ormdb.NewModuleDB(MyModuleSchema, ormdb.ModuleDBOptions{KVStoreService: storeService})\n    if err != nil {\n        return nil, err\n    }\n    db, err := NewStateStore(modDb)\n    if err != nil {\n        return nil, err\n    }\n    return Keeper{db: db}, nil\n}\n</code></pre>"},{"location":"tools/cosmos-proto/#using-the-generated-code","title":"Using the generated code","text":"<p>The generated code for the ORM contains methods for inserting, updating, deleting and querying table entries. For each table in a .proto file, there is a type-safe table interface implemented in generated code. For instance, for a table named <code>Balance</code> there should be a <code>BalanceTable</code> interface that looks like this:</p> <pre><code>type BalanceTable interface {\n    Insert(ctx context.Context, balance *Balance) error\n    Update(ctx context.Context, balance *Balance) error\n    Save(ctx context.Context, balance *Balance) error\n    Delete(ctx context.Context, balance *Balance) error\n    Has(ctx context.Context, account []byte, denom string) (found bool, err error)\n    // Get returns nil and an error which responds true to ormerrors.IsNotFound() if the record was not found.\n    Get(ctx context.Context, account []byte, denom string) (*Balance, error)\n    List(ctx context.Context, prefixKey BalanceIndexKey, opts ...ormlist.Option) (BalanceIterator, error)\n    ListRange(ctx context.Context, from, to BalanceIndexKey, opts ...ormlist.Option) (BalanceIterator, error)\n    DeleteBy(ctx context.Context, prefixKey BalanceIndexKey) error\n    DeleteRange(ctx context.Context, from, to BalanceIndexKey) error\n\n    doNotImplement()\n}\n</code></pre> <p>This <code>BalanceTable</code> should be accessible from the <code>StateStore</code> interface (assuming our file is named <code>state.proto</code>) via a <code>BalanceTable()</code> accessor method. If all the above example tables/singletons were in the same <code>state.proto</code>, then <code>StateStore</code> would get generated like this:</p> <pre><code>type BankStore interface {\n    BalanceTable() BalanceTable\n    AccountTable() AccountTable\n    ParamsTable() ParamsTable\n\n    doNotImplement()\n}\n</code></pre> <p>So to work with the <code>BalanceTable</code> in a keeper method we could use code like this:</p> <pre><code>func (k keeper) AddBalance(ctx context.Context, acct []byte, denom string, amount uint64) error {\n    balance, err := k.db.BalanceTable().Get(ctx, acct, denom)\n    if err != nil &amp;&amp; !ormerrors.IsNotFound(err) {\n        return err\n    }\n\n    if balance == nil {\n        balance = &amp;Balance{\n            Account: acct,\n            Denom:   denom,\n            Amount:  amount,\n        }\n    } else {\n        balance.Amount = balance.Amount + amount\n    }\n\n    return k.db.BalanceTable().Save(ctx, balance)\n}\n</code></pre> <p><code>List</code> methods take <code>IndexKey</code> parameters. For instance, <code>BalanceTable.List</code> takes <code>BalanceIndexKey</code>. <code>BalanceIndexKey</code> let's represent index keys for the different indexes (primary and secondary) on the <code>Balance</code> table. The primary key in the <code>Balance</code> table gets a struct <code>BalanceAccountDenomIndexKey</code> and the first index gets an index key <code>BalanceDenomIndexKey</code>. If we wanted to list all the denoms and amounts that an account holds, we would use <code>BalanceAccountDenomIndexKey</code> with a <code>List</code> query just on the account prefix. Ex:</p> <pre><code>it, err := keeper.db.BalanceTable().List(ctx, BalanceAccountDenomIndexKey{}.WithAccount(acct))\n</code></pre>"},{"location":"tools/cosmos-proto/#sidebar_position-1","title":"sidebar_position: 1","text":""},{"location":"tools/cosmos-proto/#protocolbuffer-annotations","title":"ProtocolBuffer Annotations","text":"<p>This document explains the various protobuf scalars that have been added to make working with protobuf easier for Cosmos SDK application developers</p>"},{"location":"tools/cosmos-proto/#signer","title":"Signer","text":"<p>Signer specifies which field should be used to determine the signer of a message for the Cosmos SDK. This field can be used for clients as well to infer which field should be used to determine the signer of a message.</p> <p>Read more about the signer field here.</p> <p>```protobuf reference https://github.com/cosmos/cosmos-sdk/blob/e6848d99b55a65d014375b295bdd7f9641aac95e/proto/cosmos/bank/v1beta1/tx.proto#L40</p> <pre><code>\n```proto\noption (cosmos.msg.v1.signer) = \"from_address\";\n</code></pre>"},{"location":"tools/cosmos-proto/#scalar","title":"Scalar","text":"<p>The scalar type defines a way for clients to understand how to construct protobuf messages according to what is expected by the module and sdk.</p> <pre><code>(cosmos_proto.scalar) = \"cosmos.AddressString\"\n</code></pre> <p>Example of account address string scalar:</p> <p>```proto reference https://github.com/cosmos/cosmos-sdk/blob/e6848d99b55a65d014375b295bdd7f9641aac95e/proto/cosmos/bank/v1beta1/tx.proto#L46</p> <pre><code>\nExample of validator address string scalar:\n\n```proto reference\nhttps://github.com/cosmos/cosmos-sdk/blob/e8f28bf5db18b8d6b7e0d94b542ce4cf48fed9d6/proto/cosmos/distribution/v1beta1/query.proto#L87\n</code></pre> <p>Example of pubkey scalar:</p> <p>```proto reference https://github.com/cosmos/cosmos-sdk/blob/11068bfbcd44a7db8af63b6a8aa079b1718f6040/proto/cosmos/staking/v1beta1/tx.proto#L94</p> <pre><code>\nExample of Decimals scalar:\n\n```proto reference\nhttps://github.com/cosmos/cosmos-sdk/blob/e8f28bf5db18b8d6b7e0d94b542ce4cf48fed9d6/proto/cosmos/distribution/v1beta1/distribution.proto#L26\n</code></pre> <p>Example of Int scalar:</p> <p>```proto reference https://github.com/cosmos/cosmos-sdk/blob/e8f28bf5db18b8d6b7e0d94b542ce4cf48fed9d6/proto/cosmos/gov/v1/gov.proto#L137</p> <pre><code>\nThere are a few options for what can be provided as a scalar: `cosmos.AddressString`, `cosmos.ValidatorAddressString`, `cosmos.ConsensusAddressString`, `cosmos.Int`, `cosmos.Dec`.\n\n## Implements_Interface\n\nImplement interface is used to provide information to client tooling like [telescope](https://github.com/cosmology-tech/telescope) on how to encode and decode protobuf messages.\n\n```proto\noption (cosmos_proto.implements_interface) = \"cosmos.auth.v1beta1.AccountI\";\n</code></pre>"},{"location":"tools/cosmos-proto/#methodfieldmessage-added-in","title":"Method,Field,Message Added In","text":"<p><code>method_added_in</code>, <code>field_added_in</code> and <code>message_added_in</code> are annotations to denotate to clients that a field has been supported in a later version. This is useful when new methods or fields are added in later versions and that the client needs to be aware of what it can call.</p> <p>The annotation should be worded as follow:</p> <pre><code>option (cosmos_proto.method_added_in) = \"cosmos-sdk v0.50.1\";\noption (cosmos_proto.method_added_in) = \"x/epochs v1.0.0\";\noption (cosmos_proto.method_added_in) = \"simapp v24.0.0\";\n</code></pre>"},{"location":"tools/cosmos-proto/#amino","title":"Amino","text":"<p>The amino codec was removed in <code>v0.50+</code>, this means there is not a need register <code>legacyAminoCodec</code>. To replace the amino codec, Amino protobuf annotations are used to provide information to the amino codec on how to encode and decode protobuf messages.</p> <p>:::note Amino annotations are only used for backwards compatibility with amino. New modules are not required use amino annotations. :::</p> <p>The below annotations are used to provide information to the amino codec on how to encode and decode protobuf messages in a backwards compatible manner.</p>"},{"location":"tools/cosmos-proto/#name","title":"Name","text":"<p>Name specifies the amino name that would show up for the user in order for them see which message they are signing.</p> <pre><code>option (amino.name) = \"cosmos-sdk/BaseAccount\";\n</code></pre> <p>```proto reference https://github.com/cosmos/cosmos-sdk/blob/e8f28bf5db18b8d6b7e0d94b542ce4cf48fed9d6/proto/cosmos/bank/v1beta1/tx.proto#L41</p> <pre><code>\n### Field_Name\n\nField name specifies the amino name that would show up for the user in order for them see which field they are signing.\n\n```proto\nuint64 height = 1 [(amino.field_name) = \"public_key\"];\n</code></pre> <p>```proto reference https://github.com/cosmos/cosmos-sdk/blob/e8f28bf5db18b8d6b7e0d94b542ce4cf48fed9d6/proto/cosmos/distribution/v1beta1/distribution.proto#L166</p> <pre><code>\n### Dont_OmitEmpty\n\nDont omitempty specifies that the field should not be omitted when encoding to amino.\n\n```proto\nrepeated cosmos.base.v1beta1.Coin amount = 3 [(amino.dont_omitempty)   = true];\n</code></pre> <p>```proto reference https://github.com/cosmos/cosmos-sdk/blob/e8f28bf5db18b8d6b7e0d94b542ce4cf48fed9d6/proto/cosmos/bank/v1beta1/bank.proto#L56</p> <pre><code>\n### Encoding\n\nEncoding instructs the amino json marshaler how to encode certain fields that may differ from the standard encoding behaviour. The most common example of this is how `repeated cosmos.base.v1beta1.Coin` is encoded when using the amino json encoding format. The `legacy_coins` option tells the json marshaler [how to encode a null slice](https://github.com/cosmos/cosmos-sdk/blob/e8f28bf5db18b8d6b7e0d94b542ce4cf48fed9d6/x/tx/signing/aminojson/json_marshal.go#L65) of `cosmos.base.v1beta1.Coin`.\n\n```proto\n(amino.encoding)         = \"legacy_coins\",\n</code></pre> <p>```proto reference https://github.com/cosmos/cosmos-sdk/blob/e8f28bf5db18b8d6b7e0d94b542ce4cf48fed9d6/proto/cosmos/bank/v1beta1/genesis.proto#L23</p> <pre><code>\nAnother example is a protobuf `bytes` that contains a valid JSON document.\nThe `inline_json` option tells the json marshaler to embed the JSON bytes into the wrapping document without escaping.\n\n```proto\n(amino.encoding)         = \"inline_json\",\n</code></pre> <p>E.g. the bytes containing <code>{\"foo\":123}</code> in the <code>envelope</code> field would lead to the following JSON:</p> <pre><code>{\n  \"envelope\": {\n    \"foo\": 123\n  }\n}\n</code></pre> <p>If the bytes are not valid JSON, this leads to JSON broken documents. Thus a JSON validity check needs to be in place at some point of the process.</p>"},{"location":"tools/cosmos-rfc/","title":"RFC 004: Account System Refactor","text":""},{"location":"tools/cosmos-rfc/#status","title":"Status","text":"<ul> <li>Draft v2 (May 2023)</li> </ul>"},{"location":"tools/cosmos-rfc/#current-limitations","title":"Current Limitations","text":"<ol> <li>Account Representation: Limited by <code>google.Protobuf.Any</code> encapsulation and basic authentication methods</li> <li>Interface Constraints: Lacks support for advanced functionalities like vesting and complex auth systems</li> <li>Implementation Rigidity: Poor differentiation between account types (e.g., <code>ModuleAccount</code>)</li> <li>Authorization System: Basic <code>x/auth</code> module with limited scope beyond <code>x/bank</code> functionality</li> <li>Dependency Issues: Cyclic dependencies between modules (e.g., <code>x/auth</code> \u2194 <code>x/bank</code> for vesting)</li> </ol>"},{"location":"tools/cosmos-rfc/#proposal","title":"Proposal","text":"<p>This proposal aims to transform the way accounts are managed within the Cosmos SDK by introducing significant changes to their structure and functionality.</p>"},{"location":"tools/cosmos-rfc/#rethinking-account-representation-and-business-logic","title":"Rethinking Account Representation and Business Logic","text":"<p>Instead of representing accounts as simple <code>google.Protobuf.Any</code> structures stored in state with no business logic attached, this proposal suggests a more sophisticated account representation that is closer to module entities. In fact, accounts should be able to receive messages and process them in the same way modules do, and be capable of storing state in a isolated (prefixed) portion of state belonging only to them, in the same way as modules do.</p>"},{"location":"tools/cosmos-rfc/#account-message-reception","title":"Account Message Reception","text":"<p>We propose that accounts should be able to receive messages in the same way modules can, allowing them to manage their own state modifications without relying on other modules. This change would enable more advanced account functionality, such as the <code>VestingAccount</code> example, where the x/bank module previously needed to change the vestingState by casting the abstracted account to <code>VestingAccount</code> and triggering the <code>TrackDelegation</code> call. Accounts are already capable of sending messages when a state transition, originating from a transaction, is executed.</p> <p>When accounts receive messages, they will be able to identify the sender of the message and decide how to process the state transition, if at all.</p>"},{"location":"tools/cosmos-rfc/#consequences","title":"Consequences","text":"<p>These changes would have significant implications for the Cosmos SDK, resulting in a system of actors that are equal from the runtime perspective. The runtime would only be responsible for propagating messages between actors and would not manage the authorization system. Instead, actors would manage their own authorizations. For instance, there would be no need for the <code>x/auth</code> module to manage minting or burning of coins permissions, as it would fall within the scope of the <code>x/bank</code> module.</p> <p>The key difference between accounts and modules would lie in the origin of the message (state transition). Accounts (ExternallyOwnedAccount), which have credentials (e.g., a public/private key pairing), originate state transitions from transactions. In contrast, module state transitions do not have authentication credentials backing them and can be caused by two factors: either as a consequence of a state transition coming from a transaction or triggered by a scheduler (e.g., the runtime's Begin/EndBlock).</p> <p>By implementing these proposed changes, the Cosmos SDK will benefit from a more extensible, versatile, and efficient account management system that is better suited to address the requirements of the Cosmos ecosystem.</p>"},{"location":"tools/cosmos-rfc/#standardization","title":"Standardization","text":"<p>With <code>x/accounts</code> allowing a modular api there becomes a need for standardization of accounts or the interfaces wallets and other clients should expect to use. For this reason we will be using the <code>CIP</code> repo in order to standardize interfaces in order for wallets to know what to expect when interacting with accounts.</p>"},{"location":"tools/cosmos-rfc/#implementation","title":"Implementation","text":""},{"location":"tools/cosmos-rfc/#account-definition","title":"Account Definition","text":"<p>We define the new <code>Account</code> type, which is what an account needs to implement to be treated as such. An <code>Account</code> type is defined at APP level, so it cannot be dynamically loaded as the chain is running without upgrading the node code, unless we create something like a <code>CosmWasmAccount</code> which is an account backed by an <code>x/wasm</code> contract.</p> <pre><code>// Account is what the developer implements to define an account.\ntype Account[InitMsg proto.Message] interface {\n    // Init is the function that initialises an account instance of a given kind.\n    // InitMsg is used to initialise the initial state of an account.\n    Init(ctx *Context, msg InitMsg) error\n    // RegisterExecuteHandlers registers an account's execution messages.\n    RegisterExecuteHandlers(executeRouter *ExecuteRouter)\n    // RegisterQueryHandlers registers an account's query messages.\n    RegisterQueryHandlers(queryRouter *QueryRouter)\n    // RegisterMigrationHandlers registers an account's migration messages.\n    RegisterMigrationHandlers(migrationRouter *MigrationRouter)\n}\n</code></pre>"},{"location":"tools/cosmos-rfc/#the-internalaccount-definition","title":"The InternalAccount definition","text":"<p>The public <code>Account</code> interface implementation is then converted by the runtime into an <code>InternalAccount</code> implementation, which contains all the information and business logic needed to operate the account.</p> <pre><code>type Schema struct {\n    state StateSchema // represents the state of an account\n    init InitSchema // represents the init msg schema\n    exec ExecSchema // represents the multiple execution msg schemas, containing also responses\n    query QuerySchema // represents the multiple query msg schemas, containing also responses\n    migrate *MigrateSchema // represents the multiple migrate msg schemas, containing also responses, it's optional\n}\n\ntype InternalAccount struct {\n    init    func(ctx *Context, msg proto.Message) (*InitResponse, error)\n    execute func(ctx *Context, msg proto.Message) (*ExecuteResponse, error)\n    query   func(ctx *Context, msg proto.Message) (proto.Message, error)\n    schema  func() *Schema\n    migrate func(ctx *Context, msg proto.Message) (*MigrateResponse, error)\n}\n</code></pre> <p>This is an internal view of the account as intended by the system. It is not meant to be what developers implement. An example implementation of the <code>InternalAccount</code> type can be found in this example of account whose credentials can be recovered. In fact, even if the <code>Internal</code> implementation is untyped (with respect to <code>proto.Message</code>), the concrete implementation is fully typed.</p> <p>During any of the execution methods of <code>InternalAccount</code>, <code>schema</code> excluded, the account is given a <code>Context</code> which provides:</p> <ul> <li>A namespaced <code>KVStore</code> for the account, which isolates the account state from others (NOTE: no <code>store keys</code> needed,   the account address serves as <code>store key</code>).</li> <li>Information regarding itself (its address)</li> <li>Information regarding the sender.</li> <li>...</li> </ul>"},{"location":"tools/cosmos-rfc/#init","title":"Init","text":"<p>Init defines the entrypoint that allows for a new account instance of a given kind to be initialised. The account is passed some opaque protobuf message which is then interpreted and contains the instructions that constitute the initial state of an account once it is deployed.</p> <p>An <code>Account</code> code can be deployed multiple times through the <code>Init</code> function, similar to how a <code>CosmWasm</code> contract code can be deployed (Instantiated) multiple times.</p>"},{"location":"tools/cosmos-rfc/#execute","title":"Execute","text":"<p>Execute defines the entrypoint that allows an <code>Account</code> to process a state transition, the account can decide then how to process the state transition based on the message provided and the sender of the transition.</p>"},{"location":"tools/cosmos-rfc/#query","title":"Query","text":"<p>Query defines a read-only entrypoint that provides a stable interface that links an account with its state. The reason for which <code>Query</code> is still being preferred as an addition to raw state reflection is to:</p> <ul> <li>Provide a stable interface for querying (state can be optimised and change more frequently than a query)</li> <li>Provide a way to define an account <code>Interface</code> with respect to its <code>Read/Write</code> paths.</li> <li>Provide a way to query information that cannot be processed from raw state reflection, ex: compute information from lazy   state that has not been yet concretely processed (eg: balances with respect to lazy inputs/outputs)</li> </ul>"},{"location":"tools/cosmos-rfc/#schema","title":"Schema","text":"<p>Schema provides the definition of an account from <code>API</code> perspective, and it's the only thing that should be taken into account when interacting with an account from another account or module, for example: an account is an <code>authz-interface</code> account if it has the following message in its execution messages <code>MsgProxyStateTransition{ state_transition: google.Protobuf.Any }</code>.</p>"},{"location":"tools/cosmos-rfc/#migrate","title":"Migrate","text":"<p>Migrate defines the entrypoint that allows an <code>Account</code> to migrate its state from a previous version to a new one. Migrations can be initiated only by the account itself, concretely this means that the migrate action sender can only be the account address itself, if the account wants to allow another address to migrate it on its behalf then it could create an execution message that makes the account migrate itself.</p>"},{"location":"tools/cosmos-rfc/#xaccounts-module","title":"x/accounts module","text":"<p>In order to create accounts we define a new module <code>x/accounts</code>, note that <code>x/accounts</code> deploys account with no authentication credentials attached to it which means no action of an account can be incepted from a TX, we will later explore how the <code>x/authn</code> module uses <code>x/accounts</code> to deploy authenticated accounts.</p> <p>This also has another important implication for which account addresses are now fully decoupled from the authentication mechanism which makes in turn off-chain operations a little more complex, as the chain becomes the real link between account identifier and credentials.</p> <p>We could also introduce a way to deterministically compute the account address.</p> <p>Note, from the transaction point of view, the <code>init_message</code> and <code>execute_message</code> are opaque <code>google.Protobuf.Any</code>.</p> <p>The module protobuf definition for <code>x/accounts</code> are the following:</p> <pre><code>// Msg defines the Msg service.\nservice Msg {\n  rpc Deploy(MsgDeploy) returns (MsgDeployResponse);\n  rpc Execute(MsgExecute) returns (MsgExecuteResponse);\n  rpc Migrate(MsgMigrate) returns (MsgMigrateResponse);\n}\n\nmessage MsgDeploy {\n  string sender = 1;\n  string kind = 2;\n  google.Protobuf.Any init_message = 3;\n  repeated google.Protobuf.Any authorize_messages = 4 [(gogoproto.nullable) = false];\n}\n\nmessage MsgDeployResponse {\n  string address = 1;\n  uint64 id = 2;\n  google.Protobuf.Any data = 3;\n}\n\nmessage MsgExecute {\n  string sender = 1;\n  string address = 2;\n  google.Protobuf.Any message = 3;\n  repeated google.Protobuf.Any authorize_messages = 4 [(gogoproto.nullable) = false];\n}\n\nmessage MsgExecuteResponse {\n  google.Protobuf.Any data = 1;\n}\n\nmessage MsgMigrate {\n  string sender = 1;\n  string new_account_kind = 2;\n  google.Protobuf.Any migrate_message = 3;\n}\n\nmessage MsgMigrateResponse {\n  google.Protobuf.Any data = 1;\n}\n\n</code></pre>"},{"location":"tools/cosmos-rfc/#msgdeploy","title":"MsgDeploy","text":"<p>Deploys a new instance of the given account <code>kind</code> with initial settings represented by the <code>init_message</code> which is a <code>google.Protobuf.Any</code>. Of course the <code>init_message</code> can be empty. A response is returned containing the account ID and humanised address, alongside some response that the account instantiation might produce.</p>"},{"location":"tools/cosmos-rfc/#address-derivation","title":"Address derivation","text":"<p>In order to decouple public keys from account addresses, we introduce a new address derivation mechanism which is</p>"},{"location":"tools/cosmos-rfc/#msgexecute","title":"MsgExecute","text":"<p>Sends a <code>StateTransition</code> execution request, where the state transition is represented by the <code>message</code> which is a <code>google.Protobuf.Any</code>. The account can then decide if to process it or not based on the <code>sender</code>.</p>"},{"location":"tools/cosmos-rfc/#msgmigrate","title":"MsgMigrate","text":"<p>Migrates an account to a new version of itself, the new version is represented by the <code>new_account_kind</code>. The state transition can only be incepted by the account itself, which means that the <code>sender</code> must be the account address itself. During the migration the account current state is given to the new version of the account, which then executes the migration logic using the <code>migrate_message</code>, it might change state or not, it's up to the account to decide. The response contains possible data that the account might produce after the migration.</p>"},{"location":"tools/cosmos-rfc/#authorize-messages","title":"Authorize Messages","text":"<p>The <code>Deploy</code> and <code>Execute</code> messages have a field in common called <code>authorize_messages</code>, these messages are messages that the account can execute on behalf of the sender. For example, in case an account is expecting some funds to be sent from the sender, the sender can attach a <code>MsgSend</code> that the account can execute on the sender's behalf. These authorizations are short-lived, they live only for the duration of the <code>Deploy</code> or <code>Execute</code> message execution, or until they are consumed.</p> <p>An alternative would have been to add a <code>funds</code> field, like it happens in cosmwasm, which guarantees the called contract that the funds are available and sent in the context of the message execution. This would have been a simpler approach, but it would have been limited to the context of <code>MsgSend</code> only, where the asset is <code>sdk.Coins</code>. The proposed generic way, instead, allows the account to execute any message on behalf of the sender, which is more flexible, it could include NFT send execution, or more complex things like <code>MsgMultiSend</code> or <code>MsgDelegate</code>, etc.</p>"},{"location":"tools/cosmos-rfc/#further-discussion","title":"Further discussion","text":""},{"location":"tools/cosmos-rfc/#sub-accounts","title":"Sub-accounts","text":"<p>We could provide a way to link accounts to other accounts. Maybe during deployment the sender could decide to link the newly created to its own account, although there might be use-cases for which the deployer is different from the account that needs to be linked, in this case a handshake protocol on linking would need to be defined.</p>"},{"location":"tools/cosmos-rfc/#predictable-address-creation","title":"Predictable address creation","text":"<p>We need to provide a way to create an account with a predictable address, this might serve a lot of purposes, like accounts wanting to generate an address that:</p> <ul> <li>nobody else can claim besides the account used to generate the new account</li> <li>is predictable</li> </ul> <p>For example:</p> <pre><code>\nmessage MsgDeployPredictable {\n  string sender = 1;\n  uint32 nonce = 2;\n  ...\n}\n</code></pre> <p>And then the address becomes <code>bechify(concat(sender, nonce))</code></p> <p><code>x/accounts</code> would still use the monotonically increasing sequence as account number.</p>"},{"location":"tools/cosmos-rfc/#joining-multiple-accounts","title":"Joining Multiple Accounts","text":"<p>As developers are building new kinds of accounts, it becomes necessary to provide a default way to combine the functionalities of different account types. This allows developers to avoid duplicating code and enables end-users to create or migrate to accounts with multiple functionalities without requiring custom development.</p> <p>To address this need, we propose the inclusion of a default account type called \"MultiAccount\". The MultiAccount type is designed to merge the functionalities of other accounts by combining their execution, query, and migration APIs. The account joining process would only fail in the case of API (intended as non-state Schema APIs) conflicts, ensuring compatibility and consistency.</p> <p>With the introduction of the MultiAccount type, users would have the option to either migrate their existing accounts to a MultiAccount type or extend an existing MultiAccount with newer APIs. This flexibility empowers users to leverage various account functionalities without compromising compatibility or resorting to manual code duplication.</p> <p>The MultiAccount type serves as a standardized solution for combining different account functionalities within the cosmos-sdk ecosystem. By adopting this approach, developers can streamline the development process and users can benefit from a modular and extensible account system.</p>"},{"location":"tools/cosmos-rfc/#adr-071-cryptography-v2-multi-curve-support","title":"ADR 071: Cryptography v2- Multi-curve support","text":""},{"location":"tools/cosmos-rfc/#change-log","title":"Change log","text":"<ul> <li>May 7th 2024: Initial Draft (Zondax AG: @raynaudoe @juliantoledano @jleni @educlerici-zondax @lucaslopezf)</li> <li>June 13th 2024: Add CometBFT implementation proposal (Zondax AG: @raynaudoe @juliantoledano @jleni @educlerici-zondax @lucaslopezf)</li> <li>July 2nd 2024: Split ADR proposal, add link to ADR in cosmos/crypto (Zondax AG: @raynaudoe @juliantoledano @jleni @educlerici-zondax @lucaslopezf)</li> </ul>"},{"location":"tools/cosmos-rfc/#status_1","title":"Status","text":"<p>DRAFT</p>"},{"location":"tools/cosmos-rfc/#abstract","title":"Abstract","text":"<p>This ADR proposes the refactoring of the existing <code>Keyring</code> and <code>cosmos-sdk/crypto</code> code to implement ADR-001-CryptoProviders.</p> <p>For in-depth details of the <code>CryptoProviders</code> and their design please refer to ADR mentioned above.</p>"},{"location":"tools/cosmos-rfc/#introduction","title":"Introduction","text":"<p>The introduction of multi-curve support in the cosmos-sdk cryptographic package offers significant advantages. By not being restricted to a single cryptographic curve, developers can choose the most appropriate curve based on security, performance, and compatibility requirements. This flexibility enhances the application's ability to adapt to evolving security standards and optimizes performance for specific use cases, helping to future-proofing the sdk's cryptographic capabilities.</p> <p>The enhancements in this proposal not only render the \"Keyring ADR\" obsolete, but also encompass its key aspects, replacing it with a more flexible and comprehensive approach. Furthermore, the gRPC service proposed in the mentioned ADR can be easily implemented as a specialized <code>CryptoProvider</code>.</p>"},{"location":"tools/cosmos-rfc/#glossary","title":"Glossary","text":"<ol> <li> <p>Interface: In the context of this document, \"interface\" refers to Go's interface.</p> </li> <li> <p>Module: In this document, \"module\" refers to a Go module.</p> </li> <li> <p>Package: In the context of Go, a \"package\" refers to a unit of code organization.</p> </li> </ol>"},{"location":"tools/cosmos-rfc/#context","title":"Context","text":"<p>In order to fully understand the need for changes and the proposed improvements, it's crucial to consider the current state of affairs:</p> <ul> <li> <p>The Cosmos SDK currently lacks a comprehensive ADR for the cryptographic package.</p> </li> <li> <p>If a blockchain project requires a cryptographic curve that is not supported by the current SDK, the most likely scenario is that they will need to fork the SDK repository and make modifications. These modifications could potentially make the fork incompatible with future updates from the upstream SDK, complicating maintenance and integration.</p> </li> <li> <p>Type leakage of specific crypto data types expose backward compatibility and extensibility challenges.</p> </li> <li> <p>The demand for a more flexible and extensible approach to cryptography and address management is high.</p> </li> <li> <p>Architectural changes are necessary to resolve many of the currently open issues related to new curves support.</p> </li> <li> <p>There is a current trend towards modularity in the Interchain stack (e.g., runtime modules).</p> </li> <li> <p>Security implications are a critical consideration during the redesign work.</p> </li> </ul>"},{"location":"tools/cosmos-rfc/#objectives","title":"Objectives","text":"<p>The key objectives for this proposal are:</p> <ul> <li>Leverage <code>CryptoProviders</code>: Utilize them as APIs for cryptographic tools, ensuring modularity, flexibility, and ease of integration.</li> </ul> <p>Developer-Centric Approach</p> <ul> <li>Prioritize clear, intuitive interfaces and best-practice design principles.</li> </ul> <p>Quality Assurance</p> <ul> <li>Enhanced Test Coverage: Improve testing methodologies to ensure the robustness and reliability of the module.</li> </ul>"},{"location":"tools/cosmos-rfc/#technical-goals","title":"Technical Goals","text":"<p>New Keyring:</p> <ul> <li>Design a new <code>Keyring</code> interface with modular backends injection system to support hardware devices and cloud-based HSMs. This feature is optional and tied to complexity; if it proves too complex, it will be deferred to a future release as an enhancement.</li> </ul>"},{"location":"tools/cosmos-rfc/#proposed-architecture","title":"Proposed architecture","text":""},{"location":"tools/cosmos-rfc/#components","title":"Components","text":"<p>The main components to be used will be the same as those found in the ADR-001.</p>"},{"location":"tools/cosmos-rfc/#storage-and-persistence","title":"Storage and persistence","text":"<p>The storage and persistence layer is tasked with storing a <code>CryptoProvider</code>s. Specifically, this layer must:</p> <ul> <li>Securely store the crypto provider's associated private key (only if stored locally, otherwise a reference to the private key will be stored instead).</li> <li>Store the <code>ProviderMetadata</code> struct which contains the data that distinguishes that provider.</li> </ul> <p>The purpose of this layer is to ensure that upon retrieval of the persisted data, we can access the provider's type, version, and specific configuration (which varies based on the provider type). This information will subsequently be utilized to initialize the appropriate factory, as detailed in the following section on the factory pattern.</p> <p>The storage proposal involves using a modified version of the Record struct, which is already defined in Keyring/v1. Additionally, we propose utilizing the existing keyring backends (keychain, filesystem, memory, etc.) to store these <code>Record</code>s in the same manner as the current Keyring/v1.</p> <p>Note: This approach will facilitate a smoother migration path from the current Keyring/v1 to the proposed architecture.</p> <p>Below is the proposed protobuf message to be included in the modified <code>Record.proto</code> file</p>"},{"location":"tools/cosmos-rfc/#protobuf-message-structure","title":"Protobuf message structure","text":"<p>The record.proto file will be modified to include the <code>CryptoProvider</code> message as an optional field as follows.</p> <pre><code>\n// record.proto\n\nmessage Record {\n  string name = 1;\n  google.protobuf.Any pub_key = 2;\n\n  oneof item {\n    Local local = 3;\n    Ledger ledger = 4;\n    Multi multi = 5;\n    Offline offline = 6;\n    CryptoProvider crypto_provider = 7; // &lt;- New\n  }\n\n  message Local {\n    google.protobuf.Any priv_key = 1;\n  }\n\n  message Ledger {\n    hd.v1.BIP44Params path = 1;\n  }\n\n  message Multi {}\n\n  message Offline {}\n}\n</code></pre>"},{"location":"tools/cosmos-rfc/#creating-and-loading-a-cryptoprovider","title":"Creating and loading a <code>CryptoProvider</code>","text":"<p>For creating providers, we propose a factory pattern and a registry for these builders. Examples of these patterns can be found here</p>"},{"location":"tools/cosmos-rfc/#keyring","title":"Keyring","text":"<p>The new <code>Keyring</code> interface will serve as a central hub for managing and fetching <code>CryptoProviders</code>. To ensure a smoother migration path, the new Keyring will be backward compatible with the previous version. Since this will be the main API from which applications will obtain their <code>CryptoProvider</code> instances, the proposal is to extend the Keyring interface to include the methods:</p> <pre><code>type KeyringV2 interface {\n  // methods from Keyring/v1\n\n  // ListCryptoProviders returns a list of all the stored CryptoProvider metadata.\n  ListCryptoProviders() ([]ProviderMetadata, error)\n\n  // GetCryptoProvider retrieves a specific CryptoProvider by its id.\n  GetCryptoProvider(id string) (CryptoProvider, error)\n}\n</code></pre> <p>Note: Methods to obtain a provider from a public key or other means that make it easier to load the desired provider can be added.</p>"},{"location":"tools/cosmos-rfc/#especial-use-case-remote-signers","title":"Especial use case: remote signers","text":"<p>It's important to note that the <code>CryptoProvider</code> interface is versatile enough to be implemented as a remote signer. This capability allows for the integration of remote cryptographic operations, which can be particularly useful in distributed or cloud-based environments where local cryptographic resources are limited or need to be managed centrally.</p>"},{"location":"tools/cosmos-rfc/#alternatives","title":"Alternatives","text":"<p>It is important to note that all the code presented in this document is not in its final form and could be subject to changes at the time of implementation. The examples and implementations discussed should be interpreted as alternatives, providing a conceptual framework rather than definitive solutions. This flexibility allows for adjustments based on further insights, technical evaluations, or changing requirements as development progresses.</p>"},{"location":"tools/cosmos-rfc/#decision","title":"Decision","text":"<p>We will:</p> <ul> <li>Leverage crypto providers</li> <li>Refactor the module structure as described above.</li> <li>Define types and interfaces as the code attached.</li> <li>Refactor existing code into new structure and interfaces.</li> <li>Implement Unit Tests to ensure no backward compatibility issues.</li> </ul>"},{"location":"tools/cosmos-rfc/#consequences_1","title":"Consequences","text":""},{"location":"tools/cosmos-rfc/#impact-on-the-sdk-codebase","title":"Impact on the SDK codebase","text":"<p>We can divide the impact of this ADR into two main categories: state machine code and client related code.</p>"},{"location":"tools/cosmos-rfc/#client","title":"Client","text":"<p>The major impact will be on the client side, where the current <code>Keyring</code> interface will be replaced by the new <code>KeyringV2</code> interface. At first, the impact will be low since <code>CryptoProvider</code> is an optional field in the <code>Record</code> message, so there's no mandatory requirement for migrating to this new concept right away. This allows a progressive transition where the risks of breaking changes or regressions are minimized.</p>"},{"location":"tools/cosmos-rfc/#state-machine","title":"State Machine","text":"<p>The impact on the state machine code will be minimal, the modules affected (at the time of writing this ADR) are the <code>x/accounts</code> module, specifically the <code>Authenticate</code> function and the <code>x/auth/ante</code> module. This function will need to be adapted to use a <code>CryptoProvider</code> service to make use of the <code>Verifier</code> instance.</p> <p>Worth mentioning that there's also the alternative of using <code>Verifier</code> instances in a standalone fashion (see note below).</p> <p>The specific way to adapt these modules will be deeply analyzed and decided at implementation time of this ADR.</p> <p>Note: All cryptographic tools (hashers, verifiers, signers, etc.) will continue to be available as standalone packages that can be imported and utilized directly without the need for a <code>CryptoProvider</code> instance. However, the <code>CryptoProvider</code> is the recommended method for using these tools as it offers a more secure way to handle sensitive data, enhanced modularity, and the ability to store configurations and metadata within the <code>CryptoProvider</code> definition.</p>"},{"location":"tools/cosmos-rfc/#backwards-compatibility","title":"Backwards Compatibility","text":"<p>The proposed migration path is similar to what the cosmos-sdk has done in the past. To ensure a smooth transition, the following steps will be taken:</p> <p>Once ADR-001 is implemented with a stable release:</p> <ul> <li>Deprecate the old crypto package. The old crypto package will still be usable, but it will be marked as deprecated and users can opt to use the new package.</li> <li>Migrate the codebase to use the new cosmos/crypto package and remove the old crypto one.</li> </ul>"},{"location":"tools/cosmos-rfc/#positive","title":"Positive","text":"<ul> <li>Single place of truth</li> <li>Easier to use interfaces</li> <li>Easier to extend</li> <li>Unit test for each crypto package</li> <li>Greater maintainability</li> <li>Incentivize addition of implementations instead of forks</li> <li>Decoupling behavior from implementation</li> <li>Sanitization of code</li> </ul>"},{"location":"tools/cosmos-rfc/#negative","title":"Negative","text":"<ul> <li>It will involve an effort to adapt existing code.</li> <li>It will require attention to detail and audition.</li> </ul>"},{"location":"tools/cosmos-rfc/#neutral","title":"Neutral","text":"<ul> <li>It will involve extensive testing.</li> </ul>"},{"location":"tools/cosmos-rfc/#test-cases","title":"Test Cases","text":"<ul> <li>The code will be unit tested to ensure a high code coverage</li> <li>There should be integration tests around Keyring and CryptoProviders.</li> </ul> <p>While an ADR is in the DRAFT or PROPOSED stage, this section should contain a summary of issues to be solved in future iterations (usually referencing comments from a pull-request discussion).</p> <p>Later, this section can optionally list ideas or improvements the author or reviewers found during the analysis of this ADR.</p>"},{"location":"tools/cosmos-rfc/#adr-71-bank-v2","title":"ADR-71 Bank V2","text":""},{"location":"tools/cosmos-rfc/#status_2","title":"Status","text":"<p>DRAFT</p>"},{"location":"tools/cosmos-rfc/#changelog","title":"Changelog","text":"<ul> <li>2024-05-08: Initial Draft (@samricotta, @julienrbrt)</li> </ul>"},{"location":"tools/cosmos-rfc/#abstract_1","title":"Abstract","text":"<p>The primary objective of refactoring the bank module is to simplify and enhance the functionality of the Cosmos SDK. Over time the bank module has been burdened with numerous responsibilities including transaction handling, account restrictions, delegation counting, and the minting and burning of coins.</p> <p>In addition to the above, the bank module is currently too rigid and handles too many tasks, so this proposal aims to streamline the module by focusing on core functions <code>Send</code>, <code>Mint</code>, and <code>Burn</code>.</p> <p>Currently, the module is split across different keepers with scattered and duplicates functionalities (with 4 send functions for instance).</p> <p>Additionally, the integration of the token factory into the bank module allows for standardization, and better integration within the core modules.</p> <p>This rewrite will reduce complexity and enhance the efficiency and UX of the bank module.</p>"},{"location":"tools/cosmos-rfc/#context_1","title":"Context","text":"<p>The current implementation of the bank module is characterised by its handling of a broad array of functions, leading to significant complexity in using and extending the bank module.</p> <p>These issues have underscored the need for a refactoring strategy that simplifies the module\u2019s architecture and focuses on its most essential operations.</p> <p>Additionally, there is an overlap in functionality with a Token Factory module, which could be integrated to streamline oper.</p>"},{"location":"tools/cosmos-rfc/#decision_1","title":"Decision","text":"<p>Permission Tightening: Access to the module can be restricted to selected denominations only, ensuring that it operates within designated boundaries and does not exceed its intended scope. Currently, the permissions allow all denoms, so this should be changed. Send restrictions functionality will be maintained.</p> <p>Simplification of Logic: The bank module will focus on core functionalities <code>Send</code>, <code>Mint</code>, and <code>Burn</code>. This refinement aims to streamline the architecture, enhancing both maintainability and performance.</p> <p>Integration of Token Factory: The Token Factory will be merged into the bank module. This consolidation of related functionalities aims to reduce redundancy and enhance coherence within the system. Migrations functions will be provided for migrating from Osmosis' Token Factory module to bank/v2.</p> <p>Legacy Support: A legacy wrapper will be implemented to ensure compatibility with about 90% of existing functions. This measure will facilitate a smooth transition while keeping older systems functional.</p> <p>Denom Implementation: A asset interface will be added to standardise interactions such as transfers, balance inquiries, minting, and burning across different tokens. This will allow the bank module to support arbitrary asset types, enabling developers to implement custom, ERC20-like denominations.</p> <p>For example, currently if a team would like to extend the transfer method the changes would apply universally, affecting all denom\u2019s. With the proposed Asset Interface, it allows teams to customise or extend the transfer method specifically for their own tokens without impacting others.</p> <p>These improvements are expected to enhance the flexibility of the bank module, allowing for the creation of custom tokens similar to ERC20 standards and assets backed by CosmWasm (CW) contracts. The integration efforts will also aim to unify CW20 with bank coins across the Cosmos chains.</p> <p>Example of denom interface:</p> <pre><code>type AssetInterface interface {\n    Transfer(ctx sdk.Context, from sdk.AccAddress, to sdk.AccAddress, amount sdk.Coin) error\n    Mint(ctx sdk.Context, to sdk.AccAddress, amount sdk.Coin) error\n    Burn(ctx sdk.Context, from sdk.AccAddress, amount sdk.Coin) error\n    QueryBalance(ctx sdk.Context, account sdk.AccAddress) (sdk.Coin, error)\n}\n</code></pre> <p>Overview of flow:</p> <ol> <li>Alice initiates a transfer by entering Bob's address and the amount (100 ATOM)</li> <li>The Bank module verifies that the ATOM token implements the <code>AssetInterface</code> by querying the <code>ATOM_Denom_Account</code>, which is an <code>x/account</code> denom account.</li> <li>The Bank module executes the transfer by subtracting 100 ATOM from Alice\u2019s balance and adding 100 ATOM to Bob\u2019s balance.</li> <li>The Bank module calls the Transfer method on the <code>ATOM_Denom_Account</code>. The Transfer method, defined in the <code>AssetInterface</code>, handles the logic to subtract 100 ATOM from Alice\u2019s balance and add 100 ATOM to Bob\u2019s balance.</li> <li>The Bank module updates the chain and returns the new balances.</li> <li>Both Alice and Bob successfully receive the updated balances.</li> </ol>"},{"location":"tools/cosmos-rfc/#migration-plans","title":"Migration Plans","text":"<p>Bank is a widely used module, so getting a v2 needs to be thought thoroughly. In order to not force all dependencies to immediately migrate to bank/v2, the same upgrading path will be taken as for the <code>gov</code> module.</p> <p>This means <code>cosmossdk.io/bank</code> will stay one module and there won't be a new <code>cosmossdk.io/bank/v2</code> go module. Instead the bank protos will be versioned from <code>v1beta1</code> (current bank) to <code>v2</code>.</p> <p>Bank <code>v1beta1</code> endpoints will use the new bank v2 implementation for maximum backward compatibility.</p> <p>The bank <code>v1beta1</code> keepers will be deprecated and potentially eventually removed, but its proto and messages definitions will remain.</p> <p>Additionally, as bank plans to integrate token factory, migrations functions will be provided to migrate from Osmosis token factory implementation (most widely used implementation) to the new bank/v2 token factory.</p>"},{"location":"tools/cosmos-rfc/#consequences_2","title":"Consequences","text":""},{"location":"tools/cosmos-rfc/#positive_1","title":"Positive","text":"<ul> <li>Simplified interaction with bank APIs</li> <li>Backward compatible changes (no contracts or apis broken)</li> <li>Optional migration (note: bank <code>v1beta1</code> won't get any new feature after bank <code>v2</code> release)</li> </ul>"},{"location":"tools/cosmos-rfc/#neutral_1","title":"Neutral","text":"<ul> <li>Asset implementation not available cross-chain (IBC-ed custom asset should possibly fallback to the default implementation)</li> <li>Many assets may slow down bank balances requests</li> </ul>"},{"location":"tools/cosmos-rfc/#negative_1","title":"Negative","text":"<ul> <li>Temporarily duplicate functionalities as bank <code>v1beta1</code> are <code>v2</code> are living alongside</li> <li>Difficultity to ever completely remove bank <code>v1beta1</code></li> </ul>"},{"location":"tools/cosmos-rfc/#references","title":"References","text":"<ul> <li>Current bank module implementation: https://github.com/cosmos/cosmos-sdk/blob/v0.50.6/x/bank/keeper/keeper.go#L22-L53</li> <li>Osmosis token factory: https://github.com/osmosis-labs/osmosis/tree/v25.0.0/x/tokenfactory/keeper</li> </ul>"},{"location":"tools/cosmos-sdk/","title":"Cosmos SDK Core Components","text":""},{"location":"tools/cosmos-sdk/#overview","title":"Overview","text":"<p>The Cosmos SDK is a framework for building secure blockchain applications on CometBFT. It provides:</p> <ul> <li>ABCI implementation in Go</li> <li>Multi-store persistence layer  </li> <li>Transaction routing system</li> </ul>"},{"location":"tools/cosmos-sdk/#transaction-flow","title":"Transaction Flow","text":"<ol> <li>CometBFT consensus delivers transaction bytes</li> <li>SDK decodes transactions and extracts messages</li> <li>Messages routed to appropriate modules</li> <li>State changes committed to stores</li> </ol> <pre><code>graph TD\n    A[CometBFT] --&gt;|Tx Bytes| B[SDK Decode]\n    B --&gt;|Messages| C[Module Router] \n    C --&gt;|State Changes| D[Multi-store]\n</code></pre>"},{"location":"tools/cosmos-sdk/#baseapp","title":"<code>baseapp</code>","text":"<p><code>baseapp</code> is the boilerplate implementation of a Cosmos SDK application. It comes with an implementation of the ABCI to handle the connection with the underlying consensus engine. Typically, a Cosmos SDK application extends <code>baseapp</code> by embedding it in <code>app.go</code>.</p> <p>Here is an example of this from <code>simapp</code>, the Cosmos SDK demonstration app:</p> <p>```go reference https://github.com/cosmos/cosmos-sdk/blob/v0.52.0-beta.1/simapp/app.go#L145-L186</p> <pre><code>\nThe goal of `baseapp` is to provide a secure interface between the store and the extensible state machine while defining as little about the state machine as possible (staying true to the ABCI).\n\nFor more on `baseapp`, please click [here](../advanced/00-baseapp.md).\n\n## Multistore\n\nThe Cosmos SDK provides a [`multistore`](../advanced/04-store.md#multistore) for persisting state. The multistore allows developers to declare any number of [`KVStores`](../advanced/04-store.md#base-layer-kvstores). These `KVStores` only accept the `[]byte` type as value and therefore any custom structure needs to be marshalled using [a codec](../advanced/05-encoding.md) before being stored.\n\nThe multistore abstraction is used to divide the state in distinct compartments, each managed by its own module. For more on the multistore, click [here](../advanced/04-store.md#multistore).\n\n## Modules\n\nThe power of the Cosmos SDK lies in its modularity. Cosmos SDK applications are built by aggregating a collection of interoperable modules. Each module defines a subset of the state and contains its own message/transaction processor, while the Cosmos SDK is responsible for routing each message to its respective module.\n\nHere is a simplified view of how a transaction is processed by the application of each full-node when it is received in a valid block:\n\n```mermaid\n flowchart TD\n    A[Transaction relayed from the full-node's CometBFT engine to the node's application via DeliverTx] --&gt; B[APPLICATION]\n    B --&gt;|\"Using baseapp's methods: Decode the Tx, extract and route the message(s)\"| C[Message routed to the correct module to be processed]\n    C --&gt; D1[AUTH MODULE]\n    C --&gt; D2[BANK MODULE]\n    C --&gt; D3[STAKING MODULE]\n    C --&gt; D4[GOV MODULE]\n    D1 --&gt;|Handle message, Update state| E[\"Return result to CometBFT (0=Ok, 1=Err)\"]\n    D2 --&gt;|Handle message, Update state| E[\"Return result to CometBFT (0=Ok, 1=Err)\"]\n    D3 --&gt;|Handle message, Update state| E[\"Return result to CometBFT (0=Ok, 1=Err)\"]\n    D4 --&gt;|Handle message, Update state| E[\"Return result to CometBFT (0=Ok, 1=Err)\"]\n</code></pre> <p>Each module can be seen as a little state-machine. Developers need to define the subset of the state handled by the module, as well as custom message types that modify the state (Note: <code>messages</code> are extracted from <code>transactions</code> by <code>baseapp</code>). In general, each module declares its own <code>KVStore</code> in the <code>multistore</code> to persist the subset of the state it defines. Most developers will need to access other 3rd party modules when building their own modules. Given that the Cosmos SDK is an open framework, some of the modules may be malicious, which means there is a need for security principles to reason about inter-module interactions. These principles are based on object-capabilities. In practice, this means that instead of having each module keep an access control list for other modules, each module implements special objects called <code>keepers</code> that can be passed to other modules to grant a pre-defined set of capabilities.</p> <p>Cosmos SDK modules are defined in the <code>x/</code> folder of the Cosmos SDK. Some core modules include:</p> <ul> <li><code>x/auth</code>: Used to manage accounts and signatures.</li> <li><code>x/bank</code>: Used to enable tokens and token transfers.</li> <li><code>x/staking</code> + <code>x/slashing</code>: Used to build Proof-of-Stake blockchains.</li> </ul> <p>In addition to the already existing modules in <code>x/</code>, which anyone can use in their app, the Cosmos SDK lets you build your own custom modules. You can check an example of that in the tutorial.# Keepers</p> <p>:::note Synopsis <code>Keeper</code>s refer to a Cosmos SDK abstraction whose role is to manage access to the subset of the state defined by various modules. <code>Keeper</code>s are module-specific, i.e. the subset of state defined by a module can only be accessed by a <code>keeper</code> defined in said module. If a module needs to access the subset of state defined by another module, a reference to the second module's internal <code>keeper</code> needs to be passed to the first one. This is done in <code>app.go</code> during the instantiation of module keepers. :::</p> <p>:::note Pre-requisite Readings</p> <ul> <li>Introduction to Cosmos SDK Modules</li> </ul> <p>:::</p>"},{"location":"tools/cosmos-sdk/#motivation","title":"Motivation","text":"<p>The Cosmos SDK is a framework that makes it easy for developers to build complex decentralized applications from scratch, mainly by composing modules together. As the ecosystem of open-source modules for the Cosmos SDK expands, it will become increasingly likely that some of these modules contain vulnerabilities, as a result of the negligence or malice of their developer.</p> <p>The Cosmos SDK adopts an object-capabilities-based approach to help developers better protect their application from unwanted inter-module interactions, and <code>keeper</code>s are at the core of this approach. A <code>keeper</code> can be considered quite literally to be the gatekeeper of a module's store(s). Each store (typically an <code>IAVL</code> Store) defined within a module comes with a <code>storeKey</code>, which grants unlimited access to it. The module's <code>keeper</code> holds this <code>storeKey</code> (which should otherwise remain unexposed), and defines methods for reading and writing to the store(s).</p> <p>The core idea behind the object-capabilities approach is to only reveal what is necessary to get the work done. In practice, this means that instead of handling permissions of modules through access-control lists, module <code>keeper</code>s are passed a reference to the specific instance of the other modules' <code>keeper</code>s that they need to access (this is done in the application's constructor function). As a consequence, a module can only interact with the subset of state defined in another module via the methods exposed by the instance of the other module's <code>keeper</code>. This is a great way for developers to control the interactions that their own module can have with modules developed by external developers.</p>"},{"location":"tools/cosmos-sdk/#type-definition","title":"Type Definition","text":"<p><code>keeper</code>s are generally implemented in a <code>/keeper/keeper.go</code> file located in the module's folder. By convention, the type <code>keeper</code> of a module is simply named <code>Keeper</code> and usually follows the following structure:</p> <pre><code>type Keeper struct {\n    // External keepers, if any\n\n    // Store key(s)\n\n    // codec\n\n    // authority\n}\n</code></pre> <p>For example, here is the type definition of the <code>keeper</code> from the <code>staking</code> module:</p> <p>```go reference https://github.com/cosmos/cosmos-sdk/blob/v0.52.0-beta.1/x/staking/keeper/keeper.go#L54-L115</p> <pre><code>\nLet us go through the different parameters:\n\n- An expected `keeper` is a `keeper` external to a module that is required by the internal `keeper` of said module. External `keeper`s are listed in the internal `keeper`'s type definition as interfaces. These interfaces are themselves defined in an `expected_keepers.go` file in the root of the module's folder. In this context, interfaces are used to reduce the number of dependencies, as well as to facilitate the maintenance of the module itself.\n- `KVStoreService`s grant access to the store(s) of the [multistore](../../learn/advanced/04-store.md) managed by the module. They should always remain unexposed to external modules.\n- `cdc` is the [codec](../../learn/advanced/05-encoding.md) used to marshal and unmarshal structs to/from `[]byte`. The `cdc` can be any of `codec.BinaryCodec`, `codec.JSONCodec` or `codec.Codec` based on your requirements. It can be either a proto or amino codec as long as they implement these interfaces.\n- The authority listed is a module account or user account that has the right to change module level parameters. Previously this was handled by the param module, which has been deprecated.\n\nOf course, it is possible to define different types of internal `keeper`s for the same module (e.g. a read-only `keeper`). Each type of `keeper` comes with its own constructor function, which is called from the [application's constructor function](../../learn/beginner/00-app-anatomy.md). This is where `keeper`s are instantiated, and where developers make sure to pass correct instances of modules' `keeper`s to other modules that require them.\n\n## Implementing Methods\n\n`Keeper`s primarily expose methods for business logic, as validity checks should have already been performed by the [`Msg` server](./03-msg-services.md) when `keeper`s' methods are called.\n\n&lt;!-- markdown-link-check-disable --&gt;\n\nState management is recommended to be done via [Collections](../packages/collections)\n\n&lt;!-- The above link is created via the script to generate docs  --&gt;\n\n## State Management\n\nIn the Cosmos SDK, it is crucial to be methodical and selective when managing state within a module, as improper state management can lead to inefficiency, security risks, and scalability issues. Not all data belongs in the on-chain state; it's important to store only essential blockchain data that needs to be verified by consensus. Storing unnecessary information, especially client-side data, can bloat the state and slow down performance. Instead, developers should focus on using an off-chain database to handle supplementary data, extending the API as needed. This approach minimizes on-chain complexity, optimizes resource usage, and keeps the blockchain state lean and efficient, ensuring scalability and smooth operations.\n\nThe Cosmos SDK leverages Protocol Buffers (protobuf) for efficient state management, providing a well-structured, binary encoding format that ensures compatibility and performance across different modules. The SDK\u2019s recommended approach for managing state is through the [collections package](../pacakges/02-collections.md), which simplifies state handling by offering predefined data structures like maps and indexed sets, reducing the complexity of managing raw state data. While users can opt for custom encoding schemes if they need more flexibility or have specialized requirements, they should be aware that such custom implementations may not integrate seamlessly with indexers that decode state data on the fly. This could lead to challenges in data retrieval, querying, and interoperability, making protobuf a safer and more future-proof choice for most use cases.\n\n# Folder Structure\n\n:::note Synopsis\nThis document outlines the structure of Cosmos SDK modules. These ideas are meant to be applied as suggestions. Application developers are encouraged to improve upon and contribute to module structure and development design.\n\nThe required interface for a module is located in the module.go. Everything beyond this is suggestive.\n:::\n\n## Structure\n\nA typical Cosmos SDK module can be structured as follows:\n\n```shell\nproto\n\u2514\u2500\u2500 {project_name}\n \u00a0\u00a0 \u2514\u2500\u2500 {module_name}\n \u00a0\u00a0     \u2514\u2500\u2500 {proto_version}\n \u00a0\u00a0  \u00a0\u00a0     \u251c\u2500\u2500 {module_name}.proto\n \u00a0\u00a0  \u00a0\u00a0     \u251c\u2500\u2500 genesis.proto\n \u00a0\u00a0  \u00a0\u00a0     \u251c\u2500\u2500 query.proto\n \u00a0\u00a0  \u00a0\u00a0     \u2514\u2500\u2500 tx.proto\n</code></pre> <ul> <li><code>{module_name}.proto</code>: The module's common message type definitions.</li> <li><code>genesis.proto</code>: The module's message type definitions related to genesis state.</li> <li><code>query.proto</code>: The module's Query service and related message type definitions.</li> <li><code>tx.proto</code>: The module's Msg service and related message type definitions.</li> </ul> <pre><code>x/{module_name}\n\u251c\u2500\u2500 client\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 cli\n\u2502\u00a0\u00a0 \u2502   \u251c\u2500\u2500 query.go\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 tx.go\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 testutil\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 cli_test.go\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 suite.go\n\u251c\u2500\u2500 exported\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 exported.go\n\u251c\u2500\u2500 keeper\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 genesis.go\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 grpc_query.go\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 hooks.go\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 invariants.go\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 keeper.go\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 keys.go\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 msg_server.go\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 querier.go\n\u251c\u2500\u2500 simulation\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 decoder.go\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 genesis.go\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 operations.go\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 params.go\n\u251c\u2500\u2500 types\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 {module_name}.pb.go\n\u2502   \u251c\u2500\u2500 codec.go\n\u2502   \u251c\u2500\u2500 errors.go\n\u2502   \u251c\u2500\u2500 events.go\n\u2502   \u251c\u2500\u2500 events.pb.go\n\u2502   \u251c\u2500\u2500 expected_keepers.go\n\u2502   \u251c\u2500\u2500 genesis.go\n\u2502   \u251c\u2500\u2500 genesis.pb.go\n\u2502   \u251c\u2500\u2500 keys.go\n\u2502   \u251c\u2500\u2500 msgs.go\n\u2502   \u251c\u2500\u2500 params.go\n\u2502   \u251c\u2500\u2500 query.pb.go\n\u2502   \u2514\u2500\u2500 tx.pb.go\n\u251c\u2500\u2500 module.go\n\u251c\u2500\u2500 abci.go\n\u251c\u2500\u2500 autocli.go\n\u251c\u2500\u2500 depinject.go\n\u2514\u2500\u2500 README.md\n</code></pre> <ul> <li><code>client/</code>: The module's CLI client functionality implementation and the module's CLI testing suite.</li> <li><code>exported/</code>: The module's exported types - typically interface types. If a module relies on keepers from another module, it is expected to receive the keepers as interface contracts through the <code>expected_keepers.go</code> file (see below) in order to avoid a direct dependency on the module implementing the keepers. However, these interface contracts can define methods that operate on and/or return types that are specific to the module that is implementing the keepers and this is where <code>exported/</code> comes into play. The interface types that are defined in <code>exported/</code> use canonical types, allowing for the module to receive the keepers as interface contracts through the <code>expected_keepers.go</code> file. This pattern allows for code to remain DRY and also alleviates import cycle chaos.</li> <li><code>keeper/</code>: The module's <code>Keeper</code> and <code>MsgServer</code> implementation.</li> <li><code>abci.go</code>: The module's <code>BeginBlocker</code> and <code>EndBlocker</code> implementations (this file is only required if <code>BeginBlocker</code> and/or <code>EndBlocker</code> need to be defined).</li> <li><code>simulation/</code>: The module's simulation package defines functions used by the blockchain simulator application (<code>simapp</code>).</li> <li><code>README.md</code>: The module's specification documents outlining important concepts, state storage structure, and message and event type definitions. Learn more how to write module specs in the spec guidelines.</li> <li><code>types/</code>: includes type definitions for messages, events, and genesis state, including the type definitions generated by Protocol Buffers.</li> <li><code>codec.go</code>: The module's registry methods for interface types.</li> <li><code>errors.go</code>: The module's sentinel errors.</li> <li><code>events.go</code>: The module's event types and constructors.</li> <li><code>expected_keepers.go</code>: The module's expected keeper interfaces.</li> <li><code>genesis.go</code>: The module's genesis state methods and helper functions.</li> <li><code>keys.go</code>: The module's store keys and associated helper functions.</li> <li><code>msgs.go</code>: The module's message type definitions and associated methods.</li> <li><code>params.go</code>: The module's parameter type definitions and associated methods.</li> <li><code>*.pb.go</code>: The module's type definitions generated by Protocol Buffers (as defined in the respective <code>*.proto</code> files above).</li> <li>The root directory includes the module's <code>AppModule</code> implementation.</li> <li><code>autocli.go</code>: The module autocli options.</li> <li><code>depinject.go</code>: The module depinject options.</li> </ul> <p>Note: although the above pattern is followed by most of the Cosmos SDK modules, there are some modules that don't follow this pattern. E.g <code>x/group</code> and <code>x/nft</code> dont have a <code>types</code> folder, instead all of the type definitions for messages, events, and genesis state are live in the root directory and the module's <code>AppModule</code> implementation lives in the <code>module</code> folder.</p>"},{"location":"tools/cosmos-sdk/#sidebar_position-1","title":"sidebar_position: 1","text":""},{"location":"tools/cosmos-sdk/#msg-services","title":"<code>Msg</code> Services","text":"<p>:::note Synopsis A Protobuf <code>Msg</code> service processes messages. Protobuf <code>Msg</code> services are specific to the module in which they are defined, and only process messages defined within the said module. They are called from <code>BaseApp</code> during <code>FinalizeBlock</code>. :::</p> <p>:::note Pre-requisite Readings</p> <ul> <li>Module Manager</li> <li>Messages and Queries</li> </ul> <p>:::</p>"},{"location":"tools/cosmos-sdk/#implementation-of-a-module-msg-service","title":"Implementation of a module <code>Msg</code> service","text":"<p>Each module should define a Protobuf <code>Msg</code> service, which will be responsible for processing requests (implementing <code>sdk.Msg</code>) and returning responses.</p> <p>As further described in ADR 031, this approach has the advantage of clearly specifying return types and generating server and client code.</p> <p>Protobuf generates a <code>MsgServer</code> interface based on the definition of <code>Msg</code> service. It is the role of the module developer to implement this interface, by implementing the state transition logic that should happen upon receival of each <code>transaction.Msg</code>. As an example, here is the generated <code>MsgServer</code> interface for <code>x/bank</code>, which exposes two <code>transaction.Msg</code>s:</p> <p>```go reference https://github.com/cosmos/cosmos-sdk/blob/28fa3b8/x/bank/types/tx.pb.go#L564-L579</p> <pre><code>\nWhen possible, the existing module's [`Keeper`](./06-keeper.md) should implement `MsgServer`, otherwise a `msgServer` struct that embeds the `Keeper` can be created, typically in `./keeper/msg_server.go`:\n\n```go reference\nhttps://github.com/cosmos/cosmos-sdk/blob/28fa3b8/x/bank/keeper/msg_server.go#L16-L19\n</code></pre> <p><code>msgServer</code> methods can retrieve the auxiliary information or services using the environment variable, it is always located in the keeper:</p> <p>Environment:</p> <p>```go reference https://github.com/cosmos/cosmos-sdk/blob/07151304e2ec6a185243d083f59a2d543253cb15/core/appmodule/v2/environment.go#L14-L29</p> <pre><code>\nKeeper Example:\n\n```go reference\nhttps://github.com/cosmos/cosmos-sdk/blob/07151304e2ec6a185243d083f59a2d543253cb15/x/bank/keeper/keeper.go#L56-L58\n</code></pre> <p><code>transaction.Msg</code> processing usually follows these 3 steps:</p>"},{"location":"tools/cosmos-sdk/#validation","title":"Validation","text":"<p>The message server must perform all validation required (both stateful and stateless) to make sure the <code>message</code> is valid. The <code>signer</code> is charged for the gas cost of this validation.</p> <p>For example, a <code>msgServer</code> method for a <code>transfer</code> message should check that the sending account has enough funds to actually perform the transfer.</p> <p>It is recommended to implement all validation checks in a separate function that passes state values as arguments. This implementation simplifies testing. As expected, expensive validation functions charge additional gas. Example:</p> <pre><code>ValidateMsgA(msg MsgA, now Time, gm GasMeter) error {\n    if now.Before(msg.Expire) {\n        return sdkerrors.ErrInvalidRequest.Wrap(\"msg expired\")\n    }\n    gm.ConsumeGas(1000, \"signature verification\")\n    return signatureVerificaton(msg.Prover, msg.Data)\n}\n</code></pre> <p>:::warning Previously, the <code>ValidateBasic</code> method was used to perform simple and stateless validation checks. This way of validating is deprecated, this means the <code>msgServer</code> must perform all validation checks. :::</p>"},{"location":"tools/cosmos-sdk/#state-transition","title":"State Transition","text":"<p>After the validation is successful, the <code>msgServer</code> method uses the <code>keeper</code> functions to access the state and perform a state transition.</p>"},{"location":"tools/cosmos-sdk/#events","title":"Events","text":"<p>Before returning, <code>msgServer</code> methods generally emit one or more events by using the <code>EventManager</code> held in <code>environment</code>.</p> <p>There are two ways to emit events, typed events using protobuf or arbitrary key &amp; values.</p> <p>Typed Events:</p> <pre><code>ctx.EventManager().EmitTypedEvent(\n    &amp;group.EventABC{Key1: Value1,  Key2, Value2})\n</code></pre> <p>Arbitrary Events:</p> <pre><code>ctx.EventManager().EmitEvent(\n    sdk.NewEvent(\n        eventType,  // e.g. sdk.EventTypeMessage for a message, types.CustomEventType for a custom event defined in the module\n        sdk.NewAttribute(key1, value1),\n        sdk.NewAttribute(key2, value2),\n    ),\n)\n</code></pre> <p>These events are relayed back to the underlying consensus engine and can be used by service providers to implement services around the application. Click here to learn more about events.</p> <p>The invoked <code>msgServer</code> method returns a <code>proto.Message</code> response and an <code>error</code>. These return values are then wrapped into an <code>*sdk.Result</code> or an <code>error</code>:</p> <p>```go reference https://github.com/cosmos/cosmos-sdk/blob/v0.50.0-alpha.0/baseapp/msg_service_router.go#L160</p> <pre><code>\nThis method takes care of marshaling the `res` parameter to protobuf and attaching any events on the `EventManager()` to the `sdk.Result`.\n\n```protobuf reference\nhttps://github.com/cosmos/cosmos-sdk/blob/v0.50.0-alpha.0/proto/cosmos/base/abci/v1beta1/abci.proto#L93-L113\n</code></pre> <p>This diagram shows a typical structure of a Protobuf <code>Msg</code> service, and how the message propagates through the module.</p> <pre><code>sequenceDiagram\n    participant User\n    participant baseApp\n    participant router\n    participant handler\n    participant msgServer\n    participant keeper\n    participant EventManager\n\n    User-&gt;&gt;baseApp: Transaction Type&lt;Tx&gt;\n    baseApp-&gt;&gt;router: Route(ctx, msgRoute)\n    router-&gt;&gt;handler: handler\n    handler-&gt;&gt;msgServer: Msg&lt;Tx&gt;(Context, Msg(..))\n\n    alt addresses invalid, denominations wrong, etc.\n        msgServer-&gt;&gt;handler: error\n        handler-&gt;&gt;router: error\n        router-&gt;&gt;baseApp: result, error code\n    else\n        msgServer-&gt;&gt;keeper: perform action, update context\n        keeper-&gt;&gt;msgServer: results, error code\n        msgServer-&gt;&gt;EventManager: Emit relevant events\n        msgServer-&gt;&gt;msgServer: maybe wrap results in more structure\n        msgServer-&gt;&gt;handler: result, error code\n        handler-&gt;&gt;router: result, error code\n        router-&gt;&gt;baseApp: result, error code\n    end\n\n    baseApp-&gt;&gt;User: result, error code\n</code></pre>"},{"location":"tools/cosmos-sdk/#telemetry","title":"Telemetry","text":"<p>New telemetry metrics can be created from <code>msgServer</code> methods when handling messages.</p> <p>This is an example from the <code>x/auth/vesting</code> module:</p> <p>```go reference https://github.com/cosmos/cosmos-sdk/blob/v0.50.0-alpha.0/x/auth/vesting/msg_server.go#L76-L88</p> <pre><code>\n:::Warning\nTelemetry adds a performance overhead to the chain. It is recommended to only use this in critical paths\n:::\n\n---\n\n## sidebar_position: 1\n\n# Query Services\n\n:::note Synopsis\nA Protobuf Query service processes [`queries`](./02-messages-and-queries.md#queries). Query services are specific to the module in which they are defined, and only process `queries` defined within said module. They are called from `BaseApp`'s [`Query` method](../../learn/advanced/00-baseapp.md#query).\n:::\n\n:::note Pre-requisite Readings\n\n- [Module Manager](./01-module-manager.md)\n- [Messages and Queries](./02-messages-and-queries.md)\n\n:::\n\n## Implementation of a module query service\n\n### gRPC Service\n\nWhen defining a Protobuf `Query` service, a `QueryServer` interface is generated for each module with all the service methods:\n\n```go\ntype QueryServer interface {\n    QueryBalance(context.Context, *QueryBalanceParams) (*types.Coin, error)\n    QueryAllBalances(context.Context, *QueryAllBalancesParams) (*QueryAllBalancesResponse, error)\n}\n</code></pre> <p>These custom queries methods should be implemented by a module's keeper, typically in <code>./keeper/grpc_query.go</code>. The first parameter of these methods is a generic <code>context.Context</code>. Therefore, the Cosmos SDK provides a function <code>sdk.UnwrapSDKContext</code> to retrieve the <code>context.Context</code> from the provided <code>context.Context</code>.</p> <p>Here's an example implementation for the bank module:</p> <p>```go reference https://github.com/cosmos/cosmos-sdk/blob/v0.50.0-alpha.0/x/bank/keeper/grpc_query.go</p> <pre><code>\n### Calling queries from the State Machine\n\nThe Cosmos SDK v0.47 introduces a new `cosmos.query.v1.module_query_safe` Protobuf annotation which is used to state that a query that is safe to be called from within the state machine, for example:\n\n- a Keeper's query function can be called from another module's Keeper,\n- ADR-033 intermodule query calls,\n- CosmWasm contracts can also directly interact with these queries.\n\nIf the `module_query_safe` annotation set to `true`, it means:\n\n- The query is deterministic: given a block height it will return the same response upon multiple calls, and doesn't introduce any state-machine breaking changes across SDK patch versions.\n- Gas consumption never fluctuates across calls and across patch versions.\n\nIf you are a module developer and want to use `module_query_safe` annotation for your own query, you have to ensure the following things:\n\n- the query is deterministic and won't introduce state-machine-breaking changes without coordinated upgrades\n- it has its gas tracked, to avoid the attack vector where no gas is accounted for\n  on potentially high-computation queries.\n\n  ***\n\n  sidebar_position: 1\n\n---\n\n# Blockchain Architecture\n\n## Introduction\n\nBlockchain architecture is a complex topic that involves many different components. In this section, we will cover the main layers of a blockchain application built with the Cosmos SDK.\n\nAt its core, a blockchain is a replicated deterministic state machine. This document explores the various layers of blockchain architecture, focusing on the execution, settlement, consensus, data availability, and interoperability layers.\n\n```mermaid\ngraph TD\n    A[Modular SDK Blockchain Architecture]\n    A --&gt; B[Execution Layer]\n    A --&gt; C[Settlement Layer]\n    A --&gt; D[Consensus Layer]\n    D --&gt; E[Data Availability Layer]\n    A --&gt; F[Interoperability Layer]\n</code></pre>"},{"location":"tools/cosmos-sdk/#layered-architecture","title":"Layered Architecture","text":"<p>Understanding blockchain architecture through the lens of different layers helps in comprehending its complex functionalities. We will give a high-level overview of the execution layer, settlement layer, consensus layer, data availability layer, and interoperability layer.</p>"},{"location":"tools/cosmos-sdk/#execution-layer","title":"Execution Layer","text":"<p>The Execution Layer is where the blockchain processes and executes transactions. The state machine within the blockchain handles the execution of transaction logic. This is done by the blockchain itself, ensuring that every transaction follows the predefined rules and state transitions. When a transaction is submitted, the execution layer processes it, updates the state, and ensures that the output is deterministic and consistent across all nodes. In the context of the Cosmos SDK, this typically involves predefined modules and transaction types rather than general-purpose smart contracts, which are used in chains with CosmWasm.</p>"},{"location":"tools/cosmos-sdk/#state-machine","title":"State machine","text":"<p>At its core, a blockchain is a replicated deterministic state machine.</p> <p>A state machine is a computer science concept whereby a machine can have multiple states, but only one at any given time. There is a <code>state</code>, which describes the current state of the system, and <code>transactions</code>, that trigger state transitions.</p> <p>Given a state S and a transaction T, the state machine will return a new state S'.</p> <pre><code>flowchart LR\n    A[S]\n    B[S']\n    A --&gt;|\"apply(T)\"| B\n</code></pre> <p>In practice, the transactions are bundled in blocks to make the process more efficient. Given a state S and a block of transactions B, the state machine will return a new state S'.</p> <pre><code>flowchart LR\n    A[S]\n    B[S']\n    A --&gt;|\"For each T in B: apply(T)\"| B\n</code></pre> <p>In a blockchain context, the state machine is deterministic. This means that if a node is started at a given state and replays the same sequence of transactions, it will always end up with the same final state.</p> <p>The Cosmos SDK gives developers maximum flexibility to define the state of their application, transaction types and state transition functions. The process of building state machines with the Cosmos SDK will be described more in-depth in the following sections. But first, let us see how the state machine is replicated using various consensus engines, such as CometBFT.</p>"},{"location":"tools/cosmos-sdk/#settlement-layer","title":"Settlement Layer","text":"<p>The Settlement Layer is responsible for finalising and recording transactions on the blockchain. This layer ensures that all transactions are accurately settled and immutable, providing a verifiable record of all activities on the blockchain. It is critical for maintaining the integrity and trustworthiness of the blockchain.</p> <p>The settlement layer can be performed on the chain itself or it can be externalised, allowing for the possibility of plugging in a different settlement layer as needed. For example if we were to use Rollkit and celestia for our Data Availability and Consensus, we could separate our settlement layer by introducing fraud or validity proofs. From there the settlement layer can create trust-minimised light clients, further enhancing security and efficiency. This process ensures that all transactions are accurately finalized and immutable, providing a verifiable record of all activities.</p>"},{"location":"tools/cosmos-sdk/#consensus-layer","title":"Consensus Layer","text":"<p>The Consensus Layer ensures that all nodes in the network agree on the order and validity of transactions. This layer uses consensus algorithms like Byzantine Fault Tolerance (BFT) or Proof of Stake (PoS) to achieve agreement, even in the presence of malicious nodes. Consensus is crucial for maintaining the security and reliability of the blockchain.</p> <p>What has been a default consensus engine in the Cosmos SDK has been CometBFT. In the most recent releases we have been moving away from this and allowing users to plug and play their own consensus engines. This is a big step forward for the Cosmos SDK as it allows for more flexibility and customisation. Other consensus engine options for example can be Rollkit with Celestias Data Availability Layer.</p> <p>Here is an example of how the consensus layer works with CometBFT in the context of the Cosmos SDK:</p>"},{"location":"tools/cosmos-sdk/#cometbft","title":"CometBFT","text":"<p>Thanks to the Cosmos SDK, developers just have to define the state machine, and CometBFT will handle replication over the network for them.</p> <pre><code>flowchart TD\n    subgraph Blockchain_Node[Blockchain Node]\n        subgraph SM[State-machine]\n            direction TB\n            SM1[Cosmos SDK]\n        end\n        subgraph CometBFT[CometBFT]\n            direction TB\n            Consensus\n            Networking\n        end\n    end\n\n    SM &lt;--&gt; CometBFT\n\n\n    Blockchain_Node --&gt;|Includes| SM\n    Blockchain_Node --&gt;|Includes| CometBFT\n</code></pre> <p>CometBFT is an application-agnostic engine that is responsible for handling the networking and consensus layers of a blockchain. In practice, this means that CometBFT is responsible for propagating and ordering transaction bytes. CometBFT relies on an eponymous Byzantine-Fault-Tolerant (BFT) algorithm to reach consensus on the order of transactions.</p> <p>The consensus algorithm adopted by CometBFT works with a set of special nodes called Validators. Validators are responsible for adding blocks of transactions to the blockchain. At any given block, there is a validator set V. A validator in V is chosen by the algorithm to be the proposer of the next block. This block is considered valid if more than two thirds of V signed a <code>prevote</code> and a <code>precommit</code> on it, and if all the transactions that it contains are valid. The validator set can be changed by rules written in the state-machine.</p>"},{"location":"tools/cosmos-sdk/#abci","title":"ABCI","text":"<p>CometBFT passes transactions to the application through an interface called the ABCI, which the application must implement.</p> <pre><code>graph TD\n    A[Application]\n    B[CometBFT]\n    A &lt;--&gt;|ABCI| B\n\n</code></pre> <p>Note that CometBFT only handles transaction bytes. It has no knowledge of what these bytes mean. All CometBFT does is order these transaction bytes deterministically. CometBFT passes the bytes to the application via the ABCI, and expects a return code to inform it if the messages contained in the transactions were successfully processed or not.</p> <p>Here are the most important messages of the ABCI:</p> <ul> <li><code>CheckTx</code>: When a transaction is received by CometBFT, it is passed to the application to check if a few basic requirements are met. <code>CheckTx</code> is used to protect the mempool of full-nodes against spam transactions. A special handler called the <code>AnteHandler</code> is used to execute a series of validation steps such as checking for sufficient fees and validating the signatures. If the checks are valid, the transaction is added to the mempool and relayed to peer nodes. Note that transactions are not processed (i.e. no modification of the state occurs) with <code>CheckTx</code> since they have not been included in a block yet.</li> <li><code>DeliverTx</code>: When a valid block is received by CometBFT, each transaction in the block is passed to the application via <code>DeliverTx</code> in order to be processed. It is during this stage that the state transitions occur. The <code>AnteHandler</code> executes again, along with the actual <code>Msg</code> service RPC for each message in the transaction.</li> <li><code>BeginBlock</code>/<code>EndBlock</code>: These messages are executed at the beginning and the end of each block, whether the block contains transactions or not. It is useful to trigger automatic execution of logic. Proceed with caution though, as computationally expensive loops could slow down your blockchain, or even freeze it if the loop is infinite.</li> </ul> <p>Find a more detailed view of the ABCI methods from the CometBFT docs.</p> <p>Any application built on CometBFT needs to implement the ABCI interface in order to communicate with the underlying local CometBFT engine. Fortunately, you do not have to implement the ABCI interface. The Cosmos SDK provides a boilerplate implementation of it in the form of baseapp.</p>"},{"location":"tools/cosmos-sdk/#data-availability-layer","title":"Data Availability Layer","text":"<p>The Data Availability (DA) Layer is a critical component of within the umbrella of the consensus layer that ensures all necessary data for transactions is available to all network participants. This layer is essential for preventing data withholding attacks, where some nodes might attempt to disrupt the network by not sharing critical transaction data.</p> <p>If we use the example of Rollkit, a user initiates a transaction, which is then propagated through the rollup network by a light node. The transaction is validated by full nodes and aggregated into a block by the sequencer. This block is posted to a data availability layer like Celestia, ensuring the data is accessible and correctly ordered. The rollup light node verifies data availability from the DA layer. Full nodes then validate the block and generate necessary proofs, such as fraud proofs for optimistic rollups or zk-SNARKs/zk-STARKs for zk-rollups. These proofs are shared across the network and verified by other nodes, ensuring the rollup's integrity. Once all validations are complete, the rollup's state is updated, finalising the transaction</p>"},{"location":"tools/cosmos-sdk/#interoperability-layer","title":"Interoperability Layer","text":"<p>The Interoperability Layer enables communication and interaction between different blockchains. This layer facilitates cross-chain transactions and data sharing, allowing various blockchain networks to interoperate seamlessly. Interoperability is key for building a connected ecosystem of blockchains, enhancing their functionality and reach.</p> <p>In this case we have separated the layers even further to really illustrate the components that make-up the blockchain architecture and it is important to note that the Cosmos SDK is designed to be interoperable with other blockchains. This is achieved through the use of the Inter-Blockchain Communication (IBC) protocol, which allows different blockchains to communicate and transfer assets between each other.</p>"},{"location":"tools/cosmos-sdk/#sidebar_position-1_1","title":"sidebar_position: 1","text":""},{"location":"tools/cosmos-sdk/#application-specific-blockchains","title":"Application-Specific Blockchains","text":"<p>:::note Synopsis This document explains what application-specific blockchains are, and why developers would want to build one as opposed to writing Smart Contracts. :::</p>"},{"location":"tools/cosmos-sdk/#what-are-application-specific-blockchains","title":"What are application-specific blockchains","text":"<p>Application-specific blockchains are blockchains customized to operate a single application. Instead of building a decentralized application on top of an underlying blockchain like Ethereum, developers build their own blockchain from the ground up. This means building a full-node client, a light-client, and all the necessary interfaces (CLI, REST, ...) to interact with the nodes.</p> <pre><code>flowchart TD\n    subgraph Blockchain_Node[Blockchain Node]\n        subgraph SM[State-machine]\n            direction TB\n            SM1[Cosmos SDK]\n        end\n        subgraph Consensus[Consensus]\n            direction TB\n        end\n        subgraph Networking[Networking]\n            direction TB\n        end\n    end\n\n    SM &lt;--&gt; Consensus\n    Consensus &lt;--&gt; Networking\n\n\n    Blockchain_Node --&gt;|Includes| SM\n    Blockchain_Node --&gt;|Includes| Consensus\n    Blockchain_Node --&gt;|Includes| Networking\n</code></pre>"},{"location":"tools/cosmos-sdk/#what-are-the-shortcomings-of-smart-contracts","title":"What are the shortcomings of Smart Contracts","text":"<p>Virtual-machine blockchains like Ethereum addressed the demand for more programmability back in 2014. At the time, the options available for building decentralized applications were quite limited. Most developers would build on top of the complex and limited Bitcoin scripting language, or fork the Bitcoin codebase which was hard to work with and customize.</p> <p>Virtual-machine blockchains came in with a new value proposition. Their state-machine incorporates a virtual-machine that is able to interpret turing-complete programs called Smart Contracts. These Smart Contracts are very good for use cases like one-time events (e.g. ICOs), but they can fall short for building complex decentralized platforms. Here is why:</p> <ul> <li>Smart Contracts are generally developed with specific programming languages that can be interpreted by the underlying virtual-machine. These programming languages are often immature and inherently limited by the constraints of the virtual-machine itself. For example, the Ethereum Virtual Machine does not allow developers to implement automatic execution of code. Developers are also limited to the account-based system of the EVM, and they can only choose from a limited set of functions for their cryptographic operations. These are examples, but they hint at the lack of flexibility that a smart contract environment often entails.</li> <li>Smart Contracts are all run by the same virtual machine. This means that they compete for resources, which can severely restrain performance. And even if the state-machine were to be split in multiple subsets (e.g. via sharding), Smart Contracts would still need to be interpreted by a virtual machine, which would limit performance compared to a native application implemented at state-machine level (our benchmarks show an improvement on the order of 10x in performance when the virtual-machine is removed).</li> <li>Another issue with the fact that Smart Contracts share the same underlying environment is the resulting limitation in sovereignty. A decentralized application is an ecosystem that involves multiple players. If the application is built on a general-purpose virtual-machine blockchain, stakeholders have very limited sovereignty over their application, and are ultimately superseded by the governance of the underlying blockchain. If there is a bug in the application, very little can be done about it.</li> </ul> <p>Application-Specific Blockchains are designed to address these shortcomings.</p>"},{"location":"tools/cosmos-sdk/#application-specific-blockchains-benefits","title":"Application-Specific Blockchains Benefits","text":""},{"location":"tools/cosmos-sdk/#flexibility","title":"Flexibility","text":"<p>Application-specific blockchains give maximum flexibility to developers:</p> <ul> <li> <p>In Cosmos blockchains, the state-machine is typically connected to the underlying consensus engine via an interface called the ABCI (Application Blockchain Interface). This interface can be wrapped in any programming language, meaning developers can build their state-machine in the programming language of their choice.</p> </li> <li> <p>Developers can choose among multiple frameworks to build their state-machine. The most widely used today is the Cosmos SDK, but others exist (e.g. Lotion, Weave, ...). Typically the choice will be made based on the programming language they want to use (Cosmos SDK and Weave are in Golang, Lotion is in Javascript, ...).</p> </li> <li>The ABCI also allows developers to swap the consensus engine of their application-specific blockchain. Today, only CometBFT is production-ready, but in the future other consensus engines are expected to emerge.</li> <li>Even when they settle for a framework and consensus engine, developers still have the freedom to tweak them if they don't perfectly match their requirements in their pristine forms.</li> <li>Developers are free to explore the full spectrum of tradeoffs (e.g. number of validators vs transaction throughput, safety vs availability in asynchrony, ...) and design choices (DB or IAVL tree for storage, UTXO or account model, ...).</li> <li>Developers can implement automatic execution of code. In the Cosmos SDK, logic can be automatically triggered at the beginning and the end of each block. They are also free to choose the cryptographic library used in their application, as opposed to being constrained by what is made available by the underlying environment in the case of virtual-machine blockchains.</li> </ul> <p>The list above contains a few examples that show how much flexibility application-specific blockchains give to developers. The goal of Cosmos and the Cosmos SDK is to make developer tooling as generic and composable as possible, so that each part of the stack can be forked, tweaked and improved without losing compatibility. As the community grows, more alternatives for each of the core building blocks will emerge, giving more options to developers.</p>"},{"location":"tools/cosmos-sdk/#performance","title":"Performance","text":"<p>Decentralized applications built with Smart Contracts are inherently capped in performance by the underlying environment. For a decentralized application to optimise performance, it needs to be built as an application-specific blockchain. Next are some of the benefits an application-specific blockchain brings in terms of performance:</p> <ul> <li>Developers of application-specific blockchains can choose to operate with a novel consensus engine such as CometBFT.</li> <li>An application-specific blockchain only operates a single application, so that the application does not compete with others for computation and storage. This is the opposite of most non-sharded virtual-machine blockchains today, where smart contracts all compete for computation and storage.</li> <li>Even if a virtual-machine blockchain offered application-based sharding coupled with an efficient consensus algorithm, performance would still be limited by the virtual-machine itself. The real throughput bottleneck is the state-machine, and requiring transactions to be interpreted by a virtual-machine significantly increases the computational complexity of processing them.</li> </ul>"},{"location":"tools/cosmos-sdk/#security","title":"Security","text":"<p>Security is hard to quantify, and greatly varies from platform to platform. That said here are some important benefits an application-specific blockchain can bring in terms of security:</p> <ul> <li>Developers can choose proven programming languages like Go when building their application-specific blockchains, as opposed to smart contract programming languages that are often more immature.</li> <li>Developers are not constrained by the cryptographic functions made available by the underlying virtual-machines. They can use their own custom cryptography, and rely on well-audited crypto libraries.</li> <li>Developers do not have to worry about potential bugs or exploitable mechanisms in the underlying virtual-machine, making it easier to reason about the security of the application.</li> </ul>"},{"location":"tools/cosmos-sdk/#sovereignty","title":"Sovereignty","text":"<p>One of the major benefits of application-specific blockchains is sovereignty. A decentralized application is an ecosystem that involves many actors: users, developers, third-party services, and more. When developers build on virtual-machine blockchain where many decentralized applications coexist, the community of the application is different than the community of the underlying blockchain, and the latter supersedes the former in the governance process. If there is a bug or if a new feature is needed, stakeholders of the application have very little leeway to upgrade the code. If the community of the underlying blockchain refuses to act, nothing can happen.</p> <p>The fundamental issue here is that the governance of the application and the governance of the network are not aligned. This issue is solved by application-specific blockchains. Because application-specific blockchains specialize to operate a single application, stakeholders of the application have full control over the entire chain. This ensures that the community will not be stuck if a bug is discovered, and that it has the freedom to choose how it is going to evolve.</p>"},{"location":"tools/ibc-accounts/","title":"Interchain Accounts","text":"<p>:::note Synopsis Learn about what the Interchain Accounts module is :::</p>"},{"location":"tools/ibc-accounts/#what-is-the-interchain-accounts-module","title":"What is the Interchain Accounts module?","text":"<p>Interchain Accounts is the Cosmos SDK implementation of the ICS-27 protocol, which enables cross-chain account management built upon IBC.</p> <ul> <li>How does an interchain account differ from a regular account?</li> </ul> <p>Regular accounts use a private key to sign transactions. Interchain Accounts are instead controlled programmatically by counterparty chains via IBC packets.</p>"},{"location":"tools/ibc-accounts/#concepts","title":"Concepts","text":"<p><code>Host Chain</code>: The chain where the interchain account is registered. The host chain listens for IBC packets from a controller chain which should contain instructions (e.g. Cosmos SDK messages) for which the interchain account will execute.</p> <p><code>Controller Chain</code>: The chain registering and controlling an account on a host chain. The controller chain sends IBC packets to the host chain to control the account.</p> <p><code>Interchain Account</code>: An account on a host chain created using the ICS-27 protocol. An interchain account has all the capabilities of a normal account. However, rather than signing transactions with a private key, a controller chain will send IBC packets to the host chain which signals what transactions the interchain account should execute.</p> <p><code>Authentication Module</code>: A custom application module on the controller chain that uses the Interchain Accounts module to build custom logic for the creation &amp; management of interchain accounts. It can be either an IBC application module using the legacy API, or a regular Cosmos SDK application module sending messages to the controller submodule's <code>MsgServer</code> (this is the recommended approach from ibc-go v6 if access to packet callbacks is not needed). Please note that the legacy API will eventually be removed and IBC applications will not be able to use them in later releases.</p>"},{"location":"tools/ibc-accounts/#sdk-security-model","title":"SDK security model","text":"<p>SDK modules on a chain are assumed to be trustworthy. For example, there are no checks to prevent an untrustworthy module from accessing the bank keeper.</p> <p>The implementation of ICS-27 in ibc-go uses this assumption in its security considerations.</p> <p>The implementation assumes other IBC application modules will not bind to ports within the ICS-27 namespace.</p>"},{"location":"tools/ibc-accounts/#channel-closure","title":"Channel Closure","text":"<p>The provided interchain account host and controller implementations do not support <code>ChanCloseInit</code>. However, they do support <code>ChanCloseConfirm</code>. This means that the host and controller modules cannot close channels, but they will confirm channel closures initiated by other implementations of ICS-27.</p> <p>In the event of a channel closing (due to a packet timeout in an ordered channel, for example), the interchain account associated with that channel can become accessible again if a new channel is created with a (JSON-formatted) version string that encodes the exact same <code>Metadata</code> information of the previous channel. The channel can be reopened using either <code>MsgRegisterInterchainAccount</code> or <code>MsgChannelOpenInit</code>. If <code>MsgRegisterInterchainAccount</code> is used, then it is possible to leave the <code>version</code> field of the message empty, since it will be filled in by the controller submodule. If <code>MsgChannelOpenInit</code> is used, then the <code>version</code> field must be provided with the correct JSON-encoded <code>Metadata</code> string. See section Understanding Active Channels for more information.</p> <p>When reopening a channel with the default controller submodule, the ordering of the channel cannot be changed. In order to change the ordering of the channel, the channel has to go through a channel upgrade handshake or reopen the channel with a custom controller implementation.</p>"},{"location":"tools/ibc-fee-middleware/","title":"Overview","text":"<p>:::note Synopsis Learn about what the Fee Middleware module is, and how to build custom modules that utilize the Fee Middleware functionality :::</p>"},{"location":"tools/ibc-fee-middleware/#what-is-the-fee-middleware-module","title":"What is the Fee Middleware module?","text":"<p>IBC does not depend on relayer operators for transaction verification. However, the relayer infrastructure ensures liveness of the Interchain network \u2014 operators listen for packets sent through channels opened between chains, and perform the vital service of ferrying these packets (and proof of the transaction on the sending chain/receipt on the receiving chain) to the clients on each side of the channel.</p> <p>Though relaying is permissionless and completely decentralized and accessible, it does come with operational costs. Running full nodes to query transaction proofs and paying for transaction fees associated with IBC packets are two of the primary cost burdens which have driven the overall discussion on a general, in-protocol incentivization mechanism for relayers.</p> <p>Initially, a simple proposal was created to incentivize relaying on ICS20 token transfers on the destination chain. However, the proposal was specific to ICS20 token transfers and would have to be reimplemented in this format on every other IBC application module.</p> <p>After much discussion, the proposal was expanded to a general incentivisation design that can be adopted by any ICS application protocol as middleware.</p>"},{"location":"tools/ibc-fee-middleware/#concepts","title":"Concepts","text":"<p>ICS29 fee payments in this middleware design are built on the assumption that sender chains are the source of incentives \u2014 the chain on which packets are incentivized is the chain that distributes fees to relayer operators. However, as part of the IBC packet flow, messages have to be submitted on both sender and destination chains. This introduces the requirement of a mapping of relayer operator's addresses on both chains.</p> <p>To achieve the stated requirements, the fee middleware module has two main groups of functionality:</p> <ul> <li>Registering of relayer addresses associated with each party involved in relaying the packet on the source chain. This registration process can be automated on start up of relayer infrastructure and happens only once, not every packet flow.</li> </ul> <p>This is described in the Fee distribution section.</p> <ul> <li>Escrowing fees by any party which will be paid out to each rightful party on completion of the packet lifecycle.</li> </ul> <p>This is described in the Fee messages section.</p> <p>We complete the introduction by giving a list of definitions of relevant terminology.</p> <p><code>Forward relayer</code>: The relayer that submits the <code>MsgRecvPacket</code> message for a given packet (on the destination chain).</p> <p><code>Reverse relayer</code>: The relayer that submits the <code>MsgAcknowledgement</code> message for a given packet (on the source chain).</p> <p><code>Timeout relayer</code>: The relayer that submits the <code>MsgTimeout</code> or <code>MsgTimeoutOnClose</code> messages for a given packet (on the source chain).</p> <p><code>Payee</code>: The account address on the source chain to be paid on completion of the packet lifecycle. The packet lifecycle on the source chain completes with the receipt of a <code>MsgTimeout</code>/<code>MsgTimeoutOnClose</code> or a <code>MsgAcknowledgement</code>.</p> <p><code>Counterparty payee</code>: The account address to be paid on completion of the packet lifecycle on the destination chain. The package lifecycle on the destination chain completes with a successful <code>MsgRecvPacket</code>.</p> <p><code>Refund address</code>: The address of the account paying for the incentivization of packet relaying. The account is refunded timeout fees upon successful acknowledgement. In the event of a packet timeout, both acknowledgement and receive fees are refunded.</p>"},{"location":"tools/ibc-fee-middleware/#known-limitations","title":"Known Limitations","text":"<ul> <li>At the time of the release of the feature (ibc-go v4) fee payments middleware only supported incentivisation of new channels; however, with the release of channel upgradeability (ibc-go v8.1) it is possible to enable incentivisation of all existing channels.</li> <li>Even though unlikely, there exists a DoS attack vector on a fee-enabled channel if 1) there exists a relayer software implementation that is incentivised to timeout packets if the timeout fee is greater than the sum of the fees to receive and acknowledge the packet, and 2) only this type of implementation is used by operators relaying on the channel. In this situation, an attacker could continuously incentivise the relayers to never deliver the packets by incrementing the timeout fee of the packets above the sum of the receive and acknowledge fees. However, this situation is unlikely to occur because 1) another relayer behaving honestly could relay the packets before they timeout, and 2) the attack would be costly because the attacker would need to incentivise the timeout fee of the packets with their own funds. Given the low impact and unlikelihood of the attack we have decided to accept this risk and not implement any mitigation mesaures.</li> </ul>"},{"location":"tools/ibc-fee-middleware/#module-integration","title":"Module Integration","text":"<p>The Fee Middleware module, as the name suggests, plays the role of an IBC middleware and as such must be configured by chain developers to route and handle IBC messages correctly. For Cosmos SDK chains this setup is done via the <code>app/app.go</code> file, where modules are constructed and configured in order to bootstrap the blockchain application.</p>"},{"location":"tools/ibc-fee-middleware/#example-integration-of-the-fee-middleware-module","title":"Example integration of the Fee Middleware module","text":"<pre><code>// app.go\n\n// Register the AppModule for the fee middleware module\nModuleBasics = module.NewBasicManager(\n  ...\n  ibcfee.AppModuleBasic{},\n  ...\n)\n\n...\n\n// Add module account permissions for the fee middleware module\nmaccPerms = map[string][]string{\n  ...\n  ibcfeetypes.ModuleName:            nil,\n}\n\n...\n\n// Add fee middleware Keeper\ntype App struct {\n  ...\n\n  IBCFeeKeeper ibcfeekeeper.Keeper\n\n  ...\n}\n\n...\n\n// Create store keys\nkeys := sdk.NewKVStoreKeys(\n  ...\n  ibcfeetypes.StoreKey,\n  ...\n)\n\n...\n\napp.IBCFeeKeeper = ibcfeekeeper.NewKeeper(\n  appCodec, keys[ibcfeetypes.StoreKey],\n  app.IBCKeeper.ChannelKeeper, // may be replaced with IBC middleware\n  app.IBCKeeper.ChannelKeeper,\n  &amp;app.IBCKeeper.PortKeeper, app.AccountKeeper, app.BankKeeper,\n)\n\n\n// See the section below for configuring an application stack with the fee middleware module\n\n...\n\n// Register fee middleware AppModule\napp.moduleManager = module.NewManager(\n  ...\n  ibcfee.NewAppModule(app.IBCFeeKeeper),\n)\n\n...\n\n// Add fee middleware to begin blocker logic\napp.moduleManager.SetOrderBeginBlockers(\n  ...\n  ibcfeetypes.ModuleName,\n  ...\n)\n\n// Add fee middleware to end blocker logic\napp.moduleManager.SetOrderEndBlockers(\n  ...\n  ibcfeetypes.ModuleName,\n  ...\n)\n\n// Add fee middleware to init genesis logic\napp.moduleManager.SetOrderInitGenesis(\n  ...\n  ibcfeetypes.ModuleName,\n  ...\n)\n</code></pre>"},{"location":"tools/ibc-fee-middleware/#configuring-an-application-stack-with-fee-middleware","title":"Configuring an application stack with Fee Middleware","text":"<p>As mentioned in IBC middleware development an application stack may be composed of many or no middlewares that nest a base application. These layers form the complete set of application logic that enable developers to build composable and flexible IBC application stacks. For example, an application stack may be just a single base application like <code>transfer</code>, however, the same application stack composed with <code>29-fee</code> will nest the <code>transfer</code> base application by wrapping it with the Fee Middleware module.</p>"},{"location":"tools/ibc-fee-middleware/#transfer","title":"Transfer","text":"<p>See below for an example of how to create an application stack using <code>transfer</code> and <code>29-fee</code>. The following <code>transferStack</code> is configured in <code>app/app.go</code> and added to the IBC <code>Router</code>. The in-line comments describe the execution flow of packets between the application stack and IBC core.</p> <pre><code>// Create Transfer Stack\n// SendPacket, since it is originating from the application to core IBC:\n// transferKeeper.SendPacket -&gt; fee.SendPacket -&gt; channel.SendPacket\n\n// RecvPacket, message that originates from core IBC and goes down to app, the flow is the other way\n// channel.RecvPacket -&gt; fee.OnRecvPacket -&gt; transfer.OnRecvPacket\n\n// transfer stack contains (from top to bottom):\n// - IBC Fee Middleware\n// - Transfer\n\n// create IBC module from bottom to top of stack\nvar transferStack porttypes.IBCModule\ntransferStack = transfer.NewIBCModule(app.TransferKeeper)\ntransferStack = ibcfee.NewIBCMiddleware(transferStack, app.IBCFeeKeeper)\n\n// Add transfer stack to IBC Router\nibcRouter.AddRoute(ibctransfertypes.ModuleName, transferStack)\n</code></pre>"},{"location":"tools/ibc-fee-middleware/#interchain-accounts","title":"Interchain Accounts","text":"<p>See below for an example of how to create an application stack using <code>27-interchain-accounts</code> and <code>29-fee</code>. The following <code>icaControllerStack</code> and <code>icaHostStack</code> are configured in <code>app/app.go</code> and added to the IBC <code>Router</code> with the associated authentication module. The in-line comments describe the execution flow of packets between the application stack and IBC core.</p> <pre><code>// Create Interchain Accounts Stack\n// SendPacket, since it is originating from the application to core IBC:\n// icaAuthModuleKeeper.SendTx -&gt; icaController.SendPacket -&gt; fee.SendPacket -&gt; channel.SendPacket\n\n// initialize ICA module with mock module as the authentication module on the controller side\nvar icaControllerStack porttypes.IBCModule\nicaControllerStack = ibcmock.NewIBCModule(&amp;mockModule, ibcmock.NewMockIBCApp(\"\", scopedICAMockKeeper))\napp.ICAAuthModule = icaControllerStack.(ibcmock.IBCModule)\nicaControllerStack = icacontroller.NewIBCMiddleware(icaControllerStack, app.ICAControllerKeeper)\nicaControllerStack = ibcfee.NewIBCMiddleware(icaControllerStack, app.IBCFeeKeeper)\n\n// RecvPacket, message that originates from core IBC and goes down to app, the flow is:\n// channel.RecvPacket -&gt; fee.OnRecvPacket -&gt; icaHost.OnRecvPacket\n\nvar icaHostStack porttypes.IBCModule\nicaHostStack = icahost.NewIBCModule(app.ICAHostKeeper)\nicaHostStack = ibcfee.NewIBCMiddleware(icaHostStack, app.IBCFeeKeeper)\n\n// Add authentication module, controller and host to IBC router\nibcRouter.\n  // the ICA Controller middleware needs to be explicitly added to the IBC Router because the\n  // ICA controller module owns the port capability for ICA. The ICA authentication module\n  // owns the channel capability.\n  AddRoute(ibcmock.ModuleName+icacontrollertypes.SubModuleName, icaControllerStack) // ica with mock auth module stack route to ica (top level of middleware stack)\n  AddRoute(icacontrollertypes.SubModuleName, icaControllerStack).\n  AddRoute(icahosttypes.SubModuleName, icaHostStack).\n</code></pre>"},{"location":"tools/ibc-fee-middleware/#fee-distribution","title":"Fee Distribution","text":"<p>Packet fees are divided into 3 distinct amounts in order to compensate relayer operators for packet relaying on fee enabled IBC channels.</p> <ul> <li><code>RecvFee</code>: The sum of all packet receive fees distributed to a payee for successful execution of <code>MsgRecvPacket</code>.</li> <li><code>AckFee</code>: The sum of all packet acknowledgement fees distributed to a payee for successful execution of <code>MsgAcknowledgement</code>.</li> <li><code>TimeoutFee</code>: The sum of all packet timeout fees distributed to a payee for successful execution of <code>MsgTimeout</code>.</li> </ul>"},{"location":"tools/ibc-fee-middleware/#register-a-counterparty-payee-address-for-forward-relaying","title":"Register a counterparty payee address for forward relaying","text":"<p>As mentioned in ICS29 Concepts, the forward relayer describes the actor who performs the submission of <code>MsgRecvPacket</code> on the destination chain. Fee distribution for incentivized packet relays takes place on the packet source chain.</p> <p>Relayer operators are expected to register a counterparty payee address, in order to be compensated accordingly with <code>RecvFee</code>s upon completion of a packet lifecycle.</p> <p>The counterparty payee address registered on the destination chain is encoded into the packet acknowledgement and communicated as such to the source chain for fee distribution. If a counterparty payee is not registered for the forward relayer on the destination chain, the escrowed fees will be refunded upon fee distribution.</p>"},{"location":"tools/ibc-fee-middleware/#relayer-operator-actions","title":"Relayer operator actions","text":"<p>A transaction must be submitted to the destination chain including a <code>CounterpartyPayee</code> address of an account on the source chain. The transaction must be signed by the <code>Relayer</code>.</p> <p>Note: If a module account address is used as the <code>CounterpartyPayee</code> but the module has been set as a blocked address in the <code>BankKeeper</code>, the refunding to the module account will fail. This is because many modules use invariants to compare internal tracking of module account balances against the actual balance of the account stored in the <code>BankKeeper</code>. If a token transfer to the module account occurs without going through this module and updating the account balance of the module on the <code>BankKeeper</code>, then invariants may break and unknown behaviour could occur depending on the module implementation. Therefore, if it is desirable to use a module account that is currently blocked, the module developers should be consulted to gauge to possibility of removing the module account from the blocked list.</p> <pre><code>type MsgRegisterCounterpartyPayee struct {\n  // unique port identifier\n  PortId string\n  // unique channel identifier\n  ChannelId string\n  // the relayer address\n  Relayer string\n  // the counterparty payee address\n  CounterpartyPayee string\n}\n</code></pre> <p>This message is expected to fail if:</p> <ul> <li><code>PortId</code> is invalid (see 24-host naming requirements.</li> <li><code>ChannelId</code> is invalid (see 24-host naming requirements).</li> <li><code>Relayer</code> is an invalid address (see Cosmos SDK Addresses).</li> <li><code>CounterpartyPayee</code> is empty or contains more than 2048 bytes.</li> </ul> <p>See below for an example CLI command:</p> <pre><code>simd tx ibc-fee register-counterparty-payee transfer channel-0 \\\n  cosmos1rsp837a4kvtgp2m4uqzdge0zzu6efqgucm0qdh \\\n  osmo1v5y0tz01llxzf4c2afml8s3awue0ymju22wxx2 \\\n  --from cosmos1rsp837a4kvtgp2m4uqzdge0zzu6efqgucm0qdh\n</code></pre>"},{"location":"tools/ibc-fee-middleware/#register-an-alternative-payee-address-for-reverse-and-timeout-relaying","title":"Register an alternative payee address for reverse and timeout relaying","text":"<p>As mentioned in ICS29 Concepts, the reverse relayer describes the actor who performs the submission of <code>MsgAcknowledgement</code> on the source chain. Similarly the timeout relayer describes the actor who performs the submission of <code>MsgTimeout</code> (or <code>MsgTimeoutOnClose</code>) on the source chain.</p> <p>Relayer operators may choose to register an optional payee address, in order to be compensated accordingly with <code>AckFee</code>s and <code>TimeoutFee</code>s upon completion of a packet life cycle.</p> <p>If a payee is not registered for the reverse or timeout relayer on the source chain, then fee distribution assumes the default behaviour, where fees are paid out to the relayer account which delivers <code>MsgAcknowledgement</code> or <code>MsgTimeout</code>/<code>MsgTimeoutOnClose</code>.</p>"},{"location":"tools/ibc-fee-middleware/#relayer-operator-actions_1","title":"Relayer operator actions","text":"<p>A transaction must be submitted to the source chain including a <code>Payee</code> address of an account on the source chain. The transaction must be signed by the <code>Relayer</code>.</p> <p>Note: If a module account address is used as the <code>Payee</code> it is recommended to turn off invariant checks for that module.</p> <pre><code>type MsgRegisterPayee struct {\n  // unique port identifier\n  PortId string\n  // unique channel identifier\n  ChannelId string\n  // the relayer address\n  Relayer string\n  // the payee address\n  Payee string\n}\n</code></pre> <p>This message is expected to fail if:</p> <ul> <li><code>PortId</code> is invalid (see 24-host naming requirements.</li> <li><code>ChannelId</code> is invalid (see 24-host naming requirements).</li> <li><code>Relayer</code> is an invalid address (see Cosmos SDK Addresses).</li> <li><code>Payee</code> is an invalid address (see Cosmos SDK Addresses).</li> </ul> <p>See below for an example CLI command:</p> <pre><code>simd tx ibc-fee register-payee transfer channel-0 \\\n  cosmos1rsp837a4kvtgp2m4uqzdge0zzu6efqgucm0qdh \\\n  cosmos153lf4zntqt33a4v0sm5cytrxyqn78q7kz8j8x5 \\\n  --from cosmos1rsp837a4kvtgp2m4uqzdge0zzu6efqgucm0qdh\n</code></pre>"},{"location":"tools/ibc-transfer/","title":"Overview","text":"<p>:::note Synopsis Learn about what the token Transfer module is :::</p>"},{"location":"tools/ibc-transfer/#what-is-the-transfer-module","title":"What is the Transfer module?","text":"<p>Transfer is the Cosmos SDK implementation of the ICS-20 protocol, which enables cross-chain fungible token transfers.</p>"},{"location":"tools/ibc-transfer/#concepts","title":"Concepts","text":""},{"location":"tools/ibc-transfer/#acknowledgements","title":"Acknowledgements","text":"<p>ICS20 uses the recommended acknowledgement format as specified by ICS 04.</p> <p>A successful receive of a transfer packet will result in a Result Acknowledgement being written with the value <code>[]byte{byte(1)}</code> in the <code>Response</code> field.</p> <p>An unsuccessful receive of a transfer packet will result in an Error Acknowledgement being written with the error message in the <code>Response</code> field.</p>"},{"location":"tools/ibc-transfer/#denomination-trace","title":"Denomination trace","text":"<p>The denomination trace corresponds to the information that allows a token to be traced back to its origin chain. It contains a sequence of port and channel identifiers ordered from the most recent to the oldest in the timeline of transfers.</p> <p>This information is included on the token's base denomination field in the form of a hash to prevent an unbounded denomination length. For example, the token <code>transfer/channelToA/uatom</code> will be displayed as <code>ibc/7F1D3FCF4AE79E1554D670D1AD949A9BA4E4A3C76C63093E17E446A46061A7A2</code>. The human readable denomination is stored using <code>x/bank</code> module's denom metadata feature. You may display the human readable denominations by querying balances with the <code>--resolve-denom</code> flag, as in:</p> <pre><code>simd query bank balances [address] --resolve-denom\n</code></pre> <p>Each send to any chain other than the one it was previously received from is a movement forwards in the token's timeline. This causes trace to be added to the token's history and the destination port and destination channel to be prefixed to the denomination. In these instances the sender chain is acting as the \"source zone\". When the token is sent back to the chain it previously received from, the prefix is removed. This is a backwards movement in the token's timeline and the sender chain is acting as the \"sink zone\".</p> <p>It is strongly recommended to read the full details of ADR 001: Coin Source Tracing to understand the implications and context of the IBC token representations.</p>"},{"location":"tools/ibc-transfer/#ux-suggestions-for-clients","title":"UX suggestions for clients","text":"<p>For clients (wallets, exchanges, applications, block explorers, etc) that want to display the source of the token, it is recommended to use the following alternatives for each of the cases below:</p>"},{"location":"tools/ibc-transfer/#direct-connection","title":"Direct connection","text":"<p>If the denomination trace contains a single identifier prefix pair (as in the example above), then the easiest way to retrieve the chain and light client identifier is to map the trace information directly. In summary, this requires querying the channel from the denomination trace identifiers, and then the counterparty client state using the counterparty port and channel identifiers from the retrieved channel.</p> <p>A general pseudo algorithm would look like the following:</p> <ol> <li>Query the full denomination trace.</li> <li>Query the channel with the <code>portID/channelID</code> pair, which corresponds to the first destination of the    token.</li> <li>Query the client state using the identifiers pair. Note that this query will return a <code>\"Not Found\"</code> response if the current chain is not connected to this channel.</li> <li>Retrieve the client identifier or chain identifier from the client state (eg: on    Tendermint clients) and store it locally.</li> </ol> <p>Using the gRPC gateway client service the steps above would be, with a given IBC token <code>ibc/7F1D3FCF4AE79E1554D670D1AD949A9BA4E4A3C76C63093E17E446A46061A7A2</code> stored on <code>chainB</code>:</p> <ol> <li><code>GET /ibc/apps/transfer/v1/denom_traces/7F1D3FCF4AE79E1554D670D1AD949A9BA4E4A3C76C63093E17E446A46061A7A2</code> -&gt; <code>{\"path\": \"transfer/channelToA\", \"base_denom\": \"uatom\"}</code></li> <li><code>GET /ibc/apps/transfer/v1/channels/channelToA/ports/transfer/client_state\"</code> -&gt; <code>{\"client_id\": \"clientA\", \"chain-id\": \"chainA\", ...}</code></li> <li><code>GET /ibc/apps/transfer/v1/channels/channelToA/ports/transfer\"</code> -&gt; <code>{\"channel_id\": \"channelToA\", port_id\": \"transfer\", counterparty: {\"channel_id\": \"channelToB\", port_id\": \"transfer\"}, ...}</code></li> <li><code>GET /ibc/apps/transfer/v1/channels/channelToB/ports/transfer/client_state\" -&gt; {\"client_id\": \"clientB\", \"chain-id\": \"chainB\", ...}</code></li> </ol> <p>Then, the token transfer chain path for the <code>uatom</code> denomination would be: <code>chainA</code> -&gt; <code>chainB</code>.</p>"},{"location":"tools/ibc-transfer/#multiple-hops","title":"Multiple hops","text":"<p>The multiple channel hops case applies when the token has passed through multiple chains between the original source and final destination chains.</p> <p>The IBC protocol doesn't know the topology of the overall network (i.e connections between chains and identifier names between them). For this reason, in the multiple hops case, a particular chain in the timeline of the individual transfers can't query the chain and client identifiers of the other chains.</p> <p>Take for example the following sequence of transfers <code>A -&gt; B -&gt; C</code> for an IBC token, with a final prefix path (trace info) of <code>transfer/channelChainC/transfer/channelChainB</code>. What the paragraph above means is that even in the case that chain <code>C</code> is directly connected to chain <code>A</code>, querying the port and channel identifiers that chain <code>B</code> uses to connect to chain <code>A</code> (eg: <code>transfer/channelChainA</code>) can be completely different from the one that chain <code>C</code> uses to connect to chain <code>A</code> (eg: <code>transfer/channelToChainA</code>).</p> <p>Thus the proposed solution for clients that the IBC team recommends are the following:</p> <ul> <li>Connect to all chains: Connecting to all the chains in the timeline would allow clients to   perform the queries outlined in the direct connection section to each   relevant chain. By repeatedly following the port and channel denomination trace transfer timeline,   clients should always be able to find all the relevant identifiers. This comes at the tradeoff   that the client must connect to nodes on each of the chains in order to perform the queries.</li> <li>Relayer as a Service (RaaS): A longer term solution is to use/create a relayer service that   could map the denomination trace to the chain path timeline for each token (i.e <code>origin chain -&gt; chain #1 -&gt; ... -&gt; chain #(n-1) -&gt; final chain</code>). These services could provide merkle proofs in   order to allow clients to optionally verify the path timeline correctness for themselves by   running light clients. If the proofs are not verified, they should be considered as trusted third   parties services. Additionally, client would be advised in the future to use RaaS that support the   largest number of connections between chains in the ecosystem. Unfortunately, none of the existing   public relayers (in Golang and   Rust), provide this service to clients.</li> </ul> <p>:::tip The only viable alternative for clients (at the time of writing) to tokens with multiple connection hops, is to connect to all chains directly and perform relevant queries to each of them in the sequence. :::</p>"},{"location":"tools/ibc-transfer/#forwarding","title":"Forwarding","text":"<p>:::info Token forwarding and unwinding is supported only on ICS20 v2 transfer channels. :::</p> <p>Forwarding allows tokens to be routed to a final destination through multiple (up to 8) intermediary chains. With forwarding, it's also possible to unwind IBC vouchers to their native chain, and forward  them afterwards to another destination, all with just a single transfer transaction on the sending chain.</p>"},{"location":"tools/ibc-transfer/#forward-tokens","title":"Forward tokens","text":"<p>Native tokens or IBC vouchers on any chain can be forwarded through intermediary chains to reach their  final destination. For example, given the topology below, with 3 chains and a transfer channel between chains A and B and between chains B and C:</p> <p></p> <p>Native tokens on chain <code>A</code> can be sent to chain <code>C</code> through chain <code>B</code>. The routing is specified by the  source port ID and channel ID of choice on every intermediary chain. In this example, there is only one forwarding hop on chain <code>B</code> and the port ID, channel ID pair is <code>transfer</code>, <code>channelBToC</code>. Forwarding of  a multi-denom collections of tokens is also allowed (i.e. forwarding of tokens of different denominations).</p>"},{"location":"tools/ibc-transfer/#unwind-tokens","title":"Unwind tokens","text":"<p>Taking again as an example the topology from the previous section, we assume that native tokens on chain <code>A</code> have been transferred to chain <code>C</code>. The IBC vouchers on chain <code>C</code> have the denomination trace <code>transfer/channelCtoB/transfer/channelBtoA</code>, and with forwarding it is possible to submit a transfer message  on chain <code>C</code> and automatically unwind the vouchers through chain <code>B</code> to chain <code>A</code>, so that the tokens recovered on the origin chain regain their native denomination. In order to execute automatic unwinding, the transfer module does not require extra user input: the unwind route is encoded in the denomination trace with the  pairs of destination port ID, channel ID that are added on every chain where the tokens are received.</p> <p>Please note that unwinding of vouchers is only allowed when vouchers transferred all share the same denomination trace (signifying coins that all originate from the same source). It is not possible to unwind vouchers of two different  IBC denominations, since they come from different source chains.</p>"},{"location":"tools/ibc-transfer/#unwind-tokens-and-then-forward","title":"Unwind tokens and then forward","text":"<p>Unwinding and forwarding can be used in combination, so that vouchers are first unwound to their origin chain and then forwarded to a final destination. The same restriction as in the unwinding case applies: only vouchers of a single IBC denomination can be used.</p>"},{"location":"tools/ibc-transfer/#locked-funds","title":"Locked funds","text":"<p>In some exceptional cases, a client state associated with a given channel cannot be updated. This causes that funds from fungible tokens in that channel will be permanently locked and thus can no longer be transferred.</p> <p>To mitigate this, a client update governance proposal can be submitted to update the frozen client with a new valid header. Once the proposal passes the client state will be unfrozen and the funds from the associated channels will then be unlocked. This mechanism only applies to clients that allow updates via governance, such as Tendermint clients.</p> <p>In addition to this, it's important to mention that a token must be sent back along the exact route that it took originally in order to return it to its original form on the source chain (eg: the Cosmos Hub for the <code>uatom</code>). Sending a token back to the same chain across a different channel will not move the token back across its timeline. If a channel in the chain history closes before the token can be sent back across that channel, then the token will not be returnable to its original form.</p>"},{"location":"tools/ibc-transfer/#security-considerations","title":"Security considerations","text":"<p>For safety, no other module must be capable of minting tokens with the <code>ibc/</code> prefix. The IBC transfer module needs a subset of the denomination space that only it can create tokens in.</p>"},{"location":"tools/ibc-transfer/#channel-closure","title":"Channel Closure","text":"<p>The IBC transfer module does not support channel closure.</p>"}]}